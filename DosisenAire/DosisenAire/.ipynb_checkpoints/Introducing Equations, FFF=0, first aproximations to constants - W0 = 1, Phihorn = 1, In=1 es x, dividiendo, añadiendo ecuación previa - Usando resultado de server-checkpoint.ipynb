{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuadrados 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-5e7b1d497cad>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddopen5 = pd.read_csv('OPEN/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
      "<ipython-input-2-5e7b1d497cad>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcropen5 = pd.read_csv('OPEN/txt/5x5/5x5pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
      "<ipython-input-2-5e7b1d497cad>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinopen5 = pd.read_csv('OPEN/txt/5x5/5x5pro-in-100.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
      "<ipython-input-2-5e7b1d497cad>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddFFF5 = pd.read_csv('FFF/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
      "<ipython-input-2-5e7b1d497cad>:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcrFFF5 = pd.read_csv('FFF/txt/5x5/5x5pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
      "<ipython-input-2-5e7b1d497cad>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinFFF5 = pd.read_csv('FFF/txt/5x5/5x5pro-in-100.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n"
     ]
    }
   ],
   "source": [
    "pddopen5 = pd.read_csv('OPEN/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "pcropen5 = pd.read_csv('OPEN/txt/5x5/5x5pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "pinopen5 = pd.read_csv('OPEN/txt/5x5/5x5pro-in-100.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "\n",
    "pddFFF5 = pd.read_csv('FFF/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
    "pcrFFF5 = pd.read_csv('FFF/txt/5x5/5x5pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
    "pinFFF5 = pd.read_csv('FFF/txt/5x5/5x5pro-in-100.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5559e724810d>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddopen10 = pd.read_csv('OPEN/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
      "<ipython-input-3-5559e724810d>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcropen10 = pd.read_csv('OPEN/txt/10x10/10x10pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
      "<ipython-input-3-5559e724810d>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinopen10 = pd.read_csv('OPEN/txt/10x10/10x10pro-in-100.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
      "<ipython-input-3-5559e724810d>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddFFF10 = pd.read_csv('FFF/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
      "<ipython-input-3-5559e724810d>:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcrFFF10 = pd.read_csv('FFF/txt/10x10/10x10pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
      "<ipython-input-3-5559e724810d>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinFFF10 = pd.read_csv('FFF/txt/10x10/10x10pro-in-100.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n"
     ]
    }
   ],
   "source": [
    "pddopen10 = pd.read_csv('OPEN/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "pcropen10 = pd.read_csv('OPEN/txt/10x10/10x10pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "pinopen10 = pd.read_csv('OPEN/txt/10x10/10x10pro-in-100.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "\n",
    "pddFFF10 = pd.read_csv('FFF/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
    "pcrFFF10 = pd.read_csv('FFF/txt/10x10/10x10pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
    "pinFFF10 = pd.read_csv('FFF/txt/10x10/10x10pro-in-100.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-fc4605168945>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddopen20 = pd.read_csv('OPEN/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
      "<ipython-input-4-fc4605168945>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcropen20 = pd.read_csv('OPEN/txt/20x20/20x20pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
      "<ipython-input-4-fc4605168945>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinopen20 = pd.read_csv('OPEN/txt/20x20/20x20pro-in-100.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
      "<ipython-input-4-fc4605168945>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddFFF20 = pd.read_csv('FFF/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
      "<ipython-input-4-fc4605168945>:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcrFFF20 = pd.read_csv('FFF/txt/20x20/20x20pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
      "<ipython-input-4-fc4605168945>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinFFF20 = pd.read_csv('FFF/txt/20x20/20x20pro-in-100.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n"
     ]
    }
   ],
   "source": [
    "pddopen20 = pd.read_csv('OPEN/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "pcropen20 = pd.read_csv('OPEN/txt/20x20/20x20pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "pinopen20 = pd.read_csv('OPEN/txt/20x20/20x20pro-in-100.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "\n",
    "pddFFF20 = pd.read_csv('FFF/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
    "pcrFFF20 = pd.read_csv('FFF/txt/20x20/20x20pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
    "pinFFF20 = pd.read_csv('FFF/txt/20x20/20x20pro-in-100.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 40x40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-38d7031e937e>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddopen40 = pd.read_csv('OPEN/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
      "<ipython-input-5-38d7031e937e>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcropen40 = pd.read_csv('OPEN/txt/40x40/40x40pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
      "<ipython-input-5-38d7031e937e>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinopen40 = pd.read_csv('OPEN/txt/40x40/40x40pro-in-100.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
      "<ipython-input-5-38d7031e937e>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddFFF40 = pd.read_csv('FFF/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
      "<ipython-input-5-38d7031e937e>:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcrFFF40 = pd.read_csv('FFF/txt/40x40/40x40pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
      "<ipython-input-5-38d7031e937e>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinFFF40 = pd.read_csv('FFF/txt/40x40/40x40pro-in-100.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n"
     ]
    }
   ],
   "source": [
    "pddopen40 = pd.read_csv('OPEN/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "pcropen40 = pd.read_csv('OPEN/txt/40x40/40x40pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "pinopen40 = pd.read_csv('OPEN/txt/40x40/40x40pro-in-100.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "\n",
    "pddFFF40 = pd.read_csv('FFF/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
    "pcrFFF40 = pd.read_csv('FFF/txt/40x40/40x40pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
    "pinFFF40 = pd.read_csv('FFF/txt/40x40/40x40pro-in-100.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuadrados 115"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-b3dbae33331e>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddopen5_115 = pd.read_csv('OPEN/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
      "<ipython-input-6-b3dbae33331e>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcropen5_115 = pd.read_csv('OPEN/txt/5x5/5x5pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
      "<ipython-input-6-b3dbae33331e>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinopen5_115 = pd.read_csv('OPEN/txt/5x5/5x5pro-in-115.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
      "<ipython-input-6-b3dbae33331e>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddFFF5_115 = pd.read_csv('FFF/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
      "<ipython-input-6-b3dbae33331e>:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcrFFF5_115 = pd.read_csv('FFF/txt/5x5/5x5pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
      "<ipython-input-6-b3dbae33331e>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinFFF5_115 = pd.read_csv('FFF/txt/5x5/5x5pro-in-115.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n"
     ]
    }
   ],
   "source": [
    "pddopen5_115 = pd.read_csv('OPEN/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "pcropen5_115 = pd.read_csv('OPEN/txt/5x5/5x5pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "pinopen5_115 = pd.read_csv('OPEN/txt/5x5/5x5pro-in-115.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "\n",
    "pddFFF5_115 = pd.read_csv('FFF/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
    "pcrFFF5_115 = pd.read_csv('FFF/txt/5x5/5x5pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
    "pinFFF5_115 = pd.read_csv('FFF/txt/5x5/5x5pro-in-115.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-876a524bf11a>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddopen10_115 = pd.read_csv('OPEN/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
      "<ipython-input-7-876a524bf11a>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcropen10_115 = pd.read_csv('OPEN/txt/10x10/10x10pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
      "<ipython-input-7-876a524bf11a>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinopen10_115 = pd.read_csv('OPEN/txt/10x10/10x10pro-in-115.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
      "<ipython-input-7-876a524bf11a>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddFFF10_115 = pd.read_csv('FFF/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
      "<ipython-input-7-876a524bf11a>:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcrFFF10_115 = pd.read_csv('FFF/txt/10x10/10x10pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
      "<ipython-input-7-876a524bf11a>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinFFF10_115 = pd.read_csv('FFF/txt/10x10/10x10pro-in-115.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n"
     ]
    }
   ],
   "source": [
    "pddopen10_115 = pd.read_csv('OPEN/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "pcropen10_115 = pd.read_csv('OPEN/txt/10x10/10x10pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "pinopen10_115 = pd.read_csv('OPEN/txt/10x10/10x10pro-in-115.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "\n",
    "pddFFF10_115 = pd.read_csv('FFF/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
    "pcrFFF10_115 = pd.read_csv('FFF/txt/10x10/10x10pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
    "pinFFF10_115 = pd.read_csv('FFF/txt/10x10/10x10pro-in-115.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-97b1090201f8>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddopen20_115 = pd.read_csv('OPEN/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
      "<ipython-input-8-97b1090201f8>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcropen20_115 = pd.read_csv('OPEN/txt/20x20/20x20pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
      "<ipython-input-8-97b1090201f8>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinopen20_115 = pd.read_csv('OPEN/txt/20x20/20x20pro-in-115.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
      "<ipython-input-8-97b1090201f8>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddFFF20_115 = pd.read_csv('FFF/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
      "<ipython-input-8-97b1090201f8>:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcrFFF20_115 = pd.read_csv('FFF/txt/20x20/20x20pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
      "<ipython-input-8-97b1090201f8>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinFFF20_115 = pd.read_csv('FFF/txt/20x20/20x20pro-in-115.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n"
     ]
    }
   ],
   "source": [
    "pddopen20_115 = pd.read_csv('OPEN/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "pcropen20_115 = pd.read_csv('OPEN/txt/20x20/20x20pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "pinopen20_115 = pd.read_csv('OPEN/txt/20x20/20x20pro-in-115.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "\n",
    "pddFFF20_115 = pd.read_csv('FFF/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
    "pcrFFF20_115 = pd.read_csv('FFF/txt/20x20/20x20pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
    "pinFFF20_115 = pd.read_csv('FFF/txt/20x20/20x20pro-in-115.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40x40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-5deaefc013ea>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddopen40_115 = pd.read_csv('OPEN/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
      "<ipython-input-9-5deaefc013ea>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcropen40_115 = pd.read_csv('OPEN/txt/40x40/40x40pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
      "<ipython-input-9-5deaefc013ea>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinopen40_115 = pd.read_csv('OPEN/txt/40x40/40x40pro-in-115.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
      "<ipython-input-9-5deaefc013ea>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddFFF40_115 = pd.read_csv('FFF/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
      "<ipython-input-9-5deaefc013ea>:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcrFFF40_115 = pd.read_csv('FFF/txt/40x40/40x40pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
      "<ipython-input-9-5deaefc013ea>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinFFF40_115 = pd.read_csv('FFF/txt/40x40/40x40pro-in-115.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n"
     ]
    }
   ],
   "source": [
    "pddopen40_115 = pd.read_csv('OPEN/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "pcropen40_115 = pd.read_csv('OPEN/txt/40x40/40x40pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "pinopen40_115 = pd.read_csv('OPEN/txt/40x40/40x40pro-in-115.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "\n",
    "pddFFF40_115 = pd.read_csv('FFF/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
    "pcrFFF40_115 = pd.read_csv('FFF/txt/40x40/40x40pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
    "pinFFF40_115 = pd.read_csv('FFF/txt/40x40/40x40pro-in-115.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 115"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-8e01dae11aa5>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddopen5_85 = pd.read_csv('OPEN/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
      "<ipython-input-10-8e01dae11aa5>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcropen5_85 = pd.read_csv('OPEN/txt/5x5/5x5pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
      "<ipython-input-10-8e01dae11aa5>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinopen5_85 = pd.read_csv('OPEN/txt/5x5/5x5pro-in-85.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
      "<ipython-input-10-8e01dae11aa5>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddFFF5_85 = pd.read_csv('FFF/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
      "<ipython-input-10-8e01dae11aa5>:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcrFFF5_85 = pd.read_csv('FFF/txt/5x5/5x5pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
      "<ipython-input-10-8e01dae11aa5>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinFFF5_85 = pd.read_csv('FFF/txt/5x5/5x5pro-in-85.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n"
     ]
    }
   ],
   "source": [
    "pddopen5_85 = pd.read_csv('OPEN/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "pcropen5_85 = pd.read_csv('OPEN/txt/5x5/5x5pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "pinopen5_85 = pd.read_csv('OPEN/txt/5x5/5x5pro-in-85.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "\n",
    "pddFFF5_85 = pd.read_csv('FFF/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
    "pcrFFF5_85 = pd.read_csv('FFF/txt/5x5/5x5pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
    "pinFFF5_85 = pd.read_csv('FFF/txt/5x5/5x5pro-in-85.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-efc97f103422>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddopen10_85 = pd.read_csv('OPEN/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
      "<ipython-input-11-efc97f103422>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcropen10_85 = pd.read_csv('OPEN/txt/10x10/10x10pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
      "<ipython-input-11-efc97f103422>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinopen10_85 = pd.read_csv('OPEN/txt/10x10/10x10pro-in-85.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
      "<ipython-input-11-efc97f103422>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddFFF10_85 = pd.read_csv('FFF/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
      "<ipython-input-11-efc97f103422>:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcrFFF10_85 = pd.read_csv('FFF/txt/10x10/10x10pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
      "<ipython-input-11-efc97f103422>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinFFF10_85 = pd.read_csv('FFF/txt/10x10/10x10pro-in-85.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n"
     ]
    }
   ],
   "source": [
    "pddopen10_85 = pd.read_csv('OPEN/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "pcropen10_85 = pd.read_csv('OPEN/txt/10x10/10x10pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "pinopen10_85 = pd.read_csv('OPEN/txt/10x10/10x10pro-in-85.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "\n",
    "pddFFF10_85 = pd.read_csv('FFF/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
    "pcrFFF10_85 = pd.read_csv('FFF/txt/10x10/10x10pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
    "pinFFF10_85 = pd.read_csv('FFF/txt/10x10/10x10pro-in-85.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-a68ef06485ef>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddopen20_85 = pd.read_csv('OPEN/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
      "<ipython-input-12-a68ef06485ef>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcropen20_85 = pd.read_csv('OPEN/txt/20x20/20x20pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
      "<ipython-input-12-a68ef06485ef>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinopen20_85 = pd.read_csv('OPEN/txt/20x20/20x20pro-in-85.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
      "<ipython-input-12-a68ef06485ef>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddFFF20_85 = pd.read_csv('FFF/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
      "<ipython-input-12-a68ef06485ef>:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcrFFF20_85 = pd.read_csv('FFF/txt/20x20/20x20pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
      "<ipython-input-12-a68ef06485ef>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinFFF20_85 = pd.read_csv('FFF/txt/20x20/20x20pro-in-85.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n"
     ]
    }
   ],
   "source": [
    "pddopen20_85 = pd.read_csv('OPEN/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "pcropen20_85 = pd.read_csv('OPEN/txt/20x20/20x20pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "pinopen20_85 = pd.read_csv('OPEN/txt/20x20/20x20pro-in-85.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "\n",
    "pddFFF20_85 = pd.read_csv('FFF/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
    "pcrFFF20_85 = pd.read_csv('FFF/txt/20x20/20x20pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
    "pinFFF20_85 = pd.read_csv('FFF/txt/20x20/20x20pro-in-85.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40x40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-a1eb063f6d0d>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddopen40_85 = pd.read_csv('OPEN/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
      "<ipython-input-13-a1eb063f6d0d>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcropen40_85 = pd.read_csv('OPEN/txt/40x40/40x40pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
      "<ipython-input-13-a1eb063f6d0d>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinopen40_85 = pd.read_csv('OPEN/txt/40x40/40x40pro-in-85.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
      "<ipython-input-13-a1eb063f6d0d>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pddFFF40_85 = pd.read_csv('FFF/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
      "<ipython-input-13-a1eb063f6d0d>:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pcrFFF40_85 = pd.read_csv('FFF/txt/40x40/40x40pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
      "<ipython-input-13-a1eb063f6d0d>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pinFFF40_85 = pd.read_csv('FFF/txt/40x40/40x40pro-in-85.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n"
     ]
    }
   ],
   "source": [
    "pddopen40_85 = pd.read_csv('OPEN/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "pcropen40_85 = pd.read_csv('OPEN/txt/40x40/40x40pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "pinopen40_85 = pd.read_csv('OPEN/txt/40x40/40x40pro-in-85.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "\n",
    "pddFFF40_85 = pd.read_csv('FFF/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
    "pcrFFF40_85 = pd.read_csv('FFF/txt/40x40/40x40pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
    "pinFFF40_85 = pd.read_csv('FFF/txt/40x40/40x40pro-in-85.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z = 100; In = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF5 = pinFFF5.iloc[:,:2]\n",
    "FFF5['FFF'] = 1\n",
    "FFF5.columns = ['r', 'señal', 'FFF']\n",
    "FFF5['Area'] = 25\n",
    "FFF5['Limit'] = 25\n",
    "\n",
    "Open5 = pinopen5.iloc[:,:2]\n",
    "Open5['FFF'] = 0\n",
    "Open5.columns = ['r', 'señal', 'FFF']\n",
    "Open5['Area'] = 25\n",
    "Open5['Limit'] = 25\n",
    "\n",
    "FFF10 = pinFFF10.iloc[:,:2]\n",
    "FFF10['FFF'] = 1\n",
    "FFF10.columns = ['r', 'señal', 'FFF']\n",
    "FFF10['Area'] = 100\n",
    "FFF10['Limit'] = 50\n",
    "\n",
    "Open10 = pinopen10.iloc[:,:2]\n",
    "Open10['FFF'] = 0\n",
    "Open10.columns = ['r', 'señal', 'FFF']\n",
    "Open10['Area'] = 100\n",
    "Open10['Limit'] = 50\n",
    "\n",
    "FFF20 = pinFFF20.iloc[:,:2]\n",
    "FFF20['FFF'] = 1\n",
    "FFF20.columns = ['r', 'señal', 'FFF']\n",
    "FFF20['Area'] = 400\n",
    "FFF20['Limit'] = 100\n",
    "\n",
    "Open20 = pinopen20.iloc[:,:2]\n",
    "Open20['FFF'] = 0\n",
    "Open20.columns = ['r', 'señal', 'FFF']\n",
    "Open20['Area'] = 400\n",
    "Open20['Limit'] = 100\n",
    "\n",
    "FFF40 = pinFFF40.iloc[:,:2]\n",
    "FFF40['FFF'] = 1\n",
    "FFF40.columns = ['r', 'señal', 'FFF']\n",
    "FFF40['Area'] = 1600\n",
    "FFF40['Limit'] = 200\n",
    "\n",
    "Open40 = pinopen40.iloc[:,:2]\n",
    "Open40['FFF'] = 0\n",
    "Open40.columns = ['r', 'señal', 'FFF']\n",
    "Open40['Area'] = 1600\n",
    "Open40['Limit'] = 200\n",
    "\n",
    "MixedIN = pd.concat([Open5, FFF5, Open10, FFF10, Open20, FFF20, Open40, FFF40]) \n",
    "MixedIN['In'] = 1\n",
    "MixedIN['Z'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z = 100; In = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF5 = pcrFFF5.iloc[:,:2]\n",
    "FFF5['FFF'] = 1\n",
    "FFF5.columns = ['r', 'señal', 'FFF']\n",
    "FFF5['Area'] = 25\n",
    "FFF5['Limit'] = 25\n",
    "\n",
    "Open5 = pcropen5.iloc[:,:2]\n",
    "Open5['FFF'] = 0\n",
    "Open5.columns = ['r', 'señal', 'FFF']\n",
    "Open5['Area'] = 25\n",
    "Open5['Limit'] = 25\n",
    "\n",
    "FFF10 = pcrFFF10.iloc[:,:2]\n",
    "FFF10['FFF'] = 1\n",
    "FFF10.columns = ['r', 'señal', 'FFF']\n",
    "FFF10['Area'] = 100\n",
    "FFF10['Limit'] = 50\n",
    "\n",
    "Open10 = pcropen10.iloc[:,:2]\n",
    "Open10['FFF'] = 0\n",
    "Open10.columns = ['r', 'señal', 'FFF']\n",
    "Open10['Area'] = 100\n",
    "Open10['Limit'] = 50\n",
    "\n",
    "FFF20 = pcrFFF20.iloc[:,:2]\n",
    "FFF20['FFF'] = 1\n",
    "FFF20.columns = ['r', 'señal', 'FFF']\n",
    "FFF20['Area'] = 400\n",
    "FFF20['Limit'] = 100\n",
    "\n",
    "Open20 = pcropen20.iloc[:,:2]\n",
    "Open20['FFF'] = 0\n",
    "Open20.columns = ['r', 'señal', 'FFF']\n",
    "Open20['Area'] = 400\n",
    "Open20['Limit'] = 100\n",
    "\n",
    "FFF40 = pcrFFF40.iloc[:,:2]\n",
    "FFF40['FFF'] = 1\n",
    "FFF40.columns = ['r', 'señal', 'FFF']\n",
    "FFF40['Area'] = 1600\n",
    "FFF40['Limit'] = 200\n",
    "\n",
    "Open40 = pcropen40.iloc[:,:2]\n",
    "Open40['FFF'] = 0\n",
    "Open40.columns = ['r', 'señal', 'FFF']\n",
    "Open40['Area'] = 1600\n",
    "Open40['Limit'] = 200\n",
    "\n",
    "MixedCR = pd.concat([Open5, FFF5, Open10, FFF10, Open20, FFF20, Open40, FFF40]) \n",
    "MixedCR['In'] = 0\n",
    "MixedCR['Z'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z = 85; In = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF5 = pinFFF5_85.iloc[:,:2]\n",
    "FFF5['FFF'] = 1\n",
    "FFF5.columns = ['r', 'señal', 'FFF']\n",
    "FFF5['Area'] = 25\n",
    "FFF5['Limit'] = 25\n",
    "\n",
    "Open5 = pinopen5_85.iloc[:,:2]\n",
    "Open5['FFF'] = 0\n",
    "Open5.columns = ['r', 'señal', 'FFF']\n",
    "Open5['Area'] = 25\n",
    "Open5['Limit'] = 25\n",
    "\n",
    "FFF10 = pinFFF10_85.iloc[:,:2]\n",
    "FFF10['FFF'] = 1\n",
    "FFF10.columns = ['r', 'señal', 'FFF']\n",
    "FFF10['Area'] = 100\n",
    "FFF10['Limit'] = 50\n",
    "\n",
    "Open10 = pinopen10_85.iloc[:,:2]\n",
    "Open10['FFF'] = 0\n",
    "Open10.columns = ['r', 'señal', 'FFF']\n",
    "Open10['Area'] = 100\n",
    "Open10['Limit'] = 50\n",
    "\n",
    "FFF20 = pinFFF20_85.iloc[:,:2]\n",
    "FFF20['FFF'] = 1\n",
    "FFF20.columns = ['r', 'señal', 'FFF']\n",
    "FFF20['Area'] = 400\n",
    "FFF20['Limit'] = 100\n",
    "\n",
    "Open20 = pinopen20_85.iloc[:,:2]\n",
    "Open20['FFF'] = 0\n",
    "Open20.columns = ['r', 'señal', 'FFF']\n",
    "Open20['Area'] = 400\n",
    "Open20['Limit'] = 100\n",
    "\n",
    "FFF40 = pinFFF40_85.iloc[:,:2]\n",
    "FFF40['FFF'] = 1\n",
    "FFF40.columns = ['r', 'señal', 'FFF']\n",
    "FFF40['Area'] = 1600\n",
    "FFF40['Limit'] = 200\n",
    "\n",
    "Open40 = pinopen40_85.iloc[:,:2]\n",
    "Open40['FFF'] = 0\n",
    "Open40.columns = ['r', 'señal', 'FFF']\n",
    "Open40['Area'] = 1600\n",
    "Open40['Limit'] = 200\n",
    "\n",
    "MixedIN85 = pd.concat([Open5, FFF5, Open10, FFF10, Open20, FFF20, Open40, FFF40]) \n",
    "MixedIN85['In'] = 1\n",
    "MixedIN85['Z'] = 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF5 = pcrFFF5_85.iloc[:,:2]\n",
    "FFF5['FFF'] = 1\n",
    "FFF5.columns = ['r', 'señal', 'FFF']\n",
    "FFF5['Area'] = 25\n",
    "FFF5['Limit'] = 25\n",
    "\n",
    "Open5 = pcropen5_85.iloc[:,:2]\n",
    "Open5['FFF'] = 0\n",
    "Open5.columns = ['r', 'señal', 'FFF']\n",
    "Open5['Area'] = 25\n",
    "Open5['Limit'] = 25\n",
    "\n",
    "FFF10 = pcrFFF10_85.iloc[:,:2]\n",
    "FFF10['FFF'] = 1\n",
    "FFF10.columns = ['r', 'señal', 'FFF']\n",
    "FFF10['Area'] = 100\n",
    "FFF10['Limit'] = 50\n",
    "\n",
    "Open10 = pcropen10_85.iloc[:,:2]\n",
    "Open10['FFF'] = 0\n",
    "Open10.columns = ['r', 'señal', 'FFF']\n",
    "Open10['Area'] = 100\n",
    "Open10['Limit'] = 50\n",
    "\n",
    "FFF20 = pcrFFF20_85.iloc[:,:2]\n",
    "FFF20['FFF'] = 1\n",
    "FFF20.columns = ['r', 'señal', 'FFF']\n",
    "FFF20['Area'] = 400\n",
    "FFF20['Limit'] = 100\n",
    "\n",
    "Open20 = pcropen20_85.iloc[:,:2]\n",
    "Open20['FFF'] = 0\n",
    "Open20.columns = ['r', 'señal', 'FFF']\n",
    "Open20['Area'] = 400\n",
    "Open20['Limit'] = 100\n",
    "\n",
    "FFF40 = pcrFFF40_85.iloc[:,:2]\n",
    "FFF40['FFF'] = 1\n",
    "FFF40.columns = ['r', 'señal', 'FFF']\n",
    "FFF40['Area'] = 1600\n",
    "FFF40['Limit'] = 200\n",
    "\n",
    "Open40 = pcropen40_85.iloc[:,:2]\n",
    "Open40['FFF'] = 0\n",
    "Open40.columns = ['r', 'señal', 'FFF']\n",
    "Open40['Area'] = 1600\n",
    "Open40['Limit'] = 200\n",
    "\n",
    "MixedCR85 = pd.concat([Open5, FFF5, Open10, FFF10, Open20, FFF20, Open40, FFF40]) \n",
    "MixedCR85['In'] = 0\n",
    "MixedCR85['Z'] = 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF5 = pinFFF5_115.iloc[:,:2]\n",
    "FFF5['FFF'] = 1\n",
    "FFF5.columns = ['r', 'señal', 'FFF']\n",
    "FFF5['Area'] = 25\n",
    "FFF5['Limit'] = 25\n",
    "\n",
    "Open5 = pinopen5_115.iloc[:,:2]\n",
    "Open5['FFF'] = 0\n",
    "Open5.columns = ['r', 'señal', 'FFF']\n",
    "Open5['Area'] = 25\n",
    "Open5['Limit'] = 25\n",
    "\n",
    "FFF10 = pinFFF10_115.iloc[:,:2]\n",
    "FFF10['FFF'] = 1\n",
    "FFF10.columns = ['r', 'señal', 'FFF']\n",
    "FFF10['Area'] = 100\n",
    "FFF10['Limit'] = 50\n",
    "\n",
    "Open10 = pinopen10_115.iloc[:,:2]\n",
    "Open10['FFF'] = 0\n",
    "Open10.columns = ['r', 'señal', 'FFF']\n",
    "Open10['Area'] = 100\n",
    "Open10['Limit'] = 50\n",
    "\n",
    "FFF20 = pinFFF20_115.iloc[:,:2]\n",
    "FFF20['FFF'] = 1\n",
    "FFF20.columns = ['r', 'señal', 'FFF']\n",
    "FFF20['Area'] = 400\n",
    "FFF20['Limit'] = 100\n",
    "\n",
    "Open20 = pinopen20_115.iloc[:,:2]\n",
    "Open20['FFF'] = 0\n",
    "Open20.columns = ['r', 'señal', 'FFF']\n",
    "Open20['Area'] = 400\n",
    "Open20['Limit'] = 100\n",
    "\n",
    "FFF40 = pinFFF40_115.iloc[:,:2]\n",
    "FFF40['FFF'] = 1\n",
    "FFF40.columns = ['r', 'señal', 'FFF']\n",
    "FFF40['Area'] = 1600\n",
    "FFF40['Limit'] = 200\n",
    "\n",
    "Open40 = pinopen40_115.iloc[:,:2]\n",
    "Open40['FFF'] = 0\n",
    "Open40.columns = ['r', 'señal', 'FFF']\n",
    "Open40['Area'] = 1600\n",
    "Open40['Limit'] = 200\n",
    "\n",
    "MixedIN115 = pd.concat([Open5, FFF5, Open10, FFF10, Open20, FFF20, Open40, FFF40]) \n",
    "MixedIN115['In'] = 1\n",
    "MixedIN115['Z'] = 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF5 = pcrFFF5_115.iloc[:,:2]\n",
    "FFF5['FFF'] = 1\n",
    "FFF5.columns = ['r', 'señal', 'FFF']\n",
    "FFF5['Area'] = 25\n",
    "FFF5['Limit'] = 25\n",
    "\n",
    "Open5 = pcropen5_115.iloc[:,:2]\n",
    "Open5['FFF'] = 0\n",
    "Open5.columns = ['r', 'señal', 'FFF']\n",
    "Open5['Area'] = 25\n",
    "Open5['Limit'] = 25\n",
    "\n",
    "FFF10 = pcrFFF10_115.iloc[:,:2]\n",
    "FFF10['FFF'] = 1\n",
    "FFF10.columns = ['r', 'señal', 'FFF']\n",
    "FFF10['Area'] = 100\n",
    "FFF10['Limit'] = 50\n",
    "\n",
    "Open10 = pcropen10_115.iloc[:,:2]\n",
    "Open10['FFF'] = 0\n",
    "Open10.columns = ['r', 'señal', 'FFF']\n",
    "Open10['Area'] = 100\n",
    "Open10['Limit'] = 50\n",
    "\n",
    "FFF20 = pcrFFF20_115.iloc[:,:2]\n",
    "FFF20['FFF'] = 1\n",
    "FFF20.columns = ['r', 'señal', 'FFF']\n",
    "FFF20['Area'] = 400\n",
    "FFF20['Limit'] = 100\n",
    "\n",
    "Open20 = pcropen20_115.iloc[:,:2]\n",
    "Open20['FFF'] = 0\n",
    "Open20.columns = ['r', 'señal', 'FFF']\n",
    "Open20['Area'] = 400\n",
    "Open20['Limit'] = 100\n",
    "\n",
    "FFF40 = pcrFFF40_115.iloc[:,:2]\n",
    "FFF40['FFF'] = 1\n",
    "FFF40.columns = ['r', 'señal', 'FFF']\n",
    "FFF40['Area'] = 1600\n",
    "FFF40['Limit'] = 200\n",
    "\n",
    "Open40 = pcropen40_115.iloc[:,:2]\n",
    "Open40['FFF'] = 0\n",
    "Open40.columns = ['r', 'señal', 'FFF']\n",
    "Open40['Area'] = 1600\n",
    "Open40['Limit'] = 200\n",
    "\n",
    "MixedCR115 = pd.concat([Open5, FFF5, Open10, FFF10, Open20, FFF20, Open40, FFF40]) \n",
    "MixedCR115['In'] = 0\n",
    "MixedCR115['Z'] = 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mixed = pd.concat([MixedCR, MixedIN, MixedCR85, MixedIN85, MixedCR115, MixedIN115]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Mixed['r'] = np.abs(Mixed.loc[:,['r']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mixed = Mixed.loc[:,['r', 'señal', 'FFF', 'Area', 'In', 'Z']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecuaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fluencia de los fotones se define como \n",
    "\n",
    "\\\\[ \\phi_\\gamma(x,y,z) = w_0\\phi_0 (x,y,z) \\phi^\\gamma_{horn}(x,y,z) + (1-w_0)\\phi_s(x,y,z)\\\\]\n",
    "\n",
    "donde \\\\(\\phi_o \\\\) es la fluencia producida por la fuente primaria y \\\\( \\phi_s \\\\) la producida por la fuente secundaria (\"scatter source\"). \n",
    "\n",
    "\n",
    "Todas las fluencias son tal que:\n",
    "\n",
    "\\\\[ \\phi_\\alpha (x,y,z) = Z(z; z_D^x, z_D^y, z_\\alpha) T_\\alpha(x^+_\\alpha x^-_\\alpha)T_\\alpha(y^+_\\alpha, y^-_\\alpha)\\\\]\n",
    "\n",
    "Donde\n",
    "\n",
    "\\\\[ Z(z; z_D^x, z_D^y, z_\\alpha) = \\frac{1}{4} \\frac{ (z^x_D - z_\\alpha) (z^y_D - z_\\alpha)}{ (z-z_\\alpha)^2} \\\\]\n",
    "\n",
    "y \\\\(T_0\\\\) es la fuente primaria y \\\\(T_\\alpha\\\\)\n",
    "\n",
    "\\\\[ T_0(t_0^+, t_0^-) = Q_0(\\frac{t_0^+}{\\delta_0}) + Q_0(\\frac{t^-_0}{\\delta_0}) \\\\]\n",
    "\n",
    "donde \\\\(Q_0(v) = \\frac{v}{\\sqrt{1+v^2}}\\\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los casos 'free' usamos únicamente las fluencias primarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\\[ \\phi_\\gamma(x,y,z) = w_0\\phi_0 (x,y,z) \\phi^\\gamma_{horn}(x,y,z)\\\\]\n",
    "\n",
    "Por tanto \n",
    "\n",
    "\\\\[ \\phi_\\gamma(x,y,z) = w_0\\phi_0 (x,y,z) ( 1 + \\rho^2 \\sum^4_{j=0} h^{\\gamma}_j \\rho^j )\\\\]\n",
    "\n",
    "donde \\\\[ \\rho = \\frac{\\sqrt{x^2 + y^2}}{z-z_0} \\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\\[ \\Phi_{horn}=0 \\\\]\n",
    "Por lo que nos queda \\\\[\\phi_\\gamma (x, y, z) = \\omega_0 \\phi_0(x,y,z) \\\\]\n",
    "\n",
    "Estamos suponiendo \\\\(\\omega_0\\\\) como 0\n",
    "\n",
    "\\\\[ \\phi_\\gamma (x,y,z) = \\phi_0(x,y,z) = \\frac{1}{4} \\frac{(z^x_D-z_0)(z^y_D - z_0)}{(z-z_0)^2}*Q_0(\\frac{t^+_0}{\\delta_0} + \\frac{t_0^-}{\\delta_0})  \\\\]\n",
    "\n",
    "Conocemos: \\\\( z^x_D = 50.9 ; z^y_D=42.6 \\\\), y sabiendo que hay componente x e y.\n",
    "\n",
    "\\\\[ \\phi_\\gamma (x,y,z) = \\phi_0(x,y,z) = \\frac{542.085}{z^2}*Q_0(\\frac{x^+_0}{\\delta_0} + \\frac{x_0^-}{\\delta_0}) * Q_0(\\frac{y^+_0}{\\delta_0} + \\frac{y_0^-}{\\delta_0})  \\\\]\n",
    "\n",
    "\\\\( Q_0 (v) = \\frac{v}{\\sqrt{1+v^2}} \\\\) por lo que, siendo fotones, van a la velocidad de la luz, siendo \\\\(Q_0 \\approx 1\\\\) \n",
    "\n",
    "\\\\[ \\phi_\\gamma (x,y,z) = \\phi_0(x,y,z) = \\frac{542.085}{z^2}*(\\frac{t^+_0 + t_0^-}{\\delta_0})  \\\\]\n",
    "\n",
    "t significa x o y, dependiendo del caso.\n",
    "\n",
    "\\\\[t_0^{\\pm} = min[\\frac{w_I^tz_U^t(z-z_0) \\pm 2tz_I(z_0 - z_U^t)}{2z_I(z-z_U^t)} , \\frac{w_I^tz_D^t(z-z_0) \\pm 2 t z_I(z_0-z_D^t)}{2z_I(z-z^t_D)}   ] \\\\]\n",
    "\n",
    "Conocemos: \\\\(  z_U^x = 43.1; z_U^y = 29.8 ; z_0 = 0 ; z^x_D = 50.9 ; z^y_D=42.6 \\\\)\n",
    "\n",
    "Para x:\n",
    "\n",
    "\\\\[x_0^{\\pm} = min[\\frac{w_I^x * 43.1*(z) \\pm 2xz_I*43.1}{2z_I(z-43.1)} , \\frac{w_I^x *50.9 *z \\pm 2 x z_I(-50.9)}{2z_I(z-50.9)}  ] \\\\]\n",
    "\n",
    "Para y:\n",
    "\n",
    "\\\\[y_0^{\\pm} = min[\\frac{w_I^y * 29.8*(z) \\pm 2yz_I*29.8}{2z_I(z-29.8)} , \\frac{w_I^y *42.6* z \\pm 2 y z_I(-42.6)}{2z_I(z-42.6)}  ] \\\\]\n",
    "\n",
    "\n",
    "\\\\( w_I \\\\) indican el área inicialmente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MixedF0 = Mixed[Mixed['FFF']==0].reset_index(drop=True)\n",
    "MixedF00 = MixedF0[MixedF0['señal']>0.5]\n",
    "MixedF00.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining T plus and T minus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z_I es lo mismo que Z?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\\\\[t_0^{\\pm} = min[\\frac{w_I^tz_U^t(z-z_0) \\pm 2tz_I(z_0 - z_U^t)}{2z_I(z-z_U^t)} , \\frac{w_I^tz_D^t(z-z_0) \\pm 2 t z_I(z_0-z_D^t)}{2z_I(z-z^t_D)}   ] \\\\]\n",
    "\n",
    "Suponemos \\\\(Z_I = Z; z_0=0\\\\)\n",
    "\n",
    "\\\\[t_0^{\\pm} = min[\\frac{w_I^tz_U^t \\pm 2t(z_0 - z_U^t)}{2(z-z_U^t)} , \\frac{w_I^tz_D^t \\pm 2 t (z_0-z_D^t)}{2z_I(z-z^t_D)}   ] \\\\]\n",
    "\n",
    "Separando en x, y, +, - y cada ima de ñas dos ecuaciones\n",
    "\n",
    "\n",
    "\n",
    "\\\\[x_0^{+} (1) = \\frac{ w_I^x * (43.1) + 2x*(-43.1)}{2(z-43.1)}   \\\\]\n",
    "\n",
    "\\\\[x_0^{+} (2) = \\frac{w_I^x *(50.9) + 2 x (-50.9)}{2(z-50.9)}  \\\\]\n",
    "\n",
    "\n",
    "\\\\[y_0^{+} (1) = \\frac{ w_I^y * (29.8) + 2y*(-29.8)}{2(z-29.8)}   \\\\]\n",
    "\n",
    "\\\\[y_0^{+} (2) = \\frac{w_I^y * (42.6) + 2 y (-42.6)}{2(z-42.6)}  \\\\]\n",
    "\n",
    "\n",
    "\\\\[x_0^{-} (1) = \\frac{ w_I^x * (43.1) - 2x*(-43.1)}{2(z-43.1)}   \\\\]\n",
    "\n",
    "\\\\[x_0^{-} (2) = \\frac{w_I^x *(50.9) - 2 x (-50.9)}{2(z-50.9)}  \\\\]\n",
    "\n",
    "\n",
    "\\\\[y_0^{-} (1) = \\frac{ w_I^y * (29.8) - 2y*(-29.8)}{2(z-29.8)}   \\\\]\n",
    "\n",
    "\\\\[y_0^{-} (2) = \\frac{w_I^y * (42.6) - 2 y (-42.6)}{2(z-42.6)}  \\\\]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tplus_1 = []\n",
    "tplus_2 = []\n",
    "\n",
    "tplus_ = []\n",
    "\n",
    "\n",
    "\n",
    "tminus_1 = []\n",
    "tminus_2 = []\n",
    "\n",
    "tminus_ = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-b658f6e40212>:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MixedF00['tplus'] = tplus\n",
      "<ipython-input-25-b658f6e40212>:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MixedF00['tminus'] = tminus\n",
      "<ipython-input-25-b658f6e40212>:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MixedF00['tplus_'] = tplus_\n",
      "<ipython-input-25-b658f6e40212>:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MixedF00['tminus_'] = tminus_\n"
     ]
    }
   ],
   "source": [
    "tplus1 = []\n",
    "tplus2 = []\n",
    "\n",
    "tplus = []\n",
    "\n",
    "\n",
    "\n",
    "tminus1 = []\n",
    "tminus2 = []\n",
    "\n",
    "tminus = []\n",
    "\n",
    "\n",
    "tplus_1 = []\n",
    "tplus_2 = []\n",
    "\n",
    "tplus_ = []\n",
    "\n",
    "\n",
    "\n",
    "tminus_1 = []\n",
    "tminus_2 = []\n",
    "\n",
    "tminus_ = []\n",
    "\n",
    "\n",
    "for k in np.arange(0, MixedF00.shape[0]):\n",
    "    \n",
    "    if MixedF00['In'][k]==1:\n",
    "        tplus1.append(((MixedF00['Area'][k] * 43.1 + 2*np.abs(MixedF00['r'][k]) * -43.1)/(2*((MixedF00['Z'][k]) - 43.1))))\n",
    "        tplus2.append(((MixedF00['Area'][k] * 50.9 + 2*np.abs(MixedF00['r'][k]) * -50.9)/(2*((MixedF00['Z'][k]) - 50.9))))\n",
    "        tminus1.append(((MixedF00['Area'][k] * 43.1 - 2*np.abs(MixedF00['r'][k]) * -43.1)/(2*((MixedF00['Z'][k]) - 43.1))))\n",
    "        tminus2.append(((MixedF00['Area'][k] * 50.9 - 2*np.abs(MixedF00['r'][k]) * -50.9)/(2*((MixedF00['Z'][k]) - 50.9))))\n",
    "        \n",
    "        tplus_1.append(((MixedF00['Area'][k] * 43.1)/(2*((MixedF00['Z'][k]) - 43.1))))\n",
    "        tplus_2.append(((MixedF00['Area'][k] * 50.9)/(2*((MixedF00['Z'][k]) - 50.9))))\n",
    "        tminus_1.append(((MixedF00['Area'][k] * 43.1)/(2*((MixedF00['Z'][k]) - 43.1))))\n",
    "        tminus_2.append(((MixedF00['Area'][k] * 50.9)/(2*((MixedF00['Z'][k]) - 50.9))))\n",
    "    else :\n",
    "        tplus1.append(((MixedF00['Area'][k] * 29.8 + 2*np.abs(MixedF00['r'][k]) * -29.8)/(2*((MixedF00['Z'][k]) - 29.8))))\n",
    "        tplus2.append(((MixedF00['Area'][k] * 42.6 + 2*np.abs(MixedF00['r'][k]) * -42.6)/(2*((MixedF00['Z'][k]) - 42.6))))\n",
    "        tminus1.append(((MixedF00['Area'][k] * 29.8 - 2*np.abs(MixedF00['r'][k]) * -29.8)/(2*((MixedF00['Z'][k]) - 29.8))))\n",
    "        tminus2.append(((MixedF00['Area'][k] * 42.6 - 2*np.abs(MixedF00['r'][k]) * -42.6)/(2*((MixedF00['Z'][k]) - 42.6))))\n",
    "\n",
    "        tplus_1.append(((MixedF00['Area'][k] * 43.1)/(2*((MixedF00['Z'][k]) - 43.1))))\n",
    "        tplus_2.append(((MixedF00['Area'][k] * 50.9)/(2*((MixedF00['Z'][k]) - 50.9))))\n",
    "        tminus_1.append(((MixedF00['Area'][k] * 43.1)/(2*((MixedF00['Z'][k]) - 43.1))))\n",
    "        tminus_2.append(((MixedF00['Area'][k] * 50.9)/(2*((MixedF00['Z'][k]) - 50.9))))\n",
    "\n",
    "        \n",
    "                \n",
    "                \n",
    "for i, j in zip(tplus1, tplus2):\n",
    "    if i <= j :\n",
    "        tplus.append(i)\n",
    "    else:\n",
    "        tplus.append(j)\n",
    "        \n",
    "for i, j in zip(tminus1, tminus2):\n",
    "    if i <= j :\n",
    "        tminus.append(i)\n",
    "    else:\n",
    "        tminus.append(j)\n",
    "        \n",
    "for i, j in zip(tplus_1, tplus_2):\n",
    "    if i <= j :\n",
    "        tplus_.append(i)\n",
    "    else:\n",
    "        tplus_.append(j)\n",
    "        \n",
    "for i, j in zip(tminus_1, tminus_2):\n",
    "    if i <= j :\n",
    "        tminus_.append(i)\n",
    "    else:\n",
    "        tminus_.append(j)\n",
    "\n",
    "        \n",
    "MixedF00['tplus'] = tplus \n",
    "MixedF00['tminus'] = tminus \n",
    "MixedF00['tplus_'] = tplus_\n",
    "MixedF00['tminus_'] = tminus_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Phi0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\\[ \\phi_\\gamma (x,y,z) = \\phi_0(x,y,z) = \\frac{542.085}{z^2}*(\\frac{x^+_0 + x_0^-}{\\delta_0})*(\\frac{y^+_0 + y_0^-}{\\delta_0})  \\\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-8b12198e1642>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MixedF00['phi0 minus delta'] = ((542.085/(MixedF00['Z'].to_numpy())**2))*(MixedF00['tplus'].to_numpy()+MixedF00['tminus'].to_numpy())*(MixedF00['tplus_'].to_numpy()+MixedF00['tminus_'].to_numpy())\n"
     ]
    }
   ],
   "source": [
    "MixedF00['phi0 minus delta'] = ((542.085/(MixedF00['Z'].to_numpy())**2))*(MixedF00['tplus'].to_numpy()+MixedF00['tminus'].to_numpy())*(MixedF00['tplus_'].to_numpy()+MixedF00['tminus_'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>señal</th>\n",
       "      <th>FFF</th>\n",
       "      <th>Area</th>\n",
       "      <th>In</th>\n",
       "      <th>Z</th>\n",
       "      <th>tplus</th>\n",
       "      <th>tminus</th>\n",
       "      <th>tplus_</th>\n",
       "      <th>tminus_</th>\n",
       "      <th>phi0 minus delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.00</td>\n",
       "      <td>0.73831</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-14.472125</td>\n",
       "      <td>18.890313</td>\n",
       "      <td>9.468366</td>\n",
       "      <td>9.468366</td>\n",
       "      <td>4.535410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.00</td>\n",
       "      <td>1.10160</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-13.729965</td>\n",
       "      <td>18.465812</td>\n",
       "      <td>9.468366</td>\n",
       "      <td>9.468366</td>\n",
       "      <td>4.861497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.00</td>\n",
       "      <td>1.45520</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-12.987805</td>\n",
       "      <td>18.041311</td>\n",
       "      <td>9.468366</td>\n",
       "      <td>9.468366</td>\n",
       "      <td>5.187584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.00</td>\n",
       "      <td>1.76280</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-12.245645</td>\n",
       "      <td>17.616809</td>\n",
       "      <td>9.468366</td>\n",
       "      <td>9.468366</td>\n",
       "      <td>5.513671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.00</td>\n",
       "      <td>2.06260</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-11.503484</td>\n",
       "      <td>17.192308</td>\n",
       "      <td>9.468366</td>\n",
       "      <td>9.468366</td>\n",
       "      <td>5.839758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>221.95</td>\n",
       "      <td>0.61982</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>346.508414</td>\n",
       "      <td>612.601460</td>\n",
       "      <td>479.554937</td>\n",
       "      <td>479.554937</td>\n",
       "      <td>37705.823847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>223.10</td>\n",
       "      <td>0.61416</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>345.819054</td>\n",
       "      <td>613.290821</td>\n",
       "      <td>479.554937</td>\n",
       "      <td>479.554937</td>\n",
       "      <td>37705.823847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>224.25</td>\n",
       "      <td>0.59830</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>345.129694</td>\n",
       "      <td>613.980181</td>\n",
       "      <td>479.554937</td>\n",
       "      <td>479.554937</td>\n",
       "      <td>37705.823847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>225.40</td>\n",
       "      <td>0.56161</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>344.440334</td>\n",
       "      <td>614.669541</td>\n",
       "      <td>479.554937</td>\n",
       "      <td>479.554937</td>\n",
       "      <td>37705.823847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>226.55</td>\n",
       "      <td>0.50512</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>343.750974</td>\n",
       "      <td>615.358901</td>\n",
       "      <td>479.554937</td>\n",
       "      <td>479.554937</td>\n",
       "      <td>37705.823847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1865 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           r    señal  FFF  Area  In    Z       tplus      tminus      tplus_  \\\n",
       "0      32.00  0.73831    0    25   0  100  -14.472125   18.890313    9.468366   \n",
       "1      31.00  1.10160    0    25   0  100  -13.729965   18.465812    9.468366   \n",
       "2      30.00  1.45520    0    25   0  100  -12.987805   18.041311    9.468366   \n",
       "3      29.00  1.76280    0    25   0  100  -12.245645   17.616809    9.468366   \n",
       "4      28.00  2.06260    0    25   0  100  -11.503484   17.192308    9.468366   \n",
       "...      ...      ...  ...   ...  ..  ...         ...         ...         ...   \n",
       "1860  221.95  0.61982    0  1600   1  115  346.508414  612.601460  479.554937   \n",
       "1861  223.10  0.61416    0  1600   1  115  345.819054  613.290821  479.554937   \n",
       "1862  224.25  0.59830    0  1600   1  115  345.129694  613.980181  479.554937   \n",
       "1863  225.40  0.56161    0  1600   1  115  344.440334  614.669541  479.554937   \n",
       "1864  226.55  0.50512    0  1600   1  115  343.750974  615.358901  479.554937   \n",
       "\n",
       "         tminus_  phi0 minus delta  \n",
       "0       9.468366          4.535410  \n",
       "1       9.468366          4.861497  \n",
       "2       9.468366          5.187584  \n",
       "3       9.468366          5.513671  \n",
       "4       9.468366          5.839758  \n",
       "...          ...               ...  \n",
       "1860  479.554937      37705.823847  \n",
       "1861  479.554937      37705.823847  \n",
       "1862  479.554937      37705.823847  \n",
       "1863  479.554937      37705.823847  \n",
       "1864  479.554937      37705.823847  \n",
       "\n",
       "[1865 rows x 11 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MixedF00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1865, 9)\n",
      "(1865, 10)\n",
      "(1865, 11)\n",
      "(1865, 12)\n",
      "(1865, 13)\n",
      "(1865, 14)\n",
      "(1865, 15)\n",
      "(1865, 16)\n",
      "(1865, 17)\n",
      "(1865, 18)\n",
      "(1865, 19)\n",
      "(1865, 20)\n",
      "(1865, 21)\n",
      "(1865, 22)\n",
      "(1865, 23)\n",
      "(1865, 24)\n",
      "(1865, 25)\n",
      "(1865, 26)\n",
      "(1865, 27)\n",
      "(1865, 28)\n",
      "(1865, 29)\n",
      "(1865, 30)\n",
      "(1865, 31)\n",
      "(1865, 32)\n",
      "(1865, 33)\n",
      "(1865, 34)\n",
      "(1865, 35)\n",
      "(1865, 36)\n",
      "(1865, 37)\n",
      "(1865, 38)\n",
      "(1865, 39)\n",
      "(1865, 40)\n",
      "(1865, 41)\n",
      "(1865, 42)\n",
      "(1865, 43)\n",
      "(1865, 44)\n",
      "(1865, 45)\n",
      "(1865, 46)\n",
      "(1865, 47)\n",
      "(1865, 48)\n",
      "(1865, 49)\n",
      "(1865, 50)\n",
      "(1865, 51)\n",
      "(1865, 52)\n",
      "(1865, 53)\n",
      "(1865, 54)\n",
      "(1865, 55)\n",
      "(1865, 56)\n",
      "(1865, 57)\n",
      "(1865, 58)\n",
      "(1865, 59)\n",
      "(1865, 60)\n",
      "(1865, 61)\n",
      "(1865, 62)\n",
      "(1865, 63)\n",
      "(1865, 64)\n",
      "(1865, 65)\n",
      "(1865, 66)\n",
      "(1865, 67)\n",
      "(1865, 68)\n",
      "(1865, 69)\n",
      "(1865, 70)\n",
      "(1865, 71)\n",
      "(1865, 72)\n",
      "(1865, 73)\n",
      "(1865, 74)\n",
      "(1865, 75)\n",
      "(1865, 76)\n",
      "(1865, 77)\n",
      "(1865, 78)\n",
      "(1865, 79)\n",
      "(1865, 80)\n",
      "(1865, 81)\n",
      "(1865, 82)\n",
      "(1865, 83)\n",
      "(1865, 84)\n",
      "(1865, 85)\n",
      "(1865, 86)\n",
      "(1865, 87)\n",
      "(1865, 88)\n",
      "(1865, 89)\n",
      "(1865, 90)\n",
      "(1865, 91)\n",
      "(1865, 92)\n",
      "(1865, 93)\n",
      "(1865, 94)\n",
      "(1865, 95)\n",
      "(1865, 96)\n",
      "(1865, 97)\n",
      "(1865, 98)\n",
      "(1865, 99)\n",
      "(1865, 100)\n",
      "(1865, 101)\n",
      "(1865, 102)\n",
      "(1865, 103)\n",
      "(1865, 104)\n",
      "(1865, 105)\n",
      "(1865, 106)\n",
      "(1865, 107)\n",
      "(1865, 108)\n",
      "(1865, 109)\n",
      "(1865, 110)\n",
      "(1865, 111)\n",
      "(1865, 112)\n",
      "(1865, 113)\n",
      "(1865, 114)\n",
      "(1865, 115)\n",
      "(1865, 116)\n",
      "(1865, 117)\n",
      "(1865, 118)\n",
      "(1865, 119)\n",
      "(1865, 120)\n",
      "(1865, 121)\n",
      "(1865, 122)\n",
      "(1865, 123)\n",
      "(1865, 124)\n",
      "(1865, 125)\n",
      "(1865, 126)\n",
      "(1865, 127)\n",
      "(1865, 128)\n",
      "(1865, 129)\n",
      "(1865, 130)\n",
      "(1865, 131)\n",
      "(1865, 132)\n",
      "(1865, 133)\n",
      "(1865, 134)\n",
      "(1865, 135)\n",
      "(1865, 136)\n",
      "(1865, 137)\n",
      "(1865, 138)\n",
      "(1865, 139)\n",
      "(1865, 140)\n",
      "(1865, 141)\n",
      "(1865, 142)\n",
      "(1865, 143)\n",
      "(1865, 144)\n",
      "(1865, 145)\n",
      "(1865, 146)\n",
      "(1865, 147)\n",
      "(1865, 148)\n",
      "(1865, 149)\n",
      "(1865, 150)\n",
      "(1865, 151)\n",
      "(1865, 152)\n",
      "(1865, 153)\n",
      "(1865, 154)\n",
      "(1865, 155)\n",
      "(1865, 156)\n",
      "(1865, 157)\n",
      "(1865, 158)\n",
      "(1865, 159)\n",
      "(1865, 160)\n",
      "(1865, 161)\n",
      "(1865, 162)\n",
      "(1865, 163)\n",
      "(1865, 164)\n",
      "(1865, 165)\n",
      "(1865, 166)\n",
      "(1865, 167)\n",
      "(1865, 168)\n",
      "(1865, 169)\n",
      "(1865, 170)\n",
      "(1865, 171)\n",
      "(1865, 172)\n",
      "(1865, 173)\n",
      "(1865, 174)\n",
      "(1865, 175)\n",
      "(1865, 176)\n",
      "(1865, 177)\n",
      "(1865, 178)\n",
      "(1865, 179)\n",
      "(1865, 180)\n",
      "(1865, 181)\n",
      "(1865, 182)\n",
      "(1865, 183)\n",
      "(1865, 184)\n",
      "(1865, 185)\n",
      "(1865, 186)\n",
      "(1865, 187)\n",
      "(1865, 188)\n",
      "(1865, 189)\n",
      "(1865, 190)\n",
      "(1865, 191)\n",
      "(1865, 192)\n",
      "(1865, 193)\n",
      "(1865, 194)\n",
      "(1865, 195)\n",
      "(1865, 196)\n",
      "(1865, 197)\n",
      "(1865, 198)\n",
      "(1865, 199)\n",
      "(1865, 200)\n",
      "(1865, 201)\n",
      "(1865, 202)\n",
      "(1865, 203)\n",
      "(1865, 204)\n",
      "(1865, 205)\n",
      "(1865, 206)\n",
      "(1865, 207)\n",
      "(1865, 208)\n",
      "(1865, 209)\n",
      "(1865, 210)\n",
      "(1865, 211)\n",
      "(1865, 212)\n",
      "(1865, 213)\n",
      "(1865, 214)\n",
      "(1865, 215)\n",
      "(1865, 216)\n",
      "(1865, 217)\n",
      "(1865, 218)\n",
      "(1865, 219)\n",
      "(1865, 220)\n",
      "(1865, 221)\n",
      "(1865, 222)\n",
      "(1865, 223)\n",
      "(1865, 224)\n",
      "(1865, 225)\n",
      "(1865, 226)\n",
      "(1865, 227)\n",
      "(1865, 228)\n",
      "(1865, 229)\n",
      "(1865, 230)\n",
      "(1865, 231)\n",
      "(1865, 232)\n",
      "(1865, 233)\n",
      "(1865, 234)\n",
      "(1865, 235)\n",
      "(1865, 236)\n",
      "(1865, 237)\n",
      "(1865, 238)\n",
      "(1865, 239)\n",
      "(1865, 240)\n",
      "(1865, 241)\n",
      "(1865, 242)\n",
      "(1865, 243)\n",
      "(1865, 244)\n",
      "(1865, 245)\n",
      "(1865, 246)\n",
      "(1865, 247)\n",
      "(1865, 248)\n",
      "(1865, 249)\n",
      "(1865, 250)\n",
      "(1865, 251)\n",
      "(1865, 252)\n",
      "(1865, 253)\n",
      "(1865, 254)\n",
      "(1865, 255)\n",
      "(1865, 256)\n",
      "(1865, 257)\n",
      "(1865, 258)\n",
      "(1865, 259)\n",
      "(1865, 260)\n",
      "(1865, 261)\n",
      "(1865, 262)\n",
      "(1865, 263)\n",
      "(1865, 264)\n",
      "(1865, 265)\n",
      "(1865, 266)\n",
      "(1865, 267)\n",
      "(1865, 268)\n",
      "(1865, 269)\n",
      "(1865, 270)\n",
      "(1865, 271)\n",
      "(1865, 272)\n",
      "(1865, 273)\n",
      "(1865, 274)\n",
      "(1865, 275)\n",
      "(1865, 276)\n",
      "(1865, 277)\n",
      "(1865, 278)\n",
      "(1865, 279)\n",
      "(1865, 280)\n",
      "(1865, 281)\n",
      "(1865, 282)\n",
      "(1865, 283)\n",
      "(1865, 284)\n",
      "(1865, 285)\n",
      "(1865, 286)\n",
      "(1865, 287)\n",
      "(1865, 288)\n",
      "(1865, 289)\n",
      "(1865, 290)\n",
      "(1865, 291)\n",
      "(1865, 292)\n",
      "(1865, 293)\n",
      "(1865, 294)\n",
      "(1865, 295)\n",
      "(1865, 296)\n",
      "(1865, 297)\n",
      "(1865, 298)\n",
      "(1865, 299)\n",
      "(1865, 300)\n",
      "(1865, 301)\n",
      "(1865, 302)\n",
      "(1865, 303)\n",
      "(1865, 304)\n",
      "(1865, 305)\n",
      "(1865, 306)\n",
      "(1865, 307)\n",
      "(1865, 308)\n",
      "(1865, 309)\n",
      "(1865, 310)\n",
      "(1865, 311)\n",
      "(1865, 312)\n",
      "(1865, 313)\n",
      "(1865, 314)\n",
      "(1865, 315)\n",
      "(1865, 316)\n",
      "(1865, 317)\n",
      "(1865, 318)\n",
      "(1865, 319)\n",
      "(1865, 320)\n",
      "(1865, 321)\n",
      "(1865, 322)\n",
      "(1865, 323)\n",
      "(1865, 324)\n",
      "(1865, 325)\n",
      "(1865, 326)\n",
      "(1865, 327)\n",
      "(1865, 328)\n",
      "(1865, 329)\n",
      "(1865, 330)\n",
      "(1865, 331)\n",
      "(1865, 332)\n",
      "(1865, 333)\n",
      "(1865, 334)\n",
      "(1865, 335)\n",
      "(1865, 336)\n",
      "(1865, 337)\n",
      "(1865, 338)\n",
      "(1865, 339)\n",
      "(1865, 340)\n",
      "(1865, 341)\n",
      "(1865, 342)\n",
      "(1865, 343)\n",
      "(1865, 344)\n",
      "(1865, 345)\n",
      "(1865, 346)\n",
      "(1865, 347)\n",
      "(1865, 348)\n",
      "(1865, 349)\n",
      "(1865, 350)\n",
      "(1865, 351)\n",
      "(1865, 352)\n",
      "(1865, 353)\n",
      "(1865, 354)\n",
      "(1865, 355)\n",
      "(1865, 356)\n",
      "(1865, 357)\n",
      "(1865, 358)\n",
      "(1865, 359)\n",
      "(1865, 360)\n",
      "(1865, 361)\n",
      "(1865, 362)\n",
      "(1865, 363)\n",
      "(1865, 364)\n",
      "(1865, 365)\n",
      "(1865, 366)\n",
      "(1865, 367)\n",
      "(1865, 368)\n",
      "(1865, 369)\n",
      "(1865, 370)\n",
      "(1865, 371)\n",
      "(1865, 372)\n",
      "(1865, 373)\n",
      "(1865, 374)\n",
      "(1865, 375)\n",
      "(1865, 376)\n",
      "(1865, 377)\n",
      "(1865, 378)\n",
      "(1865, 379)\n",
      "(1865, 380)\n",
      "(1865, 381)\n",
      "(1865, 382)\n",
      "(1865, 383)\n",
      "(1865, 384)\n",
      "(1865, 385)\n",
      "(1865, 386)\n",
      "(1865, 387)\n",
      "(1865, 388)\n",
      "(1865, 389)\n",
      "(1865, 390)\n",
      "(1865, 391)\n",
      "(1865, 392)\n",
      "(1865, 393)\n",
      "(1865, 394)\n",
      "(1865, 395)\n",
      "(1865, 396)\n",
      "(1865, 397)\n",
      "(1865, 398)\n",
      "(1865, 399)\n",
      "(1865, 400)\n",
      "(1865, 401)\n",
      "(1865, 402)\n",
      "(1865, 403)\n",
      "(1865, 404)\n",
      "(1865, 405)\n",
      "(1865, 406)\n",
      "(1865, 407)\n",
      "(1865, 408)\n",
      "(1865, 409)\n",
      "(1865, 410)\n",
      "(1865, 411)\n",
      "(1865, 412)\n",
      "(1865, 413)\n",
      "(1865, 414)\n",
      "(1865, 415)\n",
      "(1865, 416)\n",
      "(1865, 417)\n",
      "(1865, 418)\n",
      "(1865, 419)\n",
      "(1865, 420)\n",
      "(1865, 421)\n",
      "(1865, 422)\n",
      "(1865, 423)\n",
      "(1865, 424)\n",
      "(1865, 425)\n",
      "(1865, 426)\n",
      "(1865, 427)\n",
      "(1865, 428)\n",
      "(1865, 429)\n",
      "(1865, 430)\n",
      "(1865, 431)\n",
      "(1865, 432)\n",
      "(1865, 433)\n",
      "(1865, 434)\n",
      "(1865, 435)\n",
      "(1865, 436)\n",
      "(1865, 437)\n",
      "(1865, 438)\n",
      "(1865, 439)\n",
      "(1865, 440)\n",
      "(1865, 441)\n",
      "(1865, 442)\n",
      "(1865, 443)\n",
      "(1865, 444)\n",
      "(1865, 445)\n",
      "(1865, 446)\n",
      "(1865, 447)\n",
      "(1865, 448)\n",
      "(1865, 449)\n",
      "(1865, 450)\n",
      "(1865, 451)\n",
      "(1865, 452)\n",
      "(1865, 453)\n",
      "(1865, 454)\n",
      "(1865, 455)\n",
      "(1865, 456)\n",
      "(1865, 457)\n",
      "(1865, 458)\n",
      "(1865, 459)\n",
      "(1865, 460)\n",
      "(1865, 461)\n",
      "(1865, 462)\n",
      "(1865, 463)\n",
      "(1865, 464)\n",
      "(1865, 465)\n",
      "(1865, 466)\n",
      "(1865, 467)\n",
      "(1865, 468)\n",
      "(1865, 469)\n",
      "(1865, 470)\n",
      "(1865, 471)\n",
      "(1865, 472)\n",
      "(1865, 473)\n",
      "(1865, 474)\n",
      "(1865, 475)\n",
      "(1865, 476)\n",
      "(1865, 477)\n",
      "(1865, 478)\n",
      "(1865, 479)\n",
      "(1865, 480)\n",
      "(1865, 481)\n",
      "(1865, 482)\n",
      "(1865, 483)\n",
      "(1865, 484)\n",
      "(1865, 485)\n",
      "(1865, 486)\n",
      "(1865, 487)\n",
      "(1865, 488)\n",
      "(1865, 489)\n",
      "(1865, 490)\n",
      "(1865, 491)\n",
      "(1865, 492)\n",
      "(1865, 493)\n",
      "(1865, 494)\n",
      "(1865, 495)\n",
      "(1865, 496)\n",
      "(1865, 497)\n",
      "(1865, 498)\n",
      "(1865, 499)\n",
      "(1865, 500)\n",
      "(1865, 501)\n",
      "(1865, 502)\n",
      "(1865, 503)\n",
      "(1865, 504)\n",
      "(1865, 505)\n",
      "(1865, 506)\n",
      "(1865, 507)\n",
      "(1865, 508)\n",
      "(1865, 509)\n",
      "(1865, 510)\n",
      "(1865, 511)\n",
      "(1865, 512)\n",
      "(1865, 513)\n",
      "(1865, 514)\n",
      "(1865, 515)\n",
      "(1865, 516)\n",
      "(1865, 517)\n",
      "(1865, 518)\n",
      "(1865, 519)\n",
      "(1865, 520)\n",
      "(1865, 521)\n",
      "(1865, 522)\n",
      "(1865, 523)\n",
      "(1865, 524)\n",
      "(1865, 525)\n",
      "(1865, 526)\n",
      "(1865, 527)\n",
      "(1865, 528)\n",
      "(1865, 529)\n",
      "(1865, 530)\n",
      "(1865, 531)\n",
      "(1865, 532)\n",
      "(1865, 533)\n",
      "(1865, 534)\n",
      "(1865, 535)\n",
      "(1865, 536)\n",
      "(1865, 537)\n",
      "(1865, 538)\n",
      "(1865, 539)\n",
      "(1865, 540)\n",
      "(1865, 541)\n",
      "(1865, 542)\n",
      "(1865, 543)\n",
      "(1865, 544)\n",
      "(1865, 545)\n",
      "(1865, 546)\n",
      "(1865, 547)\n",
      "(1865, 548)\n",
      "(1865, 549)\n",
      "(1865, 550)\n",
      "(1865, 551)\n",
      "(1865, 552)\n",
      "(1865, 553)\n",
      "(1865, 554)\n",
      "(1865, 555)\n",
      "(1865, 556)\n",
      "(1865, 557)\n",
      "(1865, 558)\n",
      "(1865, 559)\n",
      "(1865, 560)\n",
      "(1865, 561)\n",
      "(1865, 562)\n",
      "(1865, 563)\n",
      "(1865, 564)\n",
      "(1865, 565)\n",
      "(1865, 566)\n",
      "(1865, 567)\n",
      "(1865, 568)\n",
      "(1865, 569)\n",
      "(1865, 570)\n",
      "(1865, 571)\n",
      "(1865, 572)\n",
      "(1865, 573)\n",
      "(1865, 574)\n",
      "(1865, 575)\n",
      "(1865, 576)\n",
      "(1865, 577)\n",
      "(1865, 578)\n",
      "(1865, 579)\n",
      "(1865, 580)\n",
      "(1865, 581)\n",
      "(1865, 582)\n",
      "(1865, 583)\n",
      "(1865, 584)\n",
      "(1865, 585)\n",
      "(1865, 586)\n",
      "(1865, 587)\n",
      "(1865, 588)\n",
      "(1865, 589)\n",
      "(1865, 590)\n",
      "(1865, 591)\n",
      "(1865, 592)\n",
      "(1865, 593)\n",
      "(1865, 594)\n",
      "(1865, 595)\n",
      "(1865, 596)\n",
      "(1865, 597)\n",
      "(1865, 598)\n",
      "(1865, 599)\n",
      "(1865, 600)\n",
      "(1865, 601)\n",
      "(1865, 602)\n",
      "(1865, 603)\n",
      "(1865, 604)\n",
      "(1865, 605)\n",
      "(1865, 606)\n",
      "(1865, 607)\n",
      "(1865, 608)\n",
      "(1865, 609)\n",
      "(1865, 610)\n",
      "(1865, 611)\n",
      "(1865, 612)\n",
      "(1865, 613)\n",
      "(1865, 614)\n",
      "(1865, 615)\n",
      "(1865, 616)\n",
      "(1865, 617)\n",
      "(1865, 618)\n",
      "(1865, 619)\n",
      "(1865, 620)\n",
      "(1865, 621)\n",
      "(1865, 622)\n",
      "(1865, 623)\n",
      "(1865, 624)\n",
      "(1865, 625)\n",
      "(1865, 626)\n",
      "(1865, 627)\n",
      "(1865, 628)\n",
      "(1865, 629)\n",
      "(1865, 630)\n",
      "(1865, 631)\n",
      "(1865, 632)\n",
      "(1865, 633)\n",
      "(1865, 634)\n",
      "(1865, 635)\n",
      "(1865, 636)\n",
      "(1865, 637)\n",
      "(1865, 638)\n",
      "(1865, 639)\n",
      "(1865, 640)\n",
      "(1865, 641)\n",
      "(1865, 642)\n",
      "(1865, 643)\n",
      "(1865, 644)\n",
      "(1865, 645)\n",
      "(1865, 646)\n",
      "(1865, 647)\n",
      "(1865, 648)\n",
      "(1865, 649)\n",
      "(1865, 650)\n",
      "(1865, 651)\n",
      "(1865, 652)\n",
      "(1865, 653)\n",
      "(1865, 654)\n",
      "(1865, 655)\n",
      "(1865, 656)\n",
      "(1865, 657)\n",
      "(1865, 658)\n",
      "(1865, 659)\n",
      "(1865, 660)\n",
      "(1865, 661)\n",
      "(1865, 662)\n",
      "(1865, 663)\n",
      "(1865, 664)\n",
      "(1865, 665)\n",
      "(1865, 666)\n",
      "(1865, 667)\n",
      "(1865, 668)\n",
      "(1865, 669)\n",
      "(1865, 670)\n",
      "(1865, 671)\n",
      "(1865, 672)\n",
      "(1865, 673)\n",
      "(1865, 674)\n",
      "(1865, 675)\n",
      "(1865, 676)\n",
      "(1865, 677)\n",
      "(1865, 678)\n",
      "(1865, 679)\n",
      "(1865, 680)\n",
      "(1865, 681)\n",
      "(1865, 682)\n",
      "(1865, 683)\n",
      "(1865, 684)\n",
      "(1865, 685)\n",
      "(1865, 686)\n",
      "(1865, 687)\n",
      "(1865, 688)\n",
      "(1865, 689)\n",
      "(1865, 690)\n",
      "(1865, 691)\n",
      "(1865, 692)\n",
      "(1865, 693)\n",
      "(1865, 694)\n",
      "(1865, 695)\n",
      "(1865, 696)\n",
      "(1865, 697)\n",
      "(1865, 698)\n",
      "(1865, 699)\n",
      "(1865, 700)\n",
      "(1865, 701)\n",
      "(1865, 702)\n",
      "(1865, 703)\n",
      "(1865, 704)\n",
      "(1865, 705)\n",
      "(1865, 706)\n",
      "(1865, 707)\n",
      "(1865, 708)\n",
      "(1865, 709)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1865, 710)\n",
      "(1865, 711)\n",
      "(1865, 712)\n",
      "(1865, 713)\n",
      "(1865, 714)\n",
      "(1865, 715)\n",
      "(1865, 716)\n",
      "(1865, 717)\n",
      "(1865, 718)\n",
      "(1865, 719)\n",
      "(1865, 720)\n",
      "(1865, 721)\n",
      "(1865, 722)\n",
      "(1865, 723)\n",
      "(1865, 724)\n",
      "(1865, 725)\n",
      "(1865, 726)\n",
      "(1865, 727)\n",
      "(1865, 728)\n",
      "(1865, 729)\n",
      "(1865, 730)\n",
      "(1865, 731)\n",
      "(1865, 732)\n",
      "(1865, 733)\n",
      "(1865, 734)\n",
      "(1865, 735)\n",
      "(1865, 736)\n",
      "(1865, 737)\n",
      "(1865, 738)\n",
      "(1865, 739)\n",
      "(1865, 740)\n",
      "(1865, 741)\n",
      "(1865, 742)\n",
      "(1865, 743)\n",
      "(1865, 744)\n",
      "(1865, 745)\n",
      "(1865, 746)\n",
      "(1865, 747)\n",
      "(1865, 748)\n",
      "(1865, 749)\n",
      "(1865, 750)\n",
      "(1865, 751)\n",
      "(1865, 752)\n",
      "(1865, 753)\n",
      "(1865, 754)\n",
      "(1865, 755)\n",
      "(1865, 756)\n",
      "(1865, 757)\n",
      "(1865, 758)\n",
      "(1865, 759)\n",
      "(1865, 760)\n",
      "(1865, 761)\n",
      "(1865, 762)\n",
      "(1865, 763)\n",
      "(1865, 764)\n",
      "(1865, 765)\n",
      "(1865, 766)\n",
      "(1865, 767)\n",
      "(1865, 768)\n",
      "(1865, 769)\n",
      "(1865, 770)\n",
      "(1865, 771)\n",
      "(1865, 772)\n",
      "(1865, 773)\n",
      "(1865, 774)\n",
      "(1865, 775)\n",
      "(1865, 776)\n",
      "(1865, 777)\n",
      "(1865, 778)\n",
      "(1865, 779)\n",
      "(1865, 780)\n",
      "(1865, 781)\n",
      "(1865, 782)\n",
      "(1865, 783)\n",
      "(1865, 784)\n",
      "(1865, 785)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'analytic 0.12770000000000223'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'analytic 0.12770000000000223'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d7ca12e1ecf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mNormX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'analytic '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mMixedF00\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phi0 minus delta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2938\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3624\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3625\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# insert to the axis; this could possibly raise a TypeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item)\u001b[0m\n\u001b[1;32m   4989\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coerce_scalar_to_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4990\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_self\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4991\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy_with_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_shallow_copy_with_infer\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 \u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_cast_data_without_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                     return cls(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_maybe_cast_data_without_dtype\u001b[0;34m(subarr)\u001b[0m\n\u001b[1;32m   5484\u001b[0m     )\n\u001b[1;32m   5485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5486\u001b[0;31m     \u001b[0minferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5488\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minferred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"integer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "MMS = MinMaxScaler()\n",
    "\n",
    "NormX = pd.DataFrame(MMS.fit_transform(MixedF00.iloc[:,[0, 3, 4, 5, 6, 7, 9, 10]]), columns = MixedF00.iloc[:,[0, 3, 4, 5, 6, 7, 9, 10]].columns)\n",
    "\n",
    "\n",
    "y = MixedF00['señal']\n",
    "\n",
    "for i in np.arange(0.05, 0.5, 0.0001):\n",
    "    NormX['analytic ' + str(i)] = (i**2)/MixedF00['phi0 minus delta']\n",
    "\n",
    "                        \n",
    "    print(NormX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through possible values of phi_0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "RF = RandomForestRegressor()\n",
    "\n",
    "\n",
    "ScoresRF = []\n",
    "for i in np.arange(8, NormX.shape[1]):\n",
    "\n",
    "    x = NormX.iloc[:,[0, 1, 2, 3, 4, 5, 6, 7, i]]\n",
    "    print(i)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    RF.fit(x_train, y_train)\n",
    "    ScoresRF.append((mean_absolute_error(RF.predict(x_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(ScoresRF).sort_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(RF.feature_importances_, index=x_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "GB = GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "ScoresGB = []\n",
    "for i in np.arange(6, NormX.shape[1]):\n",
    "\n",
    "    x = NormX.iloc[:,[0, 1, 2, 3, 4, 5, 6, 7, i]]\n",
    "    print(i)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    GB.fit(x_train, y_train)\n",
    "    ScoresGB.append((mean_absolute_error(GB.predict(x_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(ScoresGB).sort_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(GB.feature_importances_, index=x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x1 = NormX.iloc[:,[0, 1, 2, 3, 4, 5, 6, int(pd.DataFrame(ScoresRF).sort_values(0).iloc[[0],[0]].index.to_numpy())]]\n",
    "x2 = NormX.iloc[:,[0, 1, 2, 3, 4, 5, 6, int(pd.DataFrame(ScoresGB).sort_values(0).iloc[[0],[0]].index.to_numpy())]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x1, y, random_state=15)\n",
    "\n",
    "RF.fit(x_train, y_train)\n",
    "RFC = RF.predict(x_test)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x2, y, random_state=15)\n",
    "\n",
    "GB.fit(x_train, y_train)\n",
    "GBC = GB.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToREP = pd.DataFrame()\n",
    "ToREP['Analytic Function'] =  np.ravel(x_test.iloc[:,[-1]].to_numpy())\n",
    "ToREP['Signal'] = y_test.to_numpy()\n",
    "ToREP['GB'] =  GBC\n",
    "ToREP['RF'] = RFC\n",
    "\n",
    "NormREP = pd.DataFrame(MMS.fit_transform(ToREP), columns = ToREP.columns, index=x_test.index)\n",
    "NormREP.sort_index().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormX = NormX.iloc[:,[0, 1, 2, 3, 4, 5, 6, int(pd.DataFrame(ScoresRF).sort_values(0).iloc[[0],[0]].index.to_numpy())]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Rho = []\n",
    "Rho.append(MixedF00['r']/MixedF00['Z'])\n",
    "\n",
    "NormX['Rho'] = np.abs(np.ravel(Rho))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "MMS = MinMaxScaler()\n",
    "\n",
    "SecondNormX = pd.DataFrame(MMS.fit_transform(NormX), columns = NormX.columns)\n",
    "\n",
    "del NormX\n",
    "\n",
    "y = MixedF00['señal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating through possible values for h's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating equations using h')\n",
    "\n",
    "for k in np.linspace(100, 200, 12):\n",
    "    for l in np.linspace(-6000, -3000, 12):\n",
    "        for m in np.linspace(40000, 70000, 12):\n",
    "            for n in np.linspace(-400000, -150000, 12):\n",
    "                for ñ in np.linspace(800000, 300000, 12):\n",
    "        \n",
    "        \n",
    "                    SecondNormX['analytic ' + str(k)+' ' + str(l)+' ' + str(m)+' ' + str(n)+' ' + str(ñ)] = (SecondNormX.iloc[:,[7]]*(1+SecondNormX['Rho'].to_numpy()**2)*(k*SecondNormX['Rho'].to_numpy()+l*SecondNormX['Rho'].to_numpy()+m*SecondNormX['Rho'].to_numpy()+n*SecondNormX['Rho'].to_numpy()+ñ*SecondNormX['Rho'].to_numpy()))\n",
    "\n",
    "                        \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests for h's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "SecondRF = RandomForestRegressor()\n",
    "\n",
    "print('Using Random Forest through the possible equations')\n",
    "Scores = []\n",
    "for i in np.arange(9, SecondNormX.shape[1]):\n",
    "\n",
    "    x = SecondNormX.iloc[:,[0, 1, 2, 3, 4, 5, 6, 7, 8, i]]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    SecondRF.fit(x_train, y_train)\n",
    "    Scores.append((mean_absolute_error(SecondRF.predict(x_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save best result and error associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LastX = SecondNormX.iloc[:,[0, 1, 2, 3, 4, 5, 6, 7, 8, int(pd.DataFrame(Scores).sort_values(0).iloc[[0],[0]].index.to_numpy())+8]]\n",
    "LastX.to_csv('Result.csv')\n",
    "\n",
    "pd.DataFrame(Scores).sort_values(0).iloc[[0],[0]].to_csv('Min_Error.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalizedLastX = pd.DataFrame(MMS.fit_transform(LastX), columns=LastX, index=LastX)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(NormalizedLastX, y, random_state=15)\n",
    "\n",
    "SecondRF.fit(x_train, y_train)\n",
    "RFC = SecondRF.predict(x_test)\n",
    "\n",
    "\n",
    "RFC.to_csv('BestRF_Result.csv')\n",
    "y_test.to_csv('y_test.csv')\n",
    "y_test.to_csv('x_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(GB.feature_importances_, index=x_test.columns)\n",
    "\n",
    "\n",
    "x1 = NormX.iloc[:,[0, 1, 2, 3, 4, 5, 6, int(pd.DataFrame(ScoresRF).sort_values(0).iloc[[0],[0]].index.to_numpy())]]\n",
    "x2 = NormX.iloc[:,[0, 1, 2, 3, 4, 5, 6, int(pd.DataFrame(ScoresGB).sort_values(0).iloc[[0],[0]].index.to_numpy())]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x1, y, random_state=15)\n",
    "\n",
    "RF.fit(x_train, y_train)\n",
    "RFC = RF.predict(x_test)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x2, y, random_state=15)\n",
    "\n",
    "GB.fit(x_train, y_train)\n",
    "GBC = GB.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Adamax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ModelDenseAdamax1 = Sequential()\n",
    "ModelDenseAdamax1.add(Dense(14))\n",
    "ModelDenseAdamax1.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdamax1.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdamax1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax1.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax1.fit(x_train.values, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseAdamaxPrediction1 = ModelDenseAdamax1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ModelDenseAdamax1_1 = Sequential()\n",
    "ModelDenseAdamax1_1.add(Dense(14))\n",
    "ModelDenseAdamax1_1.add(Dropout(0.1))\n",
    "ModelDenseAdamax1_1.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdamax1_1.add(Dropout(0.1))\n",
    "ModelDenseAdamax1_1.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdamax1_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax1_1.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax1_1.fit(x_train.values, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseAdamaxPrediction1_1 = ModelDenseAdamax1_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction1_1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseAdamax2 = Sequential()\n",
    "ModelDenseAdamax2.add(Dense(14))\n",
    "ModelDenseAdamax2.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdamax2.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdamax2.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax2.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax2.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax2.summary()\n",
    "\n",
    "DenseAdamaxPrediction2 = ModelDenseAdamax2.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction2, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelDenseAdamax2_1 = Sequential()\n",
    "ModelDenseAdamax2_1.add(Dense(14))\n",
    "ModelDenseAdamax2_1.add(Dropout(0.1))\n",
    "ModelDenseAdamax2_1.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdamax2_1.add(Dropout(0.1))\n",
    "ModelDenseAdamax2_1.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdamax2_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax2_1.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax2_1.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax2_1.summary()\n",
    "\n",
    "DenseAdamaxPrediction2_1 = ModelDenseAdamax2_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction2_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseAdamax3 = Sequential()\n",
    "ModelDenseAdamax3.add(Dense(14))\n",
    "ModelDenseAdamax3.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdamax3.add(Dense(7, activation='selu'))\n",
    "ModelDenseAdamax3.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax3.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax3.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax3.summary()\n",
    "\n",
    "DenseAdamaxPrediction3 = ModelDenseAdamax3.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction3, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseAdamax4 = Sequential()\n",
    "ModelDenseAdamax4.add(Dense(14))\n",
    "ModelDenseAdamax4.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdamax4.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdamax4.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax4.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax4.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax4.summary()\n",
    "\n",
    "DenseAdamaxPrediction4 = ModelDenseAdamax4.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction4, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseAdamax5 = Sequential()\n",
    "ModelDenseAdamax5.add(Dense(14))\n",
    "ModelDenseAdamax5.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdamax5.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdamax5.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax5.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax5.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax5.summary()\n",
    "\n",
    "DenseAdamaxPrediction5 = ModelDenseAdamax5.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction5, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseAdamax6 = Sequential()\n",
    "ModelDenseAdamax6.add(Dense(14))\n",
    "ModelDenseAdamax6.add(Dense(70))\n",
    "ModelDenseAdamax6.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdamax6.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax6.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax6.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax6.summary()\n",
    "\n",
    "DenseAdamaxPrediction6 = ModelDenseAdamax6.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction6, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseAdamax6_1 = Sequential()\n",
    "ModelDenseAdamax6_1.add(Dense(14))\n",
    "ModelDenseAdamax6_1.add(Dropout(0.1))\n",
    "ModelDenseAdamax6_1.add(Dense(70))\n",
    "ModelDenseAdamax6_1.add(Dropout(0.1))\n",
    "ModelDenseAdamax6_1.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdamax6_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax6_1.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax6_1.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax6_1.summary()\n",
    "\n",
    "DenseAdamaxPrediction6_1 = ModelDenseAdamax6_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction6_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseAdamax7 = Sequential()\n",
    "ModelDenseAdamax7.add(Dense(14))\n",
    "ModelDenseAdamax7.add(Dense(192, activation='relu'))\n",
    "ModelDenseAdamax7.add(Dense(24, activation='relu'))\n",
    "ModelDenseAdamax7.add(Dense(9, activation='relu'))\n",
    "ModelDenseAdamax7.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax7.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax7.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax7.summary()\n",
    "\n",
    "DenseAdamaxPrediction7 = ModelDenseAdamax7.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction7, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ModelDenseRMSprop1 = Sequential()\n",
    "ModelDenseRMSprop1.add(Dense(14))\n",
    "ModelDenseRMSprop1.add(Dense(70, activation='relu'))\n",
    "ModelDenseRMSprop1.add(Dense(7, activation='relu'))\n",
    "ModelDenseRMSprop1.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop1.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop1.fit(x_train.values, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseRMSpropPrediction1 = ModelDenseRMSprop1.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ModelDenseRMSprop1_1 = Sequential()\n",
    "ModelDenseRMSprop1_1.add(Dense(14))\n",
    "ModelDenseRMSprop1_1.add(Dropout(0.1))\n",
    "ModelDenseRMSprop1_1.add(Dense(70, activation='relu'))\n",
    "ModelDenseRMSprop1_1.add(Dropout(0.1))\n",
    "ModelDenseRMSprop1_1.add(Dense(7, activation='relu'))\n",
    "ModelDenseRMSprop1_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop1_1.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop1_1.fit(x_train.values, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseRMSpropPrediction1_1 = ModelDenseRMSprop1_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction1_1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseRMSprop2 = Sequential()\n",
    "ModelDenseRMSprop2.add(Dense(14))\n",
    "ModelDenseRMSprop2.add(Dense(70, activation='relu'))\n",
    "ModelDenseRMSprop2.add(Dense(7, activation='elu'))\n",
    "ModelDenseRMSprop2.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop2.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop2.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop2.summary()\n",
    "\n",
    "DenseRMSpropPrediction2 = ModelDenseRMSprop2.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction2, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelDenseRMSprop2_1 = Sequential()\n",
    "ModelDenseRMSprop2_1.add(Dense(14))\n",
    "ModelDenseRMSprop2_1.add(Dropout(0.1))\n",
    "ModelDenseRMSprop2_1.add(Dense(70, activation='relu'))\n",
    "ModelDenseRMSprop2_1.add(Dropout(0.1))\n",
    "ModelDenseRMSprop2_1.add(Dense(7, activation='elu'))\n",
    "ModelDenseRMSprop2_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop2_1.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop2_1.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop2_1.summary()\n",
    "\n",
    "DenseRMSpropPrediction2_1 = ModelDenseRMSprop2_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction2_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseRMSprop3 = Sequential()\n",
    "ModelDenseRMSprop3.add(Dense(14))\n",
    "ModelDenseRMSprop3.add(Dense(70, activation='relu'))\n",
    "ModelDenseRMSprop3.add(Dense(7, activation='selu'))\n",
    "ModelDenseRMSprop3.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop3.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop3.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop3.summary()\n",
    "\n",
    "DenseRMSpropPrediction3 = ModelDenseRMSprop3.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction3, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseRMSprop4 = Sequential()\n",
    "ModelDenseRMSprop4.add(Dense(14))\n",
    "ModelDenseRMSprop4.add(Dense(70, activation='relu'))\n",
    "ModelDenseRMSprop4.add(Dense(7, activation='elu'))\n",
    "ModelDenseRMSprop4.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop4.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop4.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop4.summary()\n",
    "\n",
    "DenseRMSpropPrediction4 = ModelDenseRMSprop4.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction4, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseRMSprop5 = Sequential()\n",
    "ModelDenseRMSprop5.add(Dense(14))\n",
    "ModelDenseRMSprop5.add(Dense(70, activation='relu'))\n",
    "ModelDenseRMSprop5.add(Dense(7, activation='elu'))\n",
    "ModelDenseRMSprop5.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop5.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop5.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop5.summary()\n",
    "\n",
    "DenseRMSpropPrediction5 = ModelDenseRMSprop5.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction5, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseRMSprop6 = Sequential()\n",
    "ModelDenseRMSprop6.add(Dense(14))\n",
    "ModelDenseRMSprop6.add(Dense(70))\n",
    "ModelDenseRMSprop6.add(Dense(7, activation='relu'))\n",
    "ModelDenseRMSprop6.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop6.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop6.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop6.summary()\n",
    "\n",
    "DenseRMSpropPrediction6 = ModelDenseRMSprop6.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction6, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseRMSprop6_1 = Sequential()\n",
    "ModelDenseRMSprop6_1.add(Dense(14))\n",
    "ModelDenseRMSprop6_1.add(Dropout(0.1))\n",
    "ModelDenseRMSprop6_1.add(Dense(70))\n",
    "ModelDenseRMSprop6_1.add(Dropout(0.1))\n",
    "ModelDenseRMSprop6_1.add(Dense(7, activation='relu'))\n",
    "ModelDenseRMSprop6_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop6_1.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop6_1.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop6_1.summary()\n",
    "\n",
    "DenseRMSpropPrediction6_1 = ModelDenseRMSprop6_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction6_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseRMSprop7 = Sequential()\n",
    "ModelDenseRMSprop7.add(Dense(14))\n",
    "ModelDenseRMSprop7.add(Dense(192, activation='relu'))\n",
    "ModelDenseRMSprop7.add(Dense(24, activation='relu'))\n",
    "ModelDenseRMSprop7.add(Dense(9, activation='relu'))\n",
    "ModelDenseRMSprop7.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop7.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop7.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop7.summary()\n",
    "\n",
    "DenseRMSpropPrediction7 = ModelDenseRMSprop7.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction7, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ModelDenseAdam1 = Sequential()\n",
    "ModelDenseAdam1.add(Dense(14))\n",
    "ModelDenseAdam1.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdam1.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdam1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam1.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam1.fit(x_train.values, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseAdamPrediction1 = ModelDenseAdam1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ModelDenseAdam1_1 = Sequential()\n",
    "ModelDenseAdam1_1.add(Dense(14))\n",
    "ModelDenseAdam1_1.add(Dropout(0.1))\n",
    "ModelDenseAdam1_1.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdam1_1.add(Dropout(0.1))\n",
    "ModelDenseAdam1_1.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdam1_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam1_1.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam1_1.fit(x_train.values, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseAdamPrediction1_1 = ModelDenseAdam1_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction1_1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseAdam2 = Sequential()\n",
    "ModelDenseAdam2.add(Dense(14))\n",
    "ModelDenseAdam2.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdam2.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdam2.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam2.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam2.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam2.summary()\n",
    "\n",
    "DenseAdamPrediction2 = ModelDenseAdam2.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction2, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelDenseAdam2_1 = Sequential()\n",
    "ModelDenseAdam2_1.add(Dense(14))\n",
    "ModelDenseAdam2_1.add(Dropout(0.1))\n",
    "ModelDenseAdam2_1.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdam2_1.add(Dropout(0.1))\n",
    "ModelDenseAdam2_1.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdam2_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam2_1.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam2_1.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam2_1.summary()\n",
    "\n",
    "DenseAdamPrediction2_1 = ModelDenseAdam2_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction2_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseAdam3 = Sequential()\n",
    "ModelDenseAdam3.add(Dense(14))\n",
    "ModelDenseAdam3.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdam3.add(Dense(7, activation='selu'))\n",
    "ModelDenseAdam3.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam3.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam3.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam3.summary()\n",
    "\n",
    "DenseAdamPrediction3 = ModelDenseAdam3.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction3, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseAdam4 = Sequential()\n",
    "ModelDenseAdam4.add(Dense(14))\n",
    "ModelDenseAdam4.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdam4.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdam4.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam4.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam4.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam4.summary()\n",
    "\n",
    "DenseAdamPrediction4 = ModelDenseAdam4.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction4, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseAdam5 = Sequential()\n",
    "ModelDenseAdam5.add(Dense(14))\n",
    "ModelDenseAdam5.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdam5.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdam5.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam5.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam5.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam5.summary()\n",
    "\n",
    "DenseAdamPrediction5 = ModelDenseAdam5.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction5, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseAdam6 = Sequential()\n",
    "ModelDenseAdam6.add(Dense(14))\n",
    "ModelDenseAdam6.add(Dense(70))\n",
    "ModelDenseAdam6.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdam6.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam6.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam6.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam6.summary()\n",
    "\n",
    "DenseAdamPrediction6 = ModelDenseAdam6.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction6, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseAdam6_1 = Sequential()\n",
    "ModelDenseAdam6_1.add(Dense(14))\n",
    "ModelDenseAdam6_1.add(Dropout(0.1))\n",
    "ModelDenseAdam6_1.add(Dense(70))\n",
    "ModelDenseAdam6_1.add(Dropout(0.1))\n",
    "ModelDenseAdam6_1.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdam6_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam6_1.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam6_1.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam6_1.summary()\n",
    "\n",
    "DenseAdamPrediction6_1 = ModelDenseAdam6_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction6_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelDenseAdam7 = Sequential()\n",
    "ModelDenseAdam7.add(Dense(14))\n",
    "ModelDenseAdam7.add(Dense(192, activation='relu'))\n",
    "ModelDenseAdam7.add(Dense(24, activation='relu'))\n",
    "ModelDenseAdam7.add(Dense(9, activation='relu'))\n",
    "ModelDenseAdam7.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam7.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam7.fit(x_train, y_train.values, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam7.summary()\n",
    "\n",
    "DenseAdamPrediction7 = ModelDenseAdam7.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction7, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.iloc[:,-1:].sort_index().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scores).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scores).sort_values(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestResult = pd.read_csv('Result.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "RF = RandomForestRegressor()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(BestResult, y)\n",
    "\n",
    "RF.fit(x_train, y_train)\n",
    "\n",
    "RFResult = RF.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "GB = GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "GB.fit(x_train, y_train)\n",
    "\n",
    "GBResult = GB.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=Data<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "Data",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "Data",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          2,
          4,
          6,
          7,
          10,
          15,
          23,
          31,
          42,
          44,
          45,
          47,
          51,
          55,
          61,
          62,
          67,
          68,
          71,
          77,
          87,
          93,
          96,
          97,
          101,
          109,
          115,
          122,
          123,
          125,
          126,
          129,
          136,
          154,
          155,
          157,
          159,
          160,
          165,
          167,
          179,
          183,
          186,
          197,
          202,
          210,
          212,
          219,
          223,
          229,
          230,
          232,
          234,
          237,
          243,
          244,
          245,
          248,
          251,
          252,
          253,
          256,
          261,
          266,
          270,
          272,
          273,
          274,
          275,
          278,
          295,
          298,
          299,
          302,
          303,
          310,
          313,
          320,
          324,
          325,
          335,
          340,
          343,
          344,
          345,
          357,
          363,
          371,
          373,
          381,
          385,
          386,
          393,
          398,
          402,
          410,
          412,
          418,
          419,
          422,
          430,
          431,
          437,
          438,
          454,
          455,
          457,
          461,
          463,
          464,
          471,
          475,
          476,
          477,
          478,
          479,
          481,
          483,
          485,
          486,
          488,
          498,
          503,
          504,
          513,
          515,
          517,
          527,
          530,
          532,
          534,
          538,
          542,
          544,
          547,
          553,
          564,
          565,
          571,
          572,
          573,
          576,
          582,
          586,
          587,
          591,
          599,
          605,
          611,
          614,
          626,
          627,
          631,
          635,
          636,
          639,
          641,
          651,
          659,
          660,
          661,
          664,
          669,
          671,
          675,
          676,
          679,
          681,
          686,
          688,
          690,
          701,
          703,
          708,
          710,
          712,
          713,
          714,
          718,
          720,
          722,
          724,
          731,
          736,
          739,
          744,
          749,
          750,
          751,
          758,
          764,
          770,
          771,
          778,
          782,
          783,
          793,
          794,
          795,
          798,
          803,
          815,
          818,
          819,
          825,
          827,
          834,
          837,
          842,
          843,
          848,
          849,
          856,
          867,
          872,
          873,
          876,
          877,
          879,
          886,
          888,
          889,
          890,
          895,
          902,
          903,
          906,
          921,
          922,
          923,
          925,
          930,
          935,
          937,
          940,
          944,
          945,
          949,
          950,
          959,
          963,
          964,
          967,
          969,
          975,
          976,
          979,
          982,
          983,
          995,
          1001,
          1002,
          1004,
          1008,
          1012,
          1014,
          1019,
          1022,
          1031,
          1033,
          1040,
          1041,
          1044,
          1047,
          1052,
          1057,
          1058,
          1059,
          1060,
          1062,
          1065,
          1069,
          1070,
          1071,
          1074,
          1085,
          1089,
          1092,
          1099,
          1102,
          1115,
          1117,
          1118,
          1121,
          1130,
          1133,
          1135,
          1138,
          1139,
          1141,
          1148,
          1155,
          1158,
          1162,
          1167,
          1168,
          1169,
          1170,
          1175,
          1177,
          1180,
          1183,
          1189,
          1193,
          1195,
          1197,
          1205,
          1206,
          1210,
          1212,
          1215,
          1218,
          1220,
          1222,
          1225,
          1226,
          1230,
          1231,
          1233,
          1234,
          1235,
          1239,
          1242,
          1244,
          1246,
          1251,
          1259,
          1262,
          1268,
          1270,
          1271,
          1275,
          1279,
          1280,
          1282,
          1284,
          1293,
          1301,
          1309,
          1310,
          1312,
          1318,
          1324,
          1333,
          1334,
          1350,
          1352,
          1356,
          1357,
          1361,
          1366,
          1370,
          1371,
          1374,
          1387,
          1388,
          1392,
          1393,
          1408,
          1409,
          1413,
          1414,
          1416,
          1417,
          1421,
          1425,
          1426,
          1431,
          1435,
          1437,
          1440,
          1450,
          1460,
          1466,
          1467,
          1469,
          1486,
          1495,
          1497,
          1501,
          1502,
          1505,
          1507,
          1511,
          1530,
          1531,
          1535,
          1537,
          1541,
          1549,
          1554,
          1558,
          1564,
          1565,
          1566,
          1568,
          1570,
          1573,
          1582,
          1584,
          1588,
          1596,
          1597,
          1598,
          1602,
          1604,
          1607,
          1609,
          1611,
          1613,
          1615,
          1616,
          1621,
          1628,
          1630,
          1631,
          1642,
          1644,
          1645,
          1651,
          1658,
          1661,
          1662,
          1663,
          1665,
          1666,
          1668,
          1670,
          1671,
          1680,
          1690,
          1696,
          1700,
          1701,
          1703,
          1710,
          1711,
          1713,
          1717,
          1725,
          1729,
          1738,
          1742,
          1743,
          1753,
          1759,
          1769,
          1771,
          1773,
          1775,
          1789,
          1799,
          1800,
          1804,
          1808,
          1815,
          1816,
          1819,
          1828,
          1833,
          1837,
          1849,
          1850,
          1851,
          1854,
          1862
         ],
         "xaxis": "x",
         "y": [
          0.73831,
          1.4552,
          2.0626,
          2.5855,
          2.7917,
          3.05,
          3.0553,
          3.0621,
          2.569,
          0.98244,
          1.0898,
          1.0987,
          1.1008,
          1.1025,
          1.1036,
          1.0998,
          1.0995,
          1.0968,
          1.0984,
          1.1032,
          1.1021,
          0.535,
          0.8968799999999999,
          0.9022399999999999,
          0.90389,
          0.9065700000000001,
          0.90636,
          0.90009,
          0.89243,
          0.8909799999999999,
          0.88974,
          0.88771,
          0.88561,
          0.8936700000000001,
          0.90743,
          0.90807,
          0.9065200000000001,
          0.90138,
          0.8974700000000001,
          0.63071,
          0.54093,
          0.78492,
          0.78668,
          0.78638,
          0.78254,
          0.78087,
          0.77742,
          0.77644,
          0.77367,
          0.77082,
          0.7627,
          0.76059,
          0.75956,
          0.7585,
          0.75573,
          0.75271,
          0.75364,
          0.7532,
          0.7572800000000001,
          0.75942,
          0.76017,
          0.75998,
          0.76658,
          0.772,
          0.77446,
          0.7762399999999999,
          0.77674,
          0.77685,
          0.77772,
          0.77841,
          0.78008,
          0.786,
          0.7861,
          0.78689,
          0.78601,
          0.7864899999999999,
          0.7089,
          0.6539699999999999,
          2.7817,
          2.9268,
          2.9248,
          2.9248,
          2.7784,
          1.9535,
          1.6309,
          1.2951,
          1.1551,
          1.1568,
          1.1512,
          1.1501,
          1.1553,
          1.1537,
          1.1538,
          0.9012,
          0.65976,
          0.9341299999999999,
          0.95278,
          0.9538399999999999,
          0.95337,
          0.95134,
          0.9464100000000001,
          0.93891,
          0.93606,
          0.9321200000000001,
          0.93311,
          0.95236,
          0.95258,
          0.9528,
          0.95281,
          0.9503299999999999,
          0.94909,
          0.89731,
          0.54169,
          0.51143,
          0.5979899999999999,
          0.6822600000000001,
          0.75035,
          0.81192,
          0.82086,
          0.82245,
          0.82335,
          0.8245899999999999,
          0.82481,
          0.82176,
          0.82204,
          0.81892,
          0.8177399999999999,
          0.81657,
          0.8122699999999999,
          0.81138,
          0.80937,
          0.80687,
          0.79979,
          0.7972899999999999,
          0.79535,
          0.79063,
          0.7948,
          0.8063100000000001,
          0.8072199999999999,
          0.81221,
          0.81318,
          0.81353,
          0.81498,
          0.81609,
          0.81872,
          0.81858,
          0.82004,
          0.8226700000000001,
          0.8239200000000001,
          0.8226700000000001,
          0.81955,
          1.9573,
          2.2572,
          3.2963,
          3.629,
          3.6347,
          3.639,
          3.6393,
          3.6114,
          1.7347,
          1.3574,
          0.9063200000000001,
          0.76756,
          1.4611,
          1.5222,
          1.528,
          1.5295,
          1.528,
          1.5305,
          1.5263,
          1.5251,
          1.5207,
          1.5299,
          1.529,
          1.3705,
          1.0894,
          0.80479,
          0.64283,
          0.5012,
          0.89956,
          1.1299,
          1.2371,
          1.2475,
          1.2566,
          1.2585,
          1.2562,
          1.2487,
          1.2387,
          1.2391,
          1.2387,
          1.2297,
          1.2365,
          1.2429,
          1.2454,
          1.2587,
          1.26,
          1.2607,
          1.0347,
          0.91755,
          0.80872,
          0.5512699999999999,
          1.0386,
          1.0838,
          1.0853,
          1.0845,
          1.0829,
          1.0811,
          1.0774,
          1.0767,
          1.0732,
          1.0728,
          1.0703,
          1.0686,
          1.0649,
          1.0452,
          1.0411,
          1.0383,
          1.0393,
          1.0413,
          1.042,
          1.0506,
          1.0546,
          1.0578,
          1.059,
          1.0659,
          1.071,
          1.0713,
          1.074,
          1.0819,
          1.0823,
          1.0836,
          1.0841,
          1.085,
          1.0851,
          1.0848,
          1.0728,
          0.8058,
          0.7094699999999999,
          1.152,
          1.5164,
          4.041,
          4.0382,
          4.0396,
          4.0396,
          4.0465,
          3.8907,
          3.635,
          2.5568,
          1.3817,
          0.98345,
          1.6006,
          1.6032,
          1.6052,
          1.6032,
          1.5963,
          1.5969,
          1.6015,
          1.603,
          1.6005,
          1.166,
          0.86634,
          1.0325,
          1.1485,
          1.3036,
          1.3117,
          1.3205,
          1.3207,
          1.3202,
          1.3202,
          1.3182,
          1.3142,
          1.3067,
          1.3023,
          1.3019,
          1.3011,
          1.2945,
          1.3022,
          1.307,
          1.3164,
          1.3222,
          1.3212,
          0.8426100000000001,
          0.59611,
          0.50268,
          0.8227,
          1.1371,
          1.1393,
          1.1392,
          1.139,
          1.1397,
          1.1394,
          1.1349,
          1.1307,
          1.1293,
          1.1266,
          1.1245,
          1.1236,
          1.1227,
          1.1214,
          1.1177,
          1.1143,
          1.1069,
          1.1025,
          1.0946,
          1.0913,
          1.0925,
          1.0958,
          1.1051,
          1.1063,
          1.1169,
          1.1193,
          1.121,
          1.1243,
          1.1245,
          1.1253,
          1.1269,
          1.128,
          1.1306,
          1.1308,
          1.1309,
          1.132,
          1.1321,
          1.1337,
          1.1357,
          1.1362,
          1.1366,
          1.1364,
          1.1262,
          1.0221,
          0.73282,
          1.3963,
          1.6928,
          2.5329,
          2.6166,
          2.6115,
          2.615,
          2.6181,
          2.6163,
          1.5437,
          0.82991,
          0.83234,
          0.8329,
          0.8318399999999999,
          0.8320200000000001,
          0.8314,
          0.8342700000000001,
          0.50266,
          0.625,
          0.68142,
          0.68101,
          0.68337,
          0.6873,
          0.68711,
          0.68713,
          0.68516,
          0.6723600000000001,
          0.67099,
          0.66922,
          0.6715800000000001,
          0.68555,
          0.68593,
          0.6873199999999999,
          0.6873199999999999,
          0.68691,
          0.68693,
          0.6828,
          0.64465,
          0.58855,
          0.59053,
          0.59601,
          0.59758,
          0.59621,
          0.5946199999999999,
          0.5916600000000001,
          0.58954,
          0.5887600000000001,
          0.5889,
          0.57721,
          0.57122,
          0.57185,
          0.5746,
          0.57587,
          0.5774199999999999,
          0.57805,
          0.58305,
          0.59172,
          0.59186,
          0.59236,
          0.59285,
          0.59427,
          0.5967899999999999,
          0.59724,
          0.5966,
          0.55789,
          0.50716,
          0.63732,
          1.2005,
          1.7609,
          2.1846,
          2.1924,
          2.198,
          2.2049,
          1.2754,
          0.98703,
          0.7045100000000001,
          0.8409200000000001,
          0.87023,
          0.87277,
          0.8712,
          0.87225,
          0.87359,
          0.8731399999999999,
          0.8710399999999999,
          0.86836,
          0.8729100000000001,
          0.8726799999999999,
          0.8723200000000001,
          0.7184699999999999,
          0.509,
          0.50446,
          0.71446,
          0.7205600000000001,
          0.72124,
          0.72139,
          0.72068,
          0.72,
          0.72015,
          0.71834,
          0.7146100000000001,
          0.71363,
          0.70617,
          0.71044,
          0.71446,
          0.72041,
          0.7197,
          0.72027,
          0.71917,
          0.71763,
          0.71503,
          0.70881,
          0.6170899999999999,
          0.62389,
          0.62654,
          0.6258699999999999,
          0.62563,
          0.6221800000000001,
          0.6201,
          0.61741,
          0.6167199999999999,
          0.6158100000000001,
          0.6147699999999999,
          0.6017,
          0.60434,
          0.60482,
          0.60655,
          0.61165,
          0.61637,
          0.61717,
          0.61832,
          0.62029,
          0.6219,
          0.6228100000000001,
          0.6260399999999999,
          0.62615,
          0.62537,
          0.62489,
          0.5983
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=RF Result<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "RF Result",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "RF Result",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          2,
          4,
          6,
          7,
          10,
          15,
          23,
          31,
          42,
          44,
          45,
          47,
          51,
          55,
          61,
          62,
          67,
          68,
          71,
          77,
          87,
          93,
          96,
          97,
          101,
          109,
          115,
          122,
          123,
          125,
          126,
          129,
          136,
          154,
          155,
          157,
          159,
          160,
          165,
          167,
          179,
          183,
          186,
          197,
          202,
          210,
          212,
          219,
          223,
          229,
          230,
          232,
          234,
          237,
          243,
          244,
          245,
          248,
          251,
          252,
          253,
          256,
          261,
          266,
          270,
          272,
          273,
          274,
          275,
          278,
          295,
          298,
          299,
          302,
          303,
          310,
          313,
          320,
          324,
          325,
          335,
          340,
          343,
          344,
          345,
          357,
          363,
          371,
          373,
          381,
          385,
          386,
          393,
          398,
          402,
          410,
          412,
          418,
          419,
          422,
          430,
          431,
          437,
          438,
          454,
          455,
          457,
          461,
          463,
          464,
          471,
          475,
          476,
          477,
          478,
          479,
          481,
          483,
          485,
          486,
          488,
          498,
          503,
          504,
          513,
          515,
          517,
          527,
          530,
          532,
          534,
          538,
          542,
          544,
          547,
          553,
          564,
          565,
          571,
          572,
          573,
          576,
          582,
          586,
          587,
          591,
          599,
          605,
          611,
          614,
          626,
          627,
          631,
          635,
          636,
          639,
          641,
          651,
          659,
          660,
          661,
          664,
          669,
          671,
          675,
          676,
          679,
          681,
          686,
          688,
          690,
          701,
          703,
          708,
          710,
          712,
          713,
          714,
          718,
          720,
          722,
          724,
          731,
          736,
          739,
          744,
          749,
          750,
          751,
          758,
          764,
          770,
          771,
          778,
          782,
          783,
          793,
          794,
          795,
          798,
          803,
          815,
          818,
          819,
          825,
          827,
          834,
          837,
          842,
          843,
          848,
          849,
          856,
          867,
          872,
          873,
          876,
          877,
          879,
          886,
          888,
          889,
          890,
          895,
          902,
          903,
          906,
          921,
          922,
          923,
          925,
          930,
          935,
          937,
          940,
          944,
          945,
          949,
          950,
          959,
          963,
          964,
          967,
          969,
          975,
          976,
          979,
          982,
          983,
          995,
          1001,
          1002,
          1004,
          1008,
          1012,
          1014,
          1019,
          1022,
          1031,
          1033,
          1040,
          1041,
          1044,
          1047,
          1052,
          1057,
          1058,
          1059,
          1060,
          1062,
          1065,
          1069,
          1070,
          1071,
          1074,
          1085,
          1089,
          1092,
          1099,
          1102,
          1115,
          1117,
          1118,
          1121,
          1130,
          1133,
          1135,
          1138,
          1139,
          1141,
          1148,
          1155,
          1158,
          1162,
          1167,
          1168,
          1169,
          1170,
          1175,
          1177,
          1180,
          1183,
          1189,
          1193,
          1195,
          1197,
          1205,
          1206,
          1210,
          1212,
          1215,
          1218,
          1220,
          1222,
          1225,
          1226,
          1230,
          1231,
          1233,
          1234,
          1235,
          1239,
          1242,
          1244,
          1246,
          1251,
          1259,
          1262,
          1268,
          1270,
          1271,
          1275,
          1279,
          1280,
          1282,
          1284,
          1293,
          1301,
          1309,
          1310,
          1312,
          1318,
          1324,
          1333,
          1334,
          1350,
          1352,
          1356,
          1357,
          1361,
          1366,
          1370,
          1371,
          1374,
          1387,
          1388,
          1392,
          1393,
          1408,
          1409,
          1413,
          1414,
          1416,
          1417,
          1421,
          1425,
          1426,
          1431,
          1435,
          1437,
          1440,
          1450,
          1460,
          1466,
          1467,
          1469,
          1486,
          1495,
          1497,
          1501,
          1502,
          1505,
          1507,
          1511,
          1530,
          1531,
          1535,
          1537,
          1541,
          1549,
          1554,
          1558,
          1564,
          1565,
          1566,
          1568,
          1570,
          1573,
          1582,
          1584,
          1588,
          1596,
          1597,
          1598,
          1602,
          1604,
          1607,
          1609,
          1611,
          1613,
          1615,
          1616,
          1621,
          1628,
          1630,
          1631,
          1642,
          1644,
          1645,
          1651,
          1658,
          1661,
          1662,
          1663,
          1665,
          1666,
          1668,
          1670,
          1671,
          1680,
          1690,
          1696,
          1700,
          1701,
          1703,
          1710,
          1711,
          1713,
          1717,
          1725,
          1729,
          1738,
          1742,
          1743,
          1753,
          1759,
          1769,
          1771,
          1773,
          1775,
          1789,
          1799,
          1800,
          1804,
          1808,
          1815,
          1816,
          1819,
          1828,
          1833,
          1837,
          1849,
          1850,
          1851,
          1854,
          1862
         ],
         "xaxis": "x",
         "y": [
          1.127753300000001,
          1.3127554000000001,
          1.8824386000000002,
          1.7013615466666667,
          1.2347573666666667,
          2.0329019333333314,
          2.934927042857143,
          3.042194583333332,
          3.0018697666666636,
          0.9663319999999993,
          0.9735242333333325,
          0.879026299999999,
          0.8428420261904759,
          1.090778666666666,
          1.1031488500000006,
          1.1041929333333336,
          1.101904666666667,
          1.0982829999999995,
          1.0976653333333335,
          1.1041929333333336,
          1.1031488500000006,
          0.6863810000000002,
          0.7848475947619048,
          0.7693181500000007,
          0.8282401000000008,
          0.9043628876190469,
          0.9073185233333325,
          0.9046579866666662,
          0.894000513333334,
          0.8933659499999994,
          0.8919455999999997,
          0.8901304149999987,
          0.8870820666666672,
          0.8921473500000003,
          0.9082322999999998,
          0.9082590833333322,
          0.9074949916666658,
          0.9043628876190469,
          0.9014754542857142,
          0.8396014066666665,
          0.6491518999999998,
          0.7798205133333331,
          0.7856779154761908,
          0.7858680833333335,
          0.7838001666666667,
          0.781230846666666,
          0.7781127999999998,
          0.7766715000000001,
          0.7744095349999995,
          0.7726254488095242,
          0.7666146749999999,
          0.7628263333333345,
          0.7618532000000012,
          0.7584554250000005,
          0.7583281799999999,
          0.7527220583333337,
          0.7527220583333337,
          0.7532713500000008,
          0.755640646666667,
          0.7581140250000005,
          0.7584554250000005,
          0.7603232666666674,
          0.7628263333333345,
          0.7706528083333343,
          0.7733904416666665,
          0.7753935107142855,
          0.7757368500000004,
          0.7763323999999996,
          0.7766715000000001,
          0.7774007000000003,
          0.7786545640476185,
          0.7850167150000001,
          0.7858031500000002,
          0.7858076500000003,
          0.7858187333333333,
          0.7856779154761908,
          0.7735943383333335,
          0.8301759200000006,
          2.7988525619047624,
          2.9238388333333374,
          2.9240123333333377,
          2.9240123333333377,
          2.7988525619047624,
          2.0280051666666683,
          1.7250473999999998,
          1.2671876400000004,
          1.1545517499999989,
          1.1558930999999997,
          1.1473204238095247,
          1.1473204238095247,
          1.1558930999999997,
          1.1546763499999988,
          1.155500749999999,
          0.9133598000000006,
          0.6839282833333344,
          0.9273898683333341,
          0.9519082999999994,
          0.952783299999999,
          0.9525135199999996,
          0.9509861628571437,
          0.9476766283333332,
          0.9384657199999986,
          0.9371925333333323,
          0.9317138000000001,
          0.9328197000000015,
          0.9525135199999996,
          0.9535315199999991,
          0.9536655033333332,
          0.9526777999999996,
          0.9511940500000002,
          0.9502112999999999,
          0.9058502333333334,
          0.6178547666666667,
          0.5879366500000005,
          0.5881934500000005,
          0.6310953166666662,
          0.7177757033333333,
          0.7887879583333333,
          0.8186236416666677,
          0.8204461000000005,
          0.8216840000000009,
          0.82341385,
          0.8234463666666666,
          0.8213496133333332,
          0.820771813333333,
          0.8179807,
          0.8170140500000003,
          0.8161169266666668,
          0.8123740966666656,
          0.8107163199999988,
          0.8090410071428562,
          0.8048351500000003,
          0.7993703849999996,
          0.7968319166666673,
          0.7949872666666667,
          0.7914901166666669,
          0.7936614500000009,
          0.8048351500000003,
          0.8080946583333325,
          0.8123740966666656,
          0.8133492949999989,
          0.8136740633333329,
          0.8149660933333339,
          0.816465633333333,
          0.8186217000000007,
          0.8192162666666681,
          0.8204418849999997,
          0.8238193733333324,
          0.8248581383333334,
          0.8238459499999999,
          0.8206769833333333,
          1.548731133333331,
          1.7995311999999983,
          1.9915733833333333,
          2.5028846666666653,
          2.9106960666666657,
          3.438671200000003,
          3.5817454833333335,
          3.5817454833333335,
          3.3440280666666684,
          3.2163086333333344,
          1.9915733833333333,
          0.8319265999999989,
          1.4204399999999986,
          1.4694489999999991,
          1.3202089166666666,
          1.424145583333333,
          1.5211530642857136,
          1.5297920000000007,
          1.531813016666667,
          1.5296763000000004,
          1.5238891833333352,
          1.529562166666669,
          1.5297920000000007,
          1.424145583333333,
          1.4386442500000007,
          1.397160214285714,
          1.4694489999999991,
          1.4781585999999987,
          0.8856470000000006,
          1.0622662666666671,
          0.9741513666666672,
          0.8345584000000005,
          1.251429049999999,
          1.259991600000002,
          1.2579880833333346,
          1.2550783666666663,
          1.2447226166666665,
          1.2412716666666668,
          1.2396988500000001,
          1.2316399166666685,
          1.2327893857142853,
          1.2412716666666668,
          1.2447226166666665,
          1.2546623833333326,
          1.2579762500000005,
          1.258486000000002,
          1.237113166666666,
          1.237610933333332,
          1.1470651000000007,
          0.7172617999999992,
          0.9575772533333345,
          1.0847270666666666,
          1.0853889999999993,
          1.0855282499999999,
          1.084957666666666,
          1.0823217333333333,
          1.0792513166666664,
          1.0777881166666674,
          1.0757030000000005,
          1.0751713333333326,
          1.0728773333333326,
          1.070729166666666,
          1.0665378333333329,
          1.0484249166666662,
          1.0441923333333354,
          1.0420270833333343,
          1.0423186333333323,
          1.0418166333333323,
          1.0420270833333343,
          1.0487713333333324,
          1.0502648666666676,
          1.0498810000000007,
          1.051293666666666,
          1.063742400000001,
          1.0682813000000007,
          1.070729166666666,
          1.071409999999999,
          1.079299250000001,
          1.079624500000002,
          1.0805940000000012,
          1.0823217333333333,
          1.0844950000000015,
          1.0847707999999985,
          1.0847270666666666,
          1.0766199785714274,
          1.0635628466666658,
          1.059547202380952,
          0.9683000083333336,
          1.3978592633333329,
          4.038504333333337,
          4.045920250000002,
          4.041650000000003,
          4.038846333333334,
          4.045920250000002,
          3.9563431833333276,
          3.798857166666667,
          2.7702086666666705,
          1.3978592633333329,
          0.9683000083333336,
          1.6008713333333342,
          1.6023055,
          1.6033182833333328,
          1.6037151666666656,
          1.597720404761904,
          1.597720404761904,
          1.6001798500000002,
          1.6023055,
          1.6003476833333317,
          1.2506095999999993,
          0.9435654500000007,
          0.9670839166666662,
          1.099096599999998,
          1.288851749999999,
          1.310837583333333,
          1.3204171666666664,
          1.3211020000000013,
          1.3215789999999992,
          1.3200642499999997,
          1.3186225000000014,
          1.3154278999999998,
          1.3059938500000008,
          1.302797466666666,
          1.3019608666666653,
          1.3000045333333319,
          1.2946224999999998,
          1.302797466666666,
          1.3059938500000008,
          1.3154278999999998,
          1.3207604666666686,
          1.3204171666666664,
          0.8680946433333344,
          0.6745984133333336,
          0.5922309816666664,
          0.7374679416666661,
          1.1344634999999992,
          1.1367090833333342,
          1.1380976642857146,
          1.1375260000000014,
          1.1376680000000006,
          1.137276000000001,
          1.1338637333333315,
          1.1311275333333344,
          1.129748066666666,
          1.1267107500000015,
          1.1243574166666657,
          1.1231573333333325,
          1.1224292499999995,
          1.121846916666667,
          1.118051000000001,
          1.114471666666666,
          1.1071287595238095,
          1.1026174666666673,
          1.095085283333332,
          1.0916742500000007,
          1.0924052833333326,
          1.095085283333332,
          1.1038177261904756,
          1.1071287595238095,
          1.1162669999999995,
          1.1192150500000013,
          1.1210920833333335,
          1.1231573333333325,
          1.124738149999999,
          1.1255417000000016,
          1.1269002500000018,
          1.12746,
          1.1306815000000012,
          1.1311275333333344,
          1.1314982000000011,
          1.1323494999999977,
          1.1325490666666647,
          1.1353362666666644,
          1.1375669499999983,
          1.1380182500000002,
          1.1381520000000014,
          1.1380976642857146,
          1.131504366666668,
          1.0687493299999995,
          1.1963487999999995,
          1.6493688999999987,
          1.837091099999998,
          1.325276166666668,
          2.150867833333332,
          2.299025833333335,
          2.5807520833333375,
          2.607176044444445,
          2.6190263333333337,
          2.370005783333332,
          0.7821529399999996,
          0.7279483399999995,
          0.7344164000000005,
          0.8326971933333336,
          0.8338542266666659,
          0.8297178000000005,
          0.8307203600000004,
          0.7279483399999995,
          0.6195140999999994,
          0.5917638000000008,
          0.5673307000000004,
          0.6789031000000009,
          0.6866112766666658,
          0.6866683266666662,
          0.6866702299999997,
          0.6859349000000009,
          0.6745220799999992,
          0.6730347530952372,
          0.6718573083333329,
          0.6706925083333328,
          0.6828135600000006,
          0.6838068999999999,
          0.6866702299999997,
          0.6866683266666662,
          0.6871146249999996,
          0.6875697150000002,
          0.68503325,
          0.677379,
          0.6560249999999995,
          0.5892308666666668,
          0.5968530999999991,
          0.5966636600000002,
          0.5970481333333337,
          0.5949911316666676,
          0.5921239050000002,
          0.5898714899999989,
          0.5897468499999994,
          0.5887968100000003,
          0.5771845499999991,
          0.5716046416666662,
          0.5716046416666662,
          0.5734555559523801,
          0.5742898666666658,
          0.5763585999999996,
          0.5773734249999992,
          0.5810722699206354,
          0.5905382250000004,
          0.5912026166666662,
          0.5923687483333341,
          0.5923227150000008,
          0.5938676966666674,
          0.5962564283333339,
          0.5967123166666659,
          0.5965640226190478,
          0.5595500666666666,
          0.5338422666666662,
          1.07857652,
          1.5058825309523807,
          1.8267156857142874,
          2.190427933333332,
          2.2499051761904765,
          2.2098601428571443,
          2.2043634500000024,
          1.5058825309523807,
          1.1333463571428577,
          1.07857652,
          0.8485123333333341,
          0.8709116333333333,
          0.8727249552380953,
          0.8714279533333331,
          0.8723983750000002,
          0.8730771999999993,
          0.873212899999999,
          0.8723164166666659,
          0.8681771749999997,
          0.8737057000000008,
          0.8730044499999999,
          0.8723983750000002,
          0.7288315833333339,
          0.6172884366666669,
          0.5434381111904755,
          0.7140822250000002,
          0.7203588176190475,
          0.7205784983333332,
          0.7205611149999999,
          0.7206148457142854,
          0.720385942380952,
          0.7189840833333334,
          0.7175608166666666,
          0.7145674133333328,
          0.7125427699999999,
          0.7059723250000005,
          0.7103912500000004,
          0.7145674133333328,
          0.7189840833333334,
          0.720385942380952,
          0.7206148457142854,
          0.7195346999999992,
          0.7183420933333329,
          0.7158494833333333,
          0.7037475000000001,
          0.6149051966666659,
          0.6224923750000001,
          0.6257169750000006,
          0.6252232499999993,
          0.6250071666666661,
          0.6218184500000002,
          0.6204209000000006,
          0.6172277333333324,
          0.6164101195238092,
          0.615724990000001,
          0.6146921399999996,
          0.6021825249999998,
          0.6041431399999996,
          0.6049543150000006,
          0.6064000666666673,
          0.6115030985714285,
          0.6164101195238092,
          0.6170726799999988,
          0.6180032000000005,
          0.6205839066666662,
          0.6218184500000002,
          0.6230565366666679,
          0.6260962999999999,
          0.6261729,
          0.6260997166666668,
          0.6256166833333332,
          0.6042515000000012
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=GB Result<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "GB Result",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "GB Result",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          2,
          4,
          6,
          7,
          10,
          15,
          23,
          31,
          42,
          44,
          45,
          47,
          51,
          55,
          61,
          62,
          67,
          68,
          71,
          77,
          87,
          93,
          96,
          97,
          101,
          109,
          115,
          122,
          123,
          125,
          126,
          129,
          136,
          154,
          155,
          157,
          159,
          160,
          165,
          167,
          179,
          183,
          186,
          197,
          202,
          210,
          212,
          219,
          223,
          229,
          230,
          232,
          234,
          237,
          243,
          244,
          245,
          248,
          251,
          252,
          253,
          256,
          261,
          266,
          270,
          272,
          273,
          274,
          275,
          278,
          295,
          298,
          299,
          302,
          303,
          310,
          313,
          320,
          324,
          325,
          335,
          340,
          343,
          344,
          345,
          357,
          363,
          371,
          373,
          381,
          385,
          386,
          393,
          398,
          402,
          410,
          412,
          418,
          419,
          422,
          430,
          431,
          437,
          438,
          454,
          455,
          457,
          461,
          463,
          464,
          471,
          475,
          476,
          477,
          478,
          479,
          481,
          483,
          485,
          486,
          488,
          498,
          503,
          504,
          513,
          515,
          517,
          527,
          530,
          532,
          534,
          538,
          542,
          544,
          547,
          553,
          564,
          565,
          571,
          572,
          573,
          576,
          582,
          586,
          587,
          591,
          599,
          605,
          611,
          614,
          626,
          627,
          631,
          635,
          636,
          639,
          641,
          651,
          659,
          660,
          661,
          664,
          669,
          671,
          675,
          676,
          679,
          681,
          686,
          688,
          690,
          701,
          703,
          708,
          710,
          712,
          713,
          714,
          718,
          720,
          722,
          724,
          731,
          736,
          739,
          744,
          749,
          750,
          751,
          758,
          764,
          770,
          771,
          778,
          782,
          783,
          793,
          794,
          795,
          798,
          803,
          815,
          818,
          819,
          825,
          827,
          834,
          837,
          842,
          843,
          848,
          849,
          856,
          867,
          872,
          873,
          876,
          877,
          879,
          886,
          888,
          889,
          890,
          895,
          902,
          903,
          906,
          921,
          922,
          923,
          925,
          930,
          935,
          937,
          940,
          944,
          945,
          949,
          950,
          959,
          963,
          964,
          967,
          969,
          975,
          976,
          979,
          982,
          983,
          995,
          1001,
          1002,
          1004,
          1008,
          1012,
          1014,
          1019,
          1022,
          1031,
          1033,
          1040,
          1041,
          1044,
          1047,
          1052,
          1057,
          1058,
          1059,
          1060,
          1062,
          1065,
          1069,
          1070,
          1071,
          1074,
          1085,
          1089,
          1092,
          1099,
          1102,
          1115,
          1117,
          1118,
          1121,
          1130,
          1133,
          1135,
          1138,
          1139,
          1141,
          1148,
          1155,
          1158,
          1162,
          1167,
          1168,
          1169,
          1170,
          1175,
          1177,
          1180,
          1183,
          1189,
          1193,
          1195,
          1197,
          1205,
          1206,
          1210,
          1212,
          1215,
          1218,
          1220,
          1222,
          1225,
          1226,
          1230,
          1231,
          1233,
          1234,
          1235,
          1239,
          1242,
          1244,
          1246,
          1251,
          1259,
          1262,
          1268,
          1270,
          1271,
          1275,
          1279,
          1280,
          1282,
          1284,
          1293,
          1301,
          1309,
          1310,
          1312,
          1318,
          1324,
          1333,
          1334,
          1350,
          1352,
          1356,
          1357,
          1361,
          1366,
          1370,
          1371,
          1374,
          1387,
          1388,
          1392,
          1393,
          1408,
          1409,
          1413,
          1414,
          1416,
          1417,
          1421,
          1425,
          1426,
          1431,
          1435,
          1437,
          1440,
          1450,
          1460,
          1466,
          1467,
          1469,
          1486,
          1495,
          1497,
          1501,
          1502,
          1505,
          1507,
          1511,
          1530,
          1531,
          1535,
          1537,
          1541,
          1549,
          1554,
          1558,
          1564,
          1565,
          1566,
          1568,
          1570,
          1573,
          1582,
          1584,
          1588,
          1596,
          1597,
          1598,
          1602,
          1604,
          1607,
          1609,
          1611,
          1613,
          1615,
          1616,
          1621,
          1628,
          1630,
          1631,
          1642,
          1644,
          1645,
          1651,
          1658,
          1661,
          1662,
          1663,
          1665,
          1666,
          1668,
          1670,
          1671,
          1680,
          1690,
          1696,
          1700,
          1701,
          1703,
          1710,
          1711,
          1713,
          1717,
          1725,
          1729,
          1738,
          1742,
          1743,
          1753,
          1759,
          1769,
          1771,
          1773,
          1775,
          1789,
          1799,
          1800,
          1804,
          1808,
          1815,
          1816,
          1819,
          1828,
          1833,
          1837,
          1849,
          1850,
          1851,
          1854,
          1862
         ],
         "xaxis": "x",
         "y": [
          0.9864329890528565,
          1.2895187247466013,
          1.887839421455548,
          1.630978581803836,
          1.2452660578569754,
          2.0604488136196286,
          3.021370554529656,
          3.026569670185672,
          2.951759766161385,
          0.8992067436594149,
          0.9328637804298477,
          0.9328637804298477,
          0.9291757721119204,
          1.0594558602632915,
          1.0594558602632915,
          1.1049685675819652,
          1.1049685675819652,
          1.1049685675819652,
          1.1049685675819652,
          1.1049685675819652,
          1.0594558602632915,
          0.688933100476364,
          0.81081136259557,
          0.8709421249916856,
          0.8785749935562,
          0.8785749935562,
          0.8785749935562,
          0.8957644789210091,
          0.9038458225077828,
          0.9038458225077828,
          0.9038458225077828,
          0.9130338369231075,
          0.9284250535932369,
          0.9038458225077828,
          0.8785749935562,
          0.8785749935562,
          0.8785749935562,
          0.8785749935562,
          0.8785749935562,
          0.860821352772585,
          0.6602812613343659,
          0.7774221681643008,
          0.7774221681643008,
          0.7774221681643008,
          0.7774221681643008,
          0.7774221681643008,
          0.7774221681643008,
          0.7769512039417318,
          0.7769512039417318,
          0.7769512039417318,
          0.7903182967001061,
          0.788532909357835,
          0.788532909357835,
          0.788532909357835,
          0.7805435295387532,
          0.7805435295387532,
          0.7805435295387532,
          0.7805435295387532,
          0.7805435295387532,
          0.7821822880498784,
          0.788532909357835,
          0.788532909357835,
          0.788532909357835,
          0.7769512039417318,
          0.7769512039417318,
          0.7769512039417318,
          0.7769512039417318,
          0.7769512039417318,
          0.7769512039417318,
          0.7778677374634659,
          0.7774221681643008,
          0.7774221681643008,
          0.7774221681643008,
          0.7774221681643008,
          0.7774221681643008,
          0.7774221681643008,
          0.7663368327327276,
          0.6755664314473829,
          2.966087490187119,
          2.920553967323411,
          2.920553967323411,
          2.920553967323411,
          2.966087490187119,
          2.0476955718964724,
          1.5957197837840973,
          1.2384426978907614,
          1.1025487717481863,
          1.1050024242517054,
          1.1483393243882436,
          1.1483393243882436,
          1.1050024242517054,
          1.1050024242517054,
          1.1025487717481863,
          0.9100720258855751,
          0.820436289807277,
          0.9175574755232917,
          0.9251903440878061,
          0.9251903440878061,
          0.9251903440878061,
          0.9251903440878061,
          0.9413224201293062,
          0.9379313945970185,
          0.9379313945970185,
          0.9379313945970185,
          0.9379313945970185,
          0.9251903440878061,
          0.9251903440878061,
          0.9251903440878061,
          0.9251903440878061,
          0.9251903440878061,
          0.9251903440878061,
          0.902969523580547,
          0.820436289807277,
          0.6504787451430782,
          0.6504787451430782,
          0.7094807996956662,
          0.7509470408310999,
          0.7908488219868266,
          0.8077665544321588,
          0.8126747543596988,
          0.8126747543596988,
          0.8126747543596988,
          0.8126747543596988,
          0.8126747543596988,
          0.8126747543596988,
          0.8126747543596988,
          0.8126747543596988,
          0.813120323658864,
          0.8122037901371298,
          0.8122037901371298,
          0.8058531688291732,
          0.8106842277005905,
          0.8157961157341512,
          0.8157961157341512,
          0.8157961157341512,
          0.8157961157341512,
          0.8157961157341512,
          0.8106842277005905,
          0.8058531688291732,
          0.8122037901371298,
          0.8122037901371298,
          0.8122037901371298,
          0.8122037901371298,
          0.8126747543596988,
          0.8126747543596988,
          0.8126747543596988,
          0.8126747543596988,
          0.8126747543596988,
          0.8126747543596988,
          0.8126747543596988,
          0.8126747543596988,
          1.701537159938472,
          1.9500460325910427,
          2.222996683325925,
          2.8443306576548366,
          2.8597448410047015,
          3.3652625529017297,
          3.563042266599458,
          3.563042266599458,
          3.133819572764986,
          3.0936719955253387,
          2.222996683325925,
          1.0523419113359824,
          1.3293508443938247,
          1.3896340973909032,
          1.409239755378468,
          1.409239755378468,
          1.4737883741286453,
          1.4737883741286453,
          1.5171252742651835,
          1.538934566459708,
          1.5744226722019277,
          1.5171252742651835,
          1.4737883741286453,
          1.409239755378468,
          1.409239755378468,
          1.3896340973909032,
          1.3896340973909032,
          1.3896340973909032,
          1.0269398248272898,
          1.0681512801844562,
          1.0681512801844562,
          1.0681512801844562,
          1.213683238680374,
          1.213683238680374,
          1.213683238680374,
          1.2291548151343439,
          1.2382817017804266,
          1.2382817017804266,
          1.2382817017804266,
          1.2382817017804266,
          1.2382817017804266,
          1.2382817017804266,
          1.2382817017804266,
          1.213683238680374,
          1.213683238680374,
          1.213683238680374,
          1.213683238680374,
          1.2060503701158594,
          1.1646135219863287,
          0.7640498984363605,
          0.8761964482763288,
          1.0674611621441232,
          1.0674611621441232,
          1.0674611621441232,
          1.0674611621441232,
          1.0674611621441232,
          1.0674611621441232,
          1.0674611621441232,
          1.0674611621441232,
          1.0674611621441232,
          1.0735488506892854,
          1.0671982293813287,
          1.0655594708702032,
          1.0771411762863063,
          1.0771411762863063,
          1.0771411762863063,
          1.0771411762863063,
          1.0771411762863063,
          1.0771411762863063,
          1.0771411762863063,
          1.0771411762863063,
          1.0771411762863063,
          1.0771411762863063,
          1.0655594708702032,
          1.0671982293813287,
          1.0671982293813287,
          1.0735488506892854,
          1.0674611621441232,
          1.0674611621441232,
          1.0674611621441232,
          1.0674611621441232,
          1.0674611621441232,
          1.0674611621441232,
          1.0674611621441232,
          1.0674611621441232,
          1.0437185505078999,
          1.027709629614886,
          0.9792445504490591,
          1.3072331352506243,
          3.9393077705479644,
          3.9410168696394634,
          3.9410168696394634,
          3.9514620822341975,
          3.9410168696394634,
          3.9120892166255126,
          3.750455036031155,
          2.7947110850846273,
          1.3072331352506243,
          0.9792445504490591,
          1.5326221674121878,
          1.516065516955738,
          1.5607510970257517,
          1.5607510970257517,
          1.5607510970257517,
          1.5607510970257517,
          1.5607510970257517,
          1.516065516955738,
          1.5326221674121878,
          1.293446777508136,
          1.0487957986263978,
          1.0317163985983995,
          1.1071656641624976,
          1.255923601967385,
          1.255923601967385,
          1.255923601967385,
          1.255923601967385,
          1.255923601967385,
          1.255923601967385,
          1.255923601967385,
          1.2805220650674376,
          1.2805220650674376,
          1.2805220650674376,
          1.2805220650674376,
          1.274913712365461,
          1.274913712365461,
          1.2805220650674376,
          1.2805220650674376,
          1.2805220650674376,
          1.255923601967385,
          1.255923601967385,
          0.9795974491262012,
          0.8774868296907592,
          0.6312518019559055,
          0.7621290171749652,
          1.11774947468803,
          1.11774947468803,
          1.11774947468803,
          1.11774947468803,
          1.11774947468803,
          1.11774947468803,
          1.11774947468803,
          1.11774947468803,
          1.1169627897676644,
          1.1169771625932488,
          1.1169771625932488,
          1.1169771625932488,
          1.1137490890598678,
          1.1137490890598678,
          1.109801618952109,
          1.1125893034848966,
          1.1156349750140424,
          1.1156349750140424,
          1.1156349750140424,
          1.1156349750140424,
          1.1156349750140424,
          1.1156349750140424,
          1.1156349750140424,
          1.1156349750140424,
          1.1103636849568173,
          1.109801618952109,
          1.1137490890598678,
          1.1169771625932488,
          1.1169771625932488,
          1.1169771625932488,
          1.1178936961149828,
          1.1148780280056478,
          1.11774947468803,
          1.11774947468803,
          1.11774947468803,
          1.11774947468803,
          1.11774947468803,
          1.11774947468803,
          1.11774947468803,
          1.11774947468803,
          1.11774947468803,
          1.11774947468803,
          1.11284127476049,
          1.0664127936310757,
          1.1043953890665439,
          1.4313787235778044,
          1.6343624434478905,
          1.1018598631610064,
          2.278341379849481,
          2.2731370797951445,
          2.5585531324789845,
          2.5861711168200068,
          2.59657817298273,
          2.4268024555945815,
          0.7700485123085165,
          0.7783663943235041,
          0.8040514345427527,
          0.8322964767413286,
          0.8342215826841828,
          0.8342215826841828,
          0.8342215826841828,
          0.7783663943235041,
          0.6131826667622724,
          0.6131826667622724,
          0.6617263876604725,
          0.6794800284440875,
          0.6794800284440875,
          0.6794800284440875,
          0.6794800284440875,
          0.6794800284440875,
          0.688857562897216,
          0.688857562897216,
          0.797105652182256,
          0.8050950320013379,
          0.6841859897107774,
          0.6794800284440875,
          0.6794800284440875,
          0.6794800284440875,
          0.6794800284440875,
          0.6794800284440875,
          0.6794800284440875,
          0.6794800284440875,
          0.6718471598795731,
          0.5948522362093263,
          0.5948522362093263,
          0.5948522362093263,
          0.5948522362093263,
          0.5948522362093263,
          0.5948522362093263,
          0.5929150027079424,
          0.5929150027079424,
          0.5929150027079424,
          0.5838974523589014,
          0.5922029548153317,
          0.5922029548153317,
          0.6001923346344136,
          0.6001923346344136,
          0.5838974523589014,
          0.5838974523589014,
          0.5886191749332769,
          0.5948522362093263,
          0.5948522362093263,
          0.5948522362093263,
          0.5948522362093263,
          0.5948522362093263,
          0.5948522362093263,
          0.5948522362093263,
          0.5948522362093263,
          0.5837669007777531,
          0.573026303836454,
          1.0062959519443744,
          1.3470263439032302,
          1.8064828817193466,
          2.125857126767671,
          2.307024745347214,
          2.2910129083024846,
          2.2902845970904107,
          1.3470263439032302,
          0.9934329933320318,
          1.0062959519443744,
          0.8103953268934885,
          0.8564102031186308,
          0.8567875544175236,
          0.870210722863201,
          0.87266437536672,
          0.87266437536672,
          0.8730987375382289,
          0.8730987375382289,
          0.8759422655750744,
          0.8730987375382289,
          0.87266437536672,
          0.87266437536672,
          0.7741335798075177,
          0.7488574795718116,
          0.6059515072298238,
          0.7058744286592118,
          0.7139370273779382,
          0.7139370273779382,
          0.7139370273779382,
          0.7139370273779382,
          0.7139370273779382,
          0.7139370273779382,
          0.7139370273779382,
          0.7139370273779382,
          0.7139370273779382,
          0.7105460018456504,
          0.7105460018456504,
          0.7139370273779382,
          0.7139370273779382,
          0.7139370273779382,
          0.7139370273779382,
          0.7139370273779382,
          0.7058744286592118,
          0.7058744286592118,
          0.6982415600946974,
          0.6005877181577407,
          0.6224136505306129,
          0.6224136505306129,
          0.6224136505306129,
          0.6224136505306129,
          0.6224136505306129,
          0.6224136505306129,
          0.6204764170292291,
          0.6204764170292291,
          0.6204764170292291,
          0.6204764170292291,
          0.6034694868611062,
          0.6051082453722315,
          0.6051082453722315,
          0.6114588666801881,
          0.6161805892545635,
          0.6204764170292291,
          0.6204764170292291,
          0.6204764170292291,
          0.6224136505306129,
          0.6224136505306129,
          0.6224136505306129,
          0.6224136505306129,
          0.6224136505306129,
          0.6224136505306129,
          0.6224136505306129,
          0.5978194404594416
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"5075cf45-1516-406f-9d97-7f070d59998a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5075cf45-1516-406f-9d97-7f070d59998a\")) {                    Plotly.newPlot(                        \"5075cf45-1516-406f-9d97-7f070d59998a\",                        [{\"hovertemplate\": \"variable=Data<br>index=%{x}<br>value=%{y}<extra></extra>\", \"legendgroup\": \"Data\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"Data\", \"showlegend\": true, \"type\": \"scattergl\", \"x\": [0, 2, 4, 6, 7, 10, 15, 23, 31, 42, 44, 45, 47, 51, 55, 61, 62, 67, 68, 71, 77, 87, 93, 96, 97, 101, 109, 115, 122, 123, 125, 126, 129, 136, 154, 155, 157, 159, 160, 165, 167, 179, 183, 186, 197, 202, 210, 212, 219, 223, 229, 230, 232, 234, 237, 243, 244, 245, 248, 251, 252, 253, 256, 261, 266, 270, 272, 273, 274, 275, 278, 295, 298, 299, 302, 303, 310, 313, 320, 324, 325, 335, 340, 343, 344, 345, 357, 363, 371, 373, 381, 385, 386, 393, 398, 402, 410, 412, 418, 419, 422, 430, 431, 437, 438, 454, 455, 457, 461, 463, 464, 471, 475, 476, 477, 478, 479, 481, 483, 485, 486, 488, 498, 503, 504, 513, 515, 517, 527, 530, 532, 534, 538, 542, 544, 547, 553, 564, 565, 571, 572, 573, 576, 582, 586, 587, 591, 599, 605, 611, 614, 626, 627, 631, 635, 636, 639, 641, 651, 659, 660, 661, 664, 669, 671, 675, 676, 679, 681, 686, 688, 690, 701, 703, 708, 710, 712, 713, 714, 718, 720, 722, 724, 731, 736, 739, 744, 749, 750, 751, 758, 764, 770, 771, 778, 782, 783, 793, 794, 795, 798, 803, 815, 818, 819, 825, 827, 834, 837, 842, 843, 848, 849, 856, 867, 872, 873, 876, 877, 879, 886, 888, 889, 890, 895, 902, 903, 906, 921, 922, 923, 925, 930, 935, 937, 940, 944, 945, 949, 950, 959, 963, 964, 967, 969, 975, 976, 979, 982, 983, 995, 1001, 1002, 1004, 1008, 1012, 1014, 1019, 1022, 1031, 1033, 1040, 1041, 1044, 1047, 1052, 1057, 1058, 1059, 1060, 1062, 1065, 1069, 1070, 1071, 1074, 1085, 1089, 1092, 1099, 1102, 1115, 1117, 1118, 1121, 1130, 1133, 1135, 1138, 1139, 1141, 1148, 1155, 1158, 1162, 1167, 1168, 1169, 1170, 1175, 1177, 1180, 1183, 1189, 1193, 1195, 1197, 1205, 1206, 1210, 1212, 1215, 1218, 1220, 1222, 1225, 1226, 1230, 1231, 1233, 1234, 1235, 1239, 1242, 1244, 1246, 1251, 1259, 1262, 1268, 1270, 1271, 1275, 1279, 1280, 1282, 1284, 1293, 1301, 1309, 1310, 1312, 1318, 1324, 1333, 1334, 1350, 1352, 1356, 1357, 1361, 1366, 1370, 1371, 1374, 1387, 1388, 1392, 1393, 1408, 1409, 1413, 1414, 1416, 1417, 1421, 1425, 1426, 1431, 1435, 1437, 1440, 1450, 1460, 1466, 1467, 1469, 1486, 1495, 1497, 1501, 1502, 1505, 1507, 1511, 1530, 1531, 1535, 1537, 1541, 1549, 1554, 1558, 1564, 1565, 1566, 1568, 1570, 1573, 1582, 1584, 1588, 1596, 1597, 1598, 1602, 1604, 1607, 1609, 1611, 1613, 1615, 1616, 1621, 1628, 1630, 1631, 1642, 1644, 1645, 1651, 1658, 1661, 1662, 1663, 1665, 1666, 1668, 1670, 1671, 1680, 1690, 1696, 1700, 1701, 1703, 1710, 1711, 1713, 1717, 1725, 1729, 1738, 1742, 1743, 1753, 1759, 1769, 1771, 1773, 1775, 1789, 1799, 1800, 1804, 1808, 1815, 1816, 1819, 1828, 1833, 1837, 1849, 1850, 1851, 1854, 1862], \"xaxis\": \"x\", \"y\": [0.73831, 1.4552, 2.0626, 2.5855, 2.7917, 3.05, 3.0553, 3.0621, 2.569, 0.98244, 1.0898, 1.0987, 1.1008, 1.1025, 1.1036, 1.0998, 1.0995, 1.0968, 1.0984, 1.1032, 1.1021, 0.535, 0.8968799999999999, 0.9022399999999999, 0.90389, 0.9065700000000001, 0.90636, 0.90009, 0.89243, 0.8909799999999999, 0.88974, 0.88771, 0.88561, 0.8936700000000001, 0.90743, 0.90807, 0.9065200000000001, 0.90138, 0.8974700000000001, 0.63071, 0.54093, 0.78492, 0.78668, 0.78638, 0.78254, 0.78087, 0.77742, 0.77644, 0.77367, 0.77082, 0.7627, 0.76059, 0.75956, 0.7585, 0.75573, 0.75271, 0.75364, 0.7532, 0.7572800000000001, 0.75942, 0.76017, 0.75998, 0.76658, 0.772, 0.77446, 0.7762399999999999, 0.77674, 0.77685, 0.77772, 0.77841, 0.78008, 0.786, 0.7861, 0.78689, 0.78601, 0.7864899999999999, 0.7089, 0.6539699999999999, 2.7817, 2.9268, 2.9248, 2.9248, 2.7784, 1.9535, 1.6309, 1.2951, 1.1551, 1.1568, 1.1512, 1.1501, 1.1553, 1.1537, 1.1538, 0.9012, 0.65976, 0.9341299999999999, 0.95278, 0.9538399999999999, 0.95337, 0.95134, 0.9464100000000001, 0.93891, 0.93606, 0.9321200000000001, 0.93311, 0.95236, 0.95258, 0.9528, 0.95281, 0.9503299999999999, 0.94909, 0.89731, 0.54169, 0.51143, 0.5979899999999999, 0.6822600000000001, 0.75035, 0.81192, 0.82086, 0.82245, 0.82335, 0.8245899999999999, 0.82481, 0.82176, 0.82204, 0.81892, 0.8177399999999999, 0.81657, 0.8122699999999999, 0.81138, 0.80937, 0.80687, 0.79979, 0.7972899999999999, 0.79535, 0.79063, 0.7948, 0.8063100000000001, 0.8072199999999999, 0.81221, 0.81318, 0.81353, 0.81498, 0.81609, 0.81872, 0.81858, 0.82004, 0.8226700000000001, 0.8239200000000001, 0.8226700000000001, 0.81955, 1.9573, 2.2572, 3.2963, 3.629, 3.6347, 3.639, 3.6393, 3.6114, 1.7347, 1.3574, 0.9063200000000001, 0.76756, 1.4611, 1.5222, 1.528, 1.5295, 1.528, 1.5305, 1.5263, 1.5251, 1.5207, 1.5299, 1.529, 1.3705, 1.0894, 0.80479, 0.64283, 0.5012, 0.89956, 1.1299, 1.2371, 1.2475, 1.2566, 1.2585, 1.2562, 1.2487, 1.2387, 1.2391, 1.2387, 1.2297, 1.2365, 1.2429, 1.2454, 1.2587, 1.26, 1.2607, 1.0347, 0.91755, 0.80872, 0.5512699999999999, 1.0386, 1.0838, 1.0853, 1.0845, 1.0829, 1.0811, 1.0774, 1.0767, 1.0732, 1.0728, 1.0703, 1.0686, 1.0649, 1.0452, 1.0411, 1.0383, 1.0393, 1.0413, 1.042, 1.0506, 1.0546, 1.0578, 1.059, 1.0659, 1.071, 1.0713, 1.074, 1.0819, 1.0823, 1.0836, 1.0841, 1.085, 1.0851, 1.0848, 1.0728, 0.8058, 0.7094699999999999, 1.152, 1.5164, 4.041, 4.0382, 4.0396, 4.0396, 4.0465, 3.8907, 3.635, 2.5568, 1.3817, 0.98345, 1.6006, 1.6032, 1.6052, 1.6032, 1.5963, 1.5969, 1.6015, 1.603, 1.6005, 1.166, 0.86634, 1.0325, 1.1485, 1.3036, 1.3117, 1.3205, 1.3207, 1.3202, 1.3202, 1.3182, 1.3142, 1.3067, 1.3023, 1.3019, 1.3011, 1.2945, 1.3022, 1.307, 1.3164, 1.3222, 1.3212, 0.8426100000000001, 0.59611, 0.50268, 0.8227, 1.1371, 1.1393, 1.1392, 1.139, 1.1397, 1.1394, 1.1349, 1.1307, 1.1293, 1.1266, 1.1245, 1.1236, 1.1227, 1.1214, 1.1177, 1.1143, 1.1069, 1.1025, 1.0946, 1.0913, 1.0925, 1.0958, 1.1051, 1.1063, 1.1169, 1.1193, 1.121, 1.1243, 1.1245, 1.1253, 1.1269, 1.128, 1.1306, 1.1308, 1.1309, 1.132, 1.1321, 1.1337, 1.1357, 1.1362, 1.1366, 1.1364, 1.1262, 1.0221, 0.73282, 1.3963, 1.6928, 2.5329, 2.6166, 2.6115, 2.615, 2.6181, 2.6163, 1.5437, 0.82991, 0.83234, 0.8329, 0.8318399999999999, 0.8320200000000001, 0.8314, 0.8342700000000001, 0.50266, 0.625, 0.68142, 0.68101, 0.68337, 0.6873, 0.68711, 0.68713, 0.68516, 0.6723600000000001, 0.67099, 0.66922, 0.6715800000000001, 0.68555, 0.68593, 0.6873199999999999, 0.6873199999999999, 0.68691, 0.68693, 0.6828, 0.64465, 0.58855, 0.59053, 0.59601, 0.59758, 0.59621, 0.5946199999999999, 0.5916600000000001, 0.58954, 0.5887600000000001, 0.5889, 0.57721, 0.57122, 0.57185, 0.5746, 0.57587, 0.5774199999999999, 0.57805, 0.58305, 0.59172, 0.59186, 0.59236, 0.59285, 0.59427, 0.5967899999999999, 0.59724, 0.5966, 0.55789, 0.50716, 0.63732, 1.2005, 1.7609, 2.1846, 2.1924, 2.198, 2.2049, 1.2754, 0.98703, 0.7045100000000001, 0.8409200000000001, 0.87023, 0.87277, 0.8712, 0.87225, 0.87359, 0.8731399999999999, 0.8710399999999999, 0.86836, 0.8729100000000001, 0.8726799999999999, 0.8723200000000001, 0.7184699999999999, 0.509, 0.50446, 0.71446, 0.7205600000000001, 0.72124, 0.72139, 0.72068, 0.72, 0.72015, 0.71834, 0.7146100000000001, 0.71363, 0.70617, 0.71044, 0.71446, 0.72041, 0.7197, 0.72027, 0.71917, 0.71763, 0.71503, 0.70881, 0.6170899999999999, 0.62389, 0.62654, 0.6258699999999999, 0.62563, 0.6221800000000001, 0.6201, 0.61741, 0.6167199999999999, 0.6158100000000001, 0.6147699999999999, 0.6017, 0.60434, 0.60482, 0.60655, 0.61165, 0.61637, 0.61717, 0.61832, 0.62029, 0.6219, 0.6228100000000001, 0.6260399999999999, 0.62615, 0.62537, 0.62489, 0.5983], \"yaxis\": \"y\"}, {\"hovertemplate\": \"variable=RF Result<br>index=%{x}<br>value=%{y}<extra></extra>\", \"legendgroup\": \"RF Result\", \"line\": {\"color\": \"#EF553B\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"RF Result\", \"showlegend\": true, \"type\": \"scattergl\", \"x\": [0, 2, 4, 6, 7, 10, 15, 23, 31, 42, 44, 45, 47, 51, 55, 61, 62, 67, 68, 71, 77, 87, 93, 96, 97, 101, 109, 115, 122, 123, 125, 126, 129, 136, 154, 155, 157, 159, 160, 165, 167, 179, 183, 186, 197, 202, 210, 212, 219, 223, 229, 230, 232, 234, 237, 243, 244, 245, 248, 251, 252, 253, 256, 261, 266, 270, 272, 273, 274, 275, 278, 295, 298, 299, 302, 303, 310, 313, 320, 324, 325, 335, 340, 343, 344, 345, 357, 363, 371, 373, 381, 385, 386, 393, 398, 402, 410, 412, 418, 419, 422, 430, 431, 437, 438, 454, 455, 457, 461, 463, 464, 471, 475, 476, 477, 478, 479, 481, 483, 485, 486, 488, 498, 503, 504, 513, 515, 517, 527, 530, 532, 534, 538, 542, 544, 547, 553, 564, 565, 571, 572, 573, 576, 582, 586, 587, 591, 599, 605, 611, 614, 626, 627, 631, 635, 636, 639, 641, 651, 659, 660, 661, 664, 669, 671, 675, 676, 679, 681, 686, 688, 690, 701, 703, 708, 710, 712, 713, 714, 718, 720, 722, 724, 731, 736, 739, 744, 749, 750, 751, 758, 764, 770, 771, 778, 782, 783, 793, 794, 795, 798, 803, 815, 818, 819, 825, 827, 834, 837, 842, 843, 848, 849, 856, 867, 872, 873, 876, 877, 879, 886, 888, 889, 890, 895, 902, 903, 906, 921, 922, 923, 925, 930, 935, 937, 940, 944, 945, 949, 950, 959, 963, 964, 967, 969, 975, 976, 979, 982, 983, 995, 1001, 1002, 1004, 1008, 1012, 1014, 1019, 1022, 1031, 1033, 1040, 1041, 1044, 1047, 1052, 1057, 1058, 1059, 1060, 1062, 1065, 1069, 1070, 1071, 1074, 1085, 1089, 1092, 1099, 1102, 1115, 1117, 1118, 1121, 1130, 1133, 1135, 1138, 1139, 1141, 1148, 1155, 1158, 1162, 1167, 1168, 1169, 1170, 1175, 1177, 1180, 1183, 1189, 1193, 1195, 1197, 1205, 1206, 1210, 1212, 1215, 1218, 1220, 1222, 1225, 1226, 1230, 1231, 1233, 1234, 1235, 1239, 1242, 1244, 1246, 1251, 1259, 1262, 1268, 1270, 1271, 1275, 1279, 1280, 1282, 1284, 1293, 1301, 1309, 1310, 1312, 1318, 1324, 1333, 1334, 1350, 1352, 1356, 1357, 1361, 1366, 1370, 1371, 1374, 1387, 1388, 1392, 1393, 1408, 1409, 1413, 1414, 1416, 1417, 1421, 1425, 1426, 1431, 1435, 1437, 1440, 1450, 1460, 1466, 1467, 1469, 1486, 1495, 1497, 1501, 1502, 1505, 1507, 1511, 1530, 1531, 1535, 1537, 1541, 1549, 1554, 1558, 1564, 1565, 1566, 1568, 1570, 1573, 1582, 1584, 1588, 1596, 1597, 1598, 1602, 1604, 1607, 1609, 1611, 1613, 1615, 1616, 1621, 1628, 1630, 1631, 1642, 1644, 1645, 1651, 1658, 1661, 1662, 1663, 1665, 1666, 1668, 1670, 1671, 1680, 1690, 1696, 1700, 1701, 1703, 1710, 1711, 1713, 1717, 1725, 1729, 1738, 1742, 1743, 1753, 1759, 1769, 1771, 1773, 1775, 1789, 1799, 1800, 1804, 1808, 1815, 1816, 1819, 1828, 1833, 1837, 1849, 1850, 1851, 1854, 1862], \"xaxis\": \"x\", \"y\": [1.127753300000001, 1.3127554000000001, 1.8824386000000002, 1.7013615466666667, 1.2347573666666667, 2.0329019333333314, 2.934927042857143, 3.042194583333332, 3.0018697666666636, 0.9663319999999993, 0.9735242333333325, 0.879026299999999, 0.8428420261904759, 1.090778666666666, 1.1031488500000006, 1.1041929333333336, 1.101904666666667, 1.0982829999999995, 1.0976653333333335, 1.1041929333333336, 1.1031488500000006, 0.6863810000000002, 0.7848475947619048, 0.7693181500000007, 0.8282401000000008, 0.9043628876190469, 0.9073185233333325, 0.9046579866666662, 0.894000513333334, 0.8933659499999994, 0.8919455999999997, 0.8901304149999987, 0.8870820666666672, 0.8921473500000003, 0.9082322999999998, 0.9082590833333322, 0.9074949916666658, 0.9043628876190469, 0.9014754542857142, 0.8396014066666665, 0.6491518999999998, 0.7798205133333331, 0.7856779154761908, 0.7858680833333335, 0.7838001666666667, 0.781230846666666, 0.7781127999999998, 0.7766715000000001, 0.7744095349999995, 0.7726254488095242, 0.7666146749999999, 0.7628263333333345, 0.7618532000000012, 0.7584554250000005, 0.7583281799999999, 0.7527220583333337, 0.7527220583333337, 0.7532713500000008, 0.755640646666667, 0.7581140250000005, 0.7584554250000005, 0.7603232666666674, 0.7628263333333345, 0.7706528083333343, 0.7733904416666665, 0.7753935107142855, 0.7757368500000004, 0.7763323999999996, 0.7766715000000001, 0.7774007000000003, 0.7786545640476185, 0.7850167150000001, 0.7858031500000002, 0.7858076500000003, 0.7858187333333333, 0.7856779154761908, 0.7735943383333335, 0.8301759200000006, 2.7988525619047624, 2.9238388333333374, 2.9240123333333377, 2.9240123333333377, 2.7988525619047624, 2.0280051666666683, 1.7250473999999998, 1.2671876400000004, 1.1545517499999989, 1.1558930999999997, 1.1473204238095247, 1.1473204238095247, 1.1558930999999997, 1.1546763499999988, 1.155500749999999, 0.9133598000000006, 0.6839282833333344, 0.9273898683333341, 0.9519082999999994, 0.952783299999999, 0.9525135199999996, 0.9509861628571437, 0.9476766283333332, 0.9384657199999986, 0.9371925333333323, 0.9317138000000001, 0.9328197000000015, 0.9525135199999996, 0.9535315199999991, 0.9536655033333332, 0.9526777999999996, 0.9511940500000002, 0.9502112999999999, 0.9058502333333334, 0.6178547666666667, 0.5879366500000005, 0.5881934500000005, 0.6310953166666662, 0.7177757033333333, 0.7887879583333333, 0.8186236416666677, 0.8204461000000005, 0.8216840000000009, 0.82341385, 0.8234463666666666, 0.8213496133333332, 0.820771813333333, 0.8179807, 0.8170140500000003, 0.8161169266666668, 0.8123740966666656, 0.8107163199999988, 0.8090410071428562, 0.8048351500000003, 0.7993703849999996, 0.7968319166666673, 0.7949872666666667, 0.7914901166666669, 0.7936614500000009, 0.8048351500000003, 0.8080946583333325, 0.8123740966666656, 0.8133492949999989, 0.8136740633333329, 0.8149660933333339, 0.816465633333333, 0.8186217000000007, 0.8192162666666681, 0.8204418849999997, 0.8238193733333324, 0.8248581383333334, 0.8238459499999999, 0.8206769833333333, 1.548731133333331, 1.7995311999999983, 1.9915733833333333, 2.5028846666666653, 2.9106960666666657, 3.438671200000003, 3.5817454833333335, 3.5817454833333335, 3.3440280666666684, 3.2163086333333344, 1.9915733833333333, 0.8319265999999989, 1.4204399999999986, 1.4694489999999991, 1.3202089166666666, 1.424145583333333, 1.5211530642857136, 1.5297920000000007, 1.531813016666667, 1.5296763000000004, 1.5238891833333352, 1.529562166666669, 1.5297920000000007, 1.424145583333333, 1.4386442500000007, 1.397160214285714, 1.4694489999999991, 1.4781585999999987, 0.8856470000000006, 1.0622662666666671, 0.9741513666666672, 0.8345584000000005, 1.251429049999999, 1.259991600000002, 1.2579880833333346, 1.2550783666666663, 1.2447226166666665, 1.2412716666666668, 1.2396988500000001, 1.2316399166666685, 1.2327893857142853, 1.2412716666666668, 1.2447226166666665, 1.2546623833333326, 1.2579762500000005, 1.258486000000002, 1.237113166666666, 1.237610933333332, 1.1470651000000007, 0.7172617999999992, 0.9575772533333345, 1.0847270666666666, 1.0853889999999993, 1.0855282499999999, 1.084957666666666, 1.0823217333333333, 1.0792513166666664, 1.0777881166666674, 1.0757030000000005, 1.0751713333333326, 1.0728773333333326, 1.070729166666666, 1.0665378333333329, 1.0484249166666662, 1.0441923333333354, 1.0420270833333343, 1.0423186333333323, 1.0418166333333323, 1.0420270833333343, 1.0487713333333324, 1.0502648666666676, 1.0498810000000007, 1.051293666666666, 1.063742400000001, 1.0682813000000007, 1.070729166666666, 1.071409999999999, 1.079299250000001, 1.079624500000002, 1.0805940000000012, 1.0823217333333333, 1.0844950000000015, 1.0847707999999985, 1.0847270666666666, 1.0766199785714274, 1.0635628466666658, 1.059547202380952, 0.9683000083333336, 1.3978592633333329, 4.038504333333337, 4.045920250000002, 4.041650000000003, 4.038846333333334, 4.045920250000002, 3.9563431833333276, 3.798857166666667, 2.7702086666666705, 1.3978592633333329, 0.9683000083333336, 1.6008713333333342, 1.6023055, 1.6033182833333328, 1.6037151666666656, 1.597720404761904, 1.597720404761904, 1.6001798500000002, 1.6023055, 1.6003476833333317, 1.2506095999999993, 0.9435654500000007, 0.9670839166666662, 1.099096599999998, 1.288851749999999, 1.310837583333333, 1.3204171666666664, 1.3211020000000013, 1.3215789999999992, 1.3200642499999997, 1.3186225000000014, 1.3154278999999998, 1.3059938500000008, 1.302797466666666, 1.3019608666666653, 1.3000045333333319, 1.2946224999999998, 1.302797466666666, 1.3059938500000008, 1.3154278999999998, 1.3207604666666686, 1.3204171666666664, 0.8680946433333344, 0.6745984133333336, 0.5922309816666664, 0.7374679416666661, 1.1344634999999992, 1.1367090833333342, 1.1380976642857146, 1.1375260000000014, 1.1376680000000006, 1.137276000000001, 1.1338637333333315, 1.1311275333333344, 1.129748066666666, 1.1267107500000015, 1.1243574166666657, 1.1231573333333325, 1.1224292499999995, 1.121846916666667, 1.118051000000001, 1.114471666666666, 1.1071287595238095, 1.1026174666666673, 1.095085283333332, 1.0916742500000007, 1.0924052833333326, 1.095085283333332, 1.1038177261904756, 1.1071287595238095, 1.1162669999999995, 1.1192150500000013, 1.1210920833333335, 1.1231573333333325, 1.124738149999999, 1.1255417000000016, 1.1269002500000018, 1.12746, 1.1306815000000012, 1.1311275333333344, 1.1314982000000011, 1.1323494999999977, 1.1325490666666647, 1.1353362666666644, 1.1375669499999983, 1.1380182500000002, 1.1381520000000014, 1.1380976642857146, 1.131504366666668, 1.0687493299999995, 1.1963487999999995, 1.6493688999999987, 1.837091099999998, 1.325276166666668, 2.150867833333332, 2.299025833333335, 2.5807520833333375, 2.607176044444445, 2.6190263333333337, 2.370005783333332, 0.7821529399999996, 0.7279483399999995, 0.7344164000000005, 0.8326971933333336, 0.8338542266666659, 0.8297178000000005, 0.8307203600000004, 0.7279483399999995, 0.6195140999999994, 0.5917638000000008, 0.5673307000000004, 0.6789031000000009, 0.6866112766666658, 0.6866683266666662, 0.6866702299999997, 0.6859349000000009, 0.6745220799999992, 0.6730347530952372, 0.6718573083333329, 0.6706925083333328, 0.6828135600000006, 0.6838068999999999, 0.6866702299999997, 0.6866683266666662, 0.6871146249999996, 0.6875697150000002, 0.68503325, 0.677379, 0.6560249999999995, 0.5892308666666668, 0.5968530999999991, 0.5966636600000002, 0.5970481333333337, 0.5949911316666676, 0.5921239050000002, 0.5898714899999989, 0.5897468499999994, 0.5887968100000003, 0.5771845499999991, 0.5716046416666662, 0.5716046416666662, 0.5734555559523801, 0.5742898666666658, 0.5763585999999996, 0.5773734249999992, 0.5810722699206354, 0.5905382250000004, 0.5912026166666662, 0.5923687483333341, 0.5923227150000008, 0.5938676966666674, 0.5962564283333339, 0.5967123166666659, 0.5965640226190478, 0.5595500666666666, 0.5338422666666662, 1.07857652, 1.5058825309523807, 1.8267156857142874, 2.190427933333332, 2.2499051761904765, 2.2098601428571443, 2.2043634500000024, 1.5058825309523807, 1.1333463571428577, 1.07857652, 0.8485123333333341, 0.8709116333333333, 0.8727249552380953, 0.8714279533333331, 0.8723983750000002, 0.8730771999999993, 0.873212899999999, 0.8723164166666659, 0.8681771749999997, 0.8737057000000008, 0.8730044499999999, 0.8723983750000002, 0.7288315833333339, 0.6172884366666669, 0.5434381111904755, 0.7140822250000002, 0.7203588176190475, 0.7205784983333332, 0.7205611149999999, 0.7206148457142854, 0.720385942380952, 0.7189840833333334, 0.7175608166666666, 0.7145674133333328, 0.7125427699999999, 0.7059723250000005, 0.7103912500000004, 0.7145674133333328, 0.7189840833333334, 0.720385942380952, 0.7206148457142854, 0.7195346999999992, 0.7183420933333329, 0.7158494833333333, 0.7037475000000001, 0.6149051966666659, 0.6224923750000001, 0.6257169750000006, 0.6252232499999993, 0.6250071666666661, 0.6218184500000002, 0.6204209000000006, 0.6172277333333324, 0.6164101195238092, 0.615724990000001, 0.6146921399999996, 0.6021825249999998, 0.6041431399999996, 0.6049543150000006, 0.6064000666666673, 0.6115030985714285, 0.6164101195238092, 0.6170726799999988, 0.6180032000000005, 0.6205839066666662, 0.6218184500000002, 0.6230565366666679, 0.6260962999999999, 0.6261729, 0.6260997166666668, 0.6256166833333332, 0.6042515000000012], \"yaxis\": \"y\"}, {\"hovertemplate\": \"variable=GB Result<br>index=%{x}<br>value=%{y}<extra></extra>\", \"legendgroup\": \"GB Result\", \"line\": {\"color\": \"#00cc96\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"GB Result\", \"showlegend\": true, \"type\": \"scattergl\", \"x\": [0, 2, 4, 6, 7, 10, 15, 23, 31, 42, 44, 45, 47, 51, 55, 61, 62, 67, 68, 71, 77, 87, 93, 96, 97, 101, 109, 115, 122, 123, 125, 126, 129, 136, 154, 155, 157, 159, 160, 165, 167, 179, 183, 186, 197, 202, 210, 212, 219, 223, 229, 230, 232, 234, 237, 243, 244, 245, 248, 251, 252, 253, 256, 261, 266, 270, 272, 273, 274, 275, 278, 295, 298, 299, 302, 303, 310, 313, 320, 324, 325, 335, 340, 343, 344, 345, 357, 363, 371, 373, 381, 385, 386, 393, 398, 402, 410, 412, 418, 419, 422, 430, 431, 437, 438, 454, 455, 457, 461, 463, 464, 471, 475, 476, 477, 478, 479, 481, 483, 485, 486, 488, 498, 503, 504, 513, 515, 517, 527, 530, 532, 534, 538, 542, 544, 547, 553, 564, 565, 571, 572, 573, 576, 582, 586, 587, 591, 599, 605, 611, 614, 626, 627, 631, 635, 636, 639, 641, 651, 659, 660, 661, 664, 669, 671, 675, 676, 679, 681, 686, 688, 690, 701, 703, 708, 710, 712, 713, 714, 718, 720, 722, 724, 731, 736, 739, 744, 749, 750, 751, 758, 764, 770, 771, 778, 782, 783, 793, 794, 795, 798, 803, 815, 818, 819, 825, 827, 834, 837, 842, 843, 848, 849, 856, 867, 872, 873, 876, 877, 879, 886, 888, 889, 890, 895, 902, 903, 906, 921, 922, 923, 925, 930, 935, 937, 940, 944, 945, 949, 950, 959, 963, 964, 967, 969, 975, 976, 979, 982, 983, 995, 1001, 1002, 1004, 1008, 1012, 1014, 1019, 1022, 1031, 1033, 1040, 1041, 1044, 1047, 1052, 1057, 1058, 1059, 1060, 1062, 1065, 1069, 1070, 1071, 1074, 1085, 1089, 1092, 1099, 1102, 1115, 1117, 1118, 1121, 1130, 1133, 1135, 1138, 1139, 1141, 1148, 1155, 1158, 1162, 1167, 1168, 1169, 1170, 1175, 1177, 1180, 1183, 1189, 1193, 1195, 1197, 1205, 1206, 1210, 1212, 1215, 1218, 1220, 1222, 1225, 1226, 1230, 1231, 1233, 1234, 1235, 1239, 1242, 1244, 1246, 1251, 1259, 1262, 1268, 1270, 1271, 1275, 1279, 1280, 1282, 1284, 1293, 1301, 1309, 1310, 1312, 1318, 1324, 1333, 1334, 1350, 1352, 1356, 1357, 1361, 1366, 1370, 1371, 1374, 1387, 1388, 1392, 1393, 1408, 1409, 1413, 1414, 1416, 1417, 1421, 1425, 1426, 1431, 1435, 1437, 1440, 1450, 1460, 1466, 1467, 1469, 1486, 1495, 1497, 1501, 1502, 1505, 1507, 1511, 1530, 1531, 1535, 1537, 1541, 1549, 1554, 1558, 1564, 1565, 1566, 1568, 1570, 1573, 1582, 1584, 1588, 1596, 1597, 1598, 1602, 1604, 1607, 1609, 1611, 1613, 1615, 1616, 1621, 1628, 1630, 1631, 1642, 1644, 1645, 1651, 1658, 1661, 1662, 1663, 1665, 1666, 1668, 1670, 1671, 1680, 1690, 1696, 1700, 1701, 1703, 1710, 1711, 1713, 1717, 1725, 1729, 1738, 1742, 1743, 1753, 1759, 1769, 1771, 1773, 1775, 1789, 1799, 1800, 1804, 1808, 1815, 1816, 1819, 1828, 1833, 1837, 1849, 1850, 1851, 1854, 1862], \"xaxis\": \"x\", \"y\": [0.9864329890528565, 1.2895187247466013, 1.887839421455548, 1.630978581803836, 1.2452660578569754, 2.0604488136196286, 3.021370554529656, 3.026569670185672, 2.951759766161385, 0.8992067436594149, 0.9328637804298477, 0.9328637804298477, 0.9291757721119204, 1.0594558602632915, 1.0594558602632915, 1.1049685675819652, 1.1049685675819652, 1.1049685675819652, 1.1049685675819652, 1.1049685675819652, 1.0594558602632915, 0.688933100476364, 0.81081136259557, 0.8709421249916856, 0.8785749935562, 0.8785749935562, 0.8785749935562, 0.8957644789210091, 0.9038458225077828, 0.9038458225077828, 0.9038458225077828, 0.9130338369231075, 0.9284250535932369, 0.9038458225077828, 0.8785749935562, 0.8785749935562, 0.8785749935562, 0.8785749935562, 0.8785749935562, 0.860821352772585, 0.6602812613343659, 0.7774221681643008, 0.7774221681643008, 0.7774221681643008, 0.7774221681643008, 0.7774221681643008, 0.7774221681643008, 0.7769512039417318, 0.7769512039417318, 0.7769512039417318, 0.7903182967001061, 0.788532909357835, 0.788532909357835, 0.788532909357835, 0.7805435295387532, 0.7805435295387532, 0.7805435295387532, 0.7805435295387532, 0.7805435295387532, 0.7821822880498784, 0.788532909357835, 0.788532909357835, 0.788532909357835, 0.7769512039417318, 0.7769512039417318, 0.7769512039417318, 0.7769512039417318, 0.7769512039417318, 0.7769512039417318, 0.7778677374634659, 0.7774221681643008, 0.7774221681643008, 0.7774221681643008, 0.7774221681643008, 0.7774221681643008, 0.7774221681643008, 0.7663368327327276, 0.6755664314473829, 2.966087490187119, 2.920553967323411, 2.920553967323411, 2.920553967323411, 2.966087490187119, 2.0476955718964724, 1.5957197837840973, 1.2384426978907614, 1.1025487717481863, 1.1050024242517054, 1.1483393243882436, 1.1483393243882436, 1.1050024242517054, 1.1050024242517054, 1.1025487717481863, 0.9100720258855751, 0.820436289807277, 0.9175574755232917, 0.9251903440878061, 0.9251903440878061, 0.9251903440878061, 0.9251903440878061, 0.9413224201293062, 0.9379313945970185, 0.9379313945970185, 0.9379313945970185, 0.9379313945970185, 0.9251903440878061, 0.9251903440878061, 0.9251903440878061, 0.9251903440878061, 0.9251903440878061, 0.9251903440878061, 0.902969523580547, 0.820436289807277, 0.6504787451430782, 0.6504787451430782, 0.7094807996956662, 0.7509470408310999, 0.7908488219868266, 0.8077665544321588, 0.8126747543596988, 0.8126747543596988, 0.8126747543596988, 0.8126747543596988, 0.8126747543596988, 0.8126747543596988, 0.8126747543596988, 0.8126747543596988, 0.813120323658864, 0.8122037901371298, 0.8122037901371298, 0.8058531688291732, 0.8106842277005905, 0.8157961157341512, 0.8157961157341512, 0.8157961157341512, 0.8157961157341512, 0.8157961157341512, 0.8106842277005905, 0.8058531688291732, 0.8122037901371298, 0.8122037901371298, 0.8122037901371298, 0.8122037901371298, 0.8126747543596988, 0.8126747543596988, 0.8126747543596988, 0.8126747543596988, 0.8126747543596988, 0.8126747543596988, 0.8126747543596988, 0.8126747543596988, 1.701537159938472, 1.9500460325910427, 2.222996683325925, 2.8443306576548366, 2.8597448410047015, 3.3652625529017297, 3.563042266599458, 3.563042266599458, 3.133819572764986, 3.0936719955253387, 2.222996683325925, 1.0523419113359824, 1.3293508443938247, 1.3896340973909032, 1.409239755378468, 1.409239755378468, 1.4737883741286453, 1.4737883741286453, 1.5171252742651835, 1.538934566459708, 1.5744226722019277, 1.5171252742651835, 1.4737883741286453, 1.409239755378468, 1.409239755378468, 1.3896340973909032, 1.3896340973909032, 1.3896340973909032, 1.0269398248272898, 1.0681512801844562, 1.0681512801844562, 1.0681512801844562, 1.213683238680374, 1.213683238680374, 1.213683238680374, 1.2291548151343439, 1.2382817017804266, 1.2382817017804266, 1.2382817017804266, 1.2382817017804266, 1.2382817017804266, 1.2382817017804266, 1.2382817017804266, 1.213683238680374, 1.213683238680374, 1.213683238680374, 1.213683238680374, 1.2060503701158594, 1.1646135219863287, 0.7640498984363605, 0.8761964482763288, 1.0674611621441232, 1.0674611621441232, 1.0674611621441232, 1.0674611621441232, 1.0674611621441232, 1.0674611621441232, 1.0674611621441232, 1.0674611621441232, 1.0674611621441232, 1.0735488506892854, 1.0671982293813287, 1.0655594708702032, 1.0771411762863063, 1.0771411762863063, 1.0771411762863063, 1.0771411762863063, 1.0771411762863063, 1.0771411762863063, 1.0771411762863063, 1.0771411762863063, 1.0771411762863063, 1.0771411762863063, 1.0655594708702032, 1.0671982293813287, 1.0671982293813287, 1.0735488506892854, 1.0674611621441232, 1.0674611621441232, 1.0674611621441232, 1.0674611621441232, 1.0674611621441232, 1.0674611621441232, 1.0674611621441232, 1.0674611621441232, 1.0437185505078999, 1.027709629614886, 0.9792445504490591, 1.3072331352506243, 3.9393077705479644, 3.9410168696394634, 3.9410168696394634, 3.9514620822341975, 3.9410168696394634, 3.9120892166255126, 3.750455036031155, 2.7947110850846273, 1.3072331352506243, 0.9792445504490591, 1.5326221674121878, 1.516065516955738, 1.5607510970257517, 1.5607510970257517, 1.5607510970257517, 1.5607510970257517, 1.5607510970257517, 1.516065516955738, 1.5326221674121878, 1.293446777508136, 1.0487957986263978, 1.0317163985983995, 1.1071656641624976, 1.255923601967385, 1.255923601967385, 1.255923601967385, 1.255923601967385, 1.255923601967385, 1.255923601967385, 1.255923601967385, 1.2805220650674376, 1.2805220650674376, 1.2805220650674376, 1.2805220650674376, 1.274913712365461, 1.274913712365461, 1.2805220650674376, 1.2805220650674376, 1.2805220650674376, 1.255923601967385, 1.255923601967385, 0.9795974491262012, 0.8774868296907592, 0.6312518019559055, 0.7621290171749652, 1.11774947468803, 1.11774947468803, 1.11774947468803, 1.11774947468803, 1.11774947468803, 1.11774947468803, 1.11774947468803, 1.11774947468803, 1.1169627897676644, 1.1169771625932488, 1.1169771625932488, 1.1169771625932488, 1.1137490890598678, 1.1137490890598678, 1.109801618952109, 1.1125893034848966, 1.1156349750140424, 1.1156349750140424, 1.1156349750140424, 1.1156349750140424, 1.1156349750140424, 1.1156349750140424, 1.1156349750140424, 1.1156349750140424, 1.1103636849568173, 1.109801618952109, 1.1137490890598678, 1.1169771625932488, 1.1169771625932488, 1.1169771625932488, 1.1178936961149828, 1.1148780280056478, 1.11774947468803, 1.11774947468803, 1.11774947468803, 1.11774947468803, 1.11774947468803, 1.11774947468803, 1.11774947468803, 1.11774947468803, 1.11774947468803, 1.11774947468803, 1.11284127476049, 1.0664127936310757, 1.1043953890665439, 1.4313787235778044, 1.6343624434478905, 1.1018598631610064, 2.278341379849481, 2.2731370797951445, 2.5585531324789845, 2.5861711168200068, 2.59657817298273, 2.4268024555945815, 0.7700485123085165, 0.7783663943235041, 0.8040514345427527, 0.8322964767413286, 0.8342215826841828, 0.8342215826841828, 0.8342215826841828, 0.7783663943235041, 0.6131826667622724, 0.6131826667622724, 0.6617263876604725, 0.6794800284440875, 0.6794800284440875, 0.6794800284440875, 0.6794800284440875, 0.6794800284440875, 0.688857562897216, 0.688857562897216, 0.797105652182256, 0.8050950320013379, 0.6841859897107774, 0.6794800284440875, 0.6794800284440875, 0.6794800284440875, 0.6794800284440875, 0.6794800284440875, 0.6794800284440875, 0.6794800284440875, 0.6718471598795731, 0.5948522362093263, 0.5948522362093263, 0.5948522362093263, 0.5948522362093263, 0.5948522362093263, 0.5948522362093263, 0.5929150027079424, 0.5929150027079424, 0.5929150027079424, 0.5838974523589014, 0.5922029548153317, 0.5922029548153317, 0.6001923346344136, 0.6001923346344136, 0.5838974523589014, 0.5838974523589014, 0.5886191749332769, 0.5948522362093263, 0.5948522362093263, 0.5948522362093263, 0.5948522362093263, 0.5948522362093263, 0.5948522362093263, 0.5948522362093263, 0.5948522362093263, 0.5837669007777531, 0.573026303836454, 1.0062959519443744, 1.3470263439032302, 1.8064828817193466, 2.125857126767671, 2.307024745347214, 2.2910129083024846, 2.2902845970904107, 1.3470263439032302, 0.9934329933320318, 1.0062959519443744, 0.8103953268934885, 0.8564102031186308, 0.8567875544175236, 0.870210722863201, 0.87266437536672, 0.87266437536672, 0.8730987375382289, 0.8730987375382289, 0.8759422655750744, 0.8730987375382289, 0.87266437536672, 0.87266437536672, 0.7741335798075177, 0.7488574795718116, 0.6059515072298238, 0.7058744286592118, 0.7139370273779382, 0.7139370273779382, 0.7139370273779382, 0.7139370273779382, 0.7139370273779382, 0.7139370273779382, 0.7139370273779382, 0.7139370273779382, 0.7139370273779382, 0.7105460018456504, 0.7105460018456504, 0.7139370273779382, 0.7139370273779382, 0.7139370273779382, 0.7139370273779382, 0.7139370273779382, 0.7058744286592118, 0.7058744286592118, 0.6982415600946974, 0.6005877181577407, 0.6224136505306129, 0.6224136505306129, 0.6224136505306129, 0.6224136505306129, 0.6224136505306129, 0.6224136505306129, 0.6204764170292291, 0.6204764170292291, 0.6204764170292291, 0.6204764170292291, 0.6034694868611062, 0.6051082453722315, 0.6051082453722315, 0.6114588666801881, 0.6161805892545635, 0.6204764170292291, 0.6204764170292291, 0.6204764170292291, 0.6224136505306129, 0.6224136505306129, 0.6224136505306129, 0.6224136505306129, 0.6224136505306129, 0.6224136505306129, 0.6224136505306129, 0.5978194404594416], \"yaxis\": \"y\"}],                        {\"legend\": {\"title\": {\"text\": \"variable\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"index\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"value\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('5075cf45-1516-406f-9d97-7f070d59998a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torep = pd.DataFrame(y_test.values, columns = ['Data'], index=y_test.index)\n",
    "torep['RF Result'] = RFResult\n",
    "torep['GB Result'] = GBResult\n",
    "TOREP = torep.iloc[:, :].sort_index()\n",
    "TOREP.plot(x=TOREP.index, y=['Data', 'RF Result', 'GB Result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test).reset_index(drop=True)[:40].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(DenseRMSpropPrediction4)[:40].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "426.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
