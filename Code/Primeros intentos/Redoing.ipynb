{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8605b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019c346",
   "metadata": {},
   "source": [
    "# Cuadrados 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef29d037",
   "metadata": {},
   "source": [
    "## 5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d339b5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "pddopen5 = pd.read_csv('OPEN/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "pcropen5 = pd.read_csv('OPEN/txt/5x5/5x5pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "pinopen5 = pd.read_csv('OPEN/txt/5x5/5x5pro-in-100.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "\n",
    "pddFFF5 = pd.read_csv('FFF/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
    "pcrFFF5 = pd.read_csv('FFF/txt/5x5/5x5pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
    "pinFFF5 = pd.read_csv('FFF/txt/5x5/5x5pro-in-100.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c88df",
   "metadata": {},
   "source": [
    "## 10x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9945d1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "pddopen10 = pd.read_csv('OPEN/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "pcropen10 = pd.read_csv('OPEN/txt/10x10/10x10pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "pinopen10 = pd.read_csv('OPEN/txt/10x10/10x10pro-in-100.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "\n",
    "pddFFF10 = pd.read_csv('FFF/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
    "pcrFFF10 = pd.read_csv('FFF/txt/10x10/10x10pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
    "pinFFF10 = pd.read_csv('FFF/txt/10x10/10x10pro-in-100.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbeede9",
   "metadata": {},
   "source": [
    "## 20x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0e24717",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "pddopen20 = pd.read_csv('OPEN/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "pcropen20 = pd.read_csv('OPEN/txt/20x20/20x20pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "pinopen20 = pd.read_csv('OPEN/txt/20x20/20x20pro-in-100.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "\n",
    "pddFFF20 = pd.read_csv('FFF/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
    "pcrFFF20 = pd.read_csv('FFF/txt/20x20/20x20pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
    "pinFFF20 = pd.read_csv('FFF/txt/20x20/20x20pro-in-100.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f339a46f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 40x40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35cf3d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "pddopen40 = pd.read_csv('OPEN/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "pcropen40 = pd.read_csv('OPEN/txt/40x40/40x40pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "pinopen40 = pd.read_csv('OPEN/txt/40x40/40x40pro-in-100.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "\n",
    "pddFFF40 = pd.read_csv('FFF/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
    "pcrFFF40 = pd.read_csv('FFF/txt/40x40/40x40pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
    "pinFFF40 = pd.read_csv('FFF/txt/40x40/40x40pro-in-100.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4531bba",
   "metadata": {},
   "source": [
    "# Cuadrados 115"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105a6bd7",
   "metadata": {},
   "source": [
    "## 5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59cf23bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "pddopen5_115 = pd.read_csv('OPEN/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "pcropen5_115 = pd.read_csv('OPEN/txt/5x5/5x5pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "pinopen5_115 = pd.read_csv('OPEN/txt/5x5/5x5pro-in-115.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "\n",
    "pddFFF5_115 = pd.read_csv('FFF/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
    "pcrFFF5_115 = pd.read_csv('FFF/txt/5x5/5x5pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
    "pinFFF5_115 = pd.read_csv('FFF/txt/5x5/5x5pro-in-115.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a47c0",
   "metadata": {},
   "source": [
    "## 10x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c54b0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "pddopen10_115 = pd.read_csv('OPEN/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "pcropen10_115 = pd.read_csv('OPEN/txt/10x10/10x10pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "pinopen10_115 = pd.read_csv('OPEN/txt/10x10/10x10pro-in-115.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "\n",
    "pddFFF10_115 = pd.read_csv('FFF/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
    "pcrFFF10_115 = pd.read_csv('FFF/txt/10x10/10x10pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
    "pinFFF10_115 = pd.read_csv('FFF/txt/10x10/10x10pro-in-115.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d9041",
   "metadata": {},
   "source": [
    "## 20x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "687e7947",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "pddopen20_115 = pd.read_csv('OPEN/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "pcropen20_115 = pd.read_csv('OPEN/txt/20x20/20x20pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "pinopen20_115 = pd.read_csv('OPEN/txt/20x20/20x20pro-in-115.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "\n",
    "pddFFF20_115 = pd.read_csv('FFF/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
    "pcrFFF20_115 = pd.read_csv('FFF/txt/20x20/20x20pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
    "pinFFF20_115 = pd.read_csv('FFF/txt/20x20/20x20pro-in-115.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a58fe",
   "metadata": {},
   "source": [
    "## 40x40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88cb2bc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "pddopen40_115 = pd.read_csv('OPEN/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "pcropen40_115 = pd.read_csv('OPEN/txt/40x40/40x40pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "pinopen40_115 = pd.read_csv('OPEN/txt/40x40/40x40pro-in-115.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "\n",
    "pddFFF40_115 = pd.read_csv('FFF/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
    "pcrFFF40_115 = pd.read_csv('FFF/txt/40x40/40x40pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
    "pinFFF40_115 = pd.read_csv('FFF/txt/40x40/40x40pro-in-115.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5438186e",
   "metadata": {},
   "source": [
    "# 85"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d00a8a",
   "metadata": {},
   "source": [
    "## 5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d36d5869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "pddopen5_85 = pd.read_csv('OPEN/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "pcropen5_85 = pd.read_csv('OPEN/txt/5x5/5x5pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "pinopen5_85 = pd.read_csv('OPEN/txt/5x5/5x5pro-in-85.txt', delimiter='\t\t', names=['r', 'señal open 5x5', 'error open 5x5'])\n",
    "\n",
    "pddFFF5_85 = pd.read_csv('FFF/txt/5x5/5x5pdd.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
    "pcrFFF5_85 = pd.read_csv('FFF/txt/5x5/5x5pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n",
    "pinFFF5_85 = pd.read_csv('FFF/txt/5x5/5x5pro-in-85.txt', delimiter='\t\t', names=['r', 'señal fff 5x5', 'error fff 5x5'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b946e4d5",
   "metadata": {},
   "source": [
    "## 10x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46d19212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "pddopen10_85 = pd.read_csv('OPEN/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "pcropen10_85 = pd.read_csv('OPEN/txt/10x10/10x10pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "pinopen10_85 = pd.read_csv('OPEN/txt/10x10/10x10pro-in-85.txt', delimiter='\t\t', names=['r', 'señal open 10x10', 'error open 10x10'])\n",
    "\n",
    "pddFFF10_85 = pd.read_csv('FFF/txt/10x10/10x10pdd.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
    "pcrFFF10_85 = pd.read_csv('FFF/txt/10x10/10x10pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n",
    "pinFFF10_85 = pd.read_csv('FFF/txt/10x10/10x10pro-in-85.txt', delimiter='\t\t', names=['r', 'señal fff 10x10', 'error fff 10x10'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa31482",
   "metadata": {},
   "source": [
    "## 20x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c04053a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "pddopen20_85 = pd.read_csv('OPEN/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "pcropen20_85 = pd.read_csv('OPEN/txt/20x20/20x20pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "pinopen20_85 = pd.read_csv('OPEN/txt/20x20/20x20pro-in-85.txt', delimiter='\t\t', names=['r', 'señal open 20x20', 'error open 20x20'])\n",
    "\n",
    "pddFFF20_85 = pd.read_csv('FFF/txt/20x20/20x20pdd.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
    "pcrFFF20_85 = pd.read_csv('FFF/txt/20x20/20x20pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n",
    "pinFFF20_85 = pd.read_csv('FFF/txt/20x20/20x20pro-in-85.txt', delimiter='\t\t', names=['r', 'señal fff 20x20', 'error fff 20x20'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d1ec83",
   "metadata": {},
   "source": [
    "## 40x40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4494ab02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "pddopen40_85 = pd.read_csv('OPEN/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "pcropen40_85 = pd.read_csv('OPEN/txt/40x40/40x40pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "pinopen40_85 = pd.read_csv('OPEN/txt/40x40/40x40pro-in-85.txt', delimiter='\t\t', names=['r', 'señal open 40x40', 'error open 40x40'])\n",
    "\n",
    "pddFFF40_85 = pd.read_csv('FFF/txt/40x40/40x40pdd.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
    "pcrFFF40_85 = pd.read_csv('FFF/txt/40x40/40x40pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n",
    "pinFFF40_85 = pd.read_csv('FFF/txt/40x40/40x40pro-in-85.txt', delimiter='\t\t', names=['r', 'señal fff 40x40', 'error fff 40x40'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47ad251",
   "metadata": {},
   "source": [
    "# Merge Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88ffe1d",
   "metadata": {},
   "source": [
    "## Z = 100; In = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eafa01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF5 = pinFFF5.iloc[:,:2]\n",
    "FFF5['FFF'] = 1\n",
    "FFF5.columns = ['r', 'señal', 'FFF']\n",
    "FFF5['Area'] = 25\n",
    "FFF5['Limit'] = 25\n",
    "\n",
    "Open5 = pinopen5.iloc[:,:2]\n",
    "Open5['FFF'] = 0\n",
    "Open5.columns = ['r', 'señal', 'FFF']\n",
    "Open5['Area'] = 25\n",
    "Open5['Limit'] = 25\n",
    "\n",
    "FFF10 = pinFFF10.iloc[:,:2]\n",
    "FFF10['FFF'] = 1\n",
    "FFF10.columns = ['r', 'señal', 'FFF']\n",
    "FFF10['Area'] = 100\n",
    "FFF10['Limit'] = 50\n",
    "\n",
    "Open10 = pinopen10.iloc[:,:2]\n",
    "Open10['FFF'] = 0\n",
    "Open10.columns = ['r', 'señal', 'FFF']\n",
    "Open10['Area'] = 100\n",
    "Open10['Limit'] = 50\n",
    "\n",
    "FFF20 = pinFFF20.iloc[:,:2]\n",
    "FFF20['FFF'] = 1\n",
    "FFF20.columns = ['r', 'señal', 'FFF']\n",
    "FFF20['Area'] = 400\n",
    "FFF20['Limit'] = 100\n",
    "\n",
    "Open20 = pinopen20.iloc[:,:2]\n",
    "Open20['FFF'] = 0\n",
    "Open20.columns = ['r', 'señal', 'FFF']\n",
    "Open20['Area'] = 400\n",
    "Open20['Limit'] = 100\n",
    "\n",
    "FFF40 = pinFFF40.iloc[:,:2]\n",
    "FFF40['FFF'] = 1\n",
    "FFF40.columns = ['r', 'señal', 'FFF']\n",
    "FFF40['Area'] = 1600\n",
    "FFF40['Limit'] = 200\n",
    "\n",
    "Open40 = pinopen40.iloc[:,:2]\n",
    "Open40['FFF'] = 0\n",
    "Open40.columns = ['r', 'señal', 'FFF']\n",
    "Open40['Area'] = 1600\n",
    "Open40['Limit'] = 200\n",
    "\n",
    "MixedIN = pd.concat([Open5, FFF5, Open10, FFF10, Open20, FFF20, Open40, FFF40]) \n",
    "MixedIN['In'] = 1\n",
    "MixedIN['Z'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea94e06",
   "metadata": {},
   "source": [
    "## Z = 100; In = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "274ac79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF5 = pcrFFF5.iloc[:,:2]\n",
    "FFF5['FFF'] = 1\n",
    "FFF5.columns = ['r', 'señal', 'FFF']\n",
    "FFF5['Area'] = 25\n",
    "FFF5['Limit'] = 25\n",
    "\n",
    "Open5 = pcropen5.iloc[:,:2]\n",
    "Open5['FFF'] = 0\n",
    "Open5.columns = ['r', 'señal', 'FFF']\n",
    "Open5['Area'] = 25\n",
    "Open5['Limit'] = 25\n",
    "\n",
    "FFF10 = pcrFFF10.iloc[:,:2]\n",
    "FFF10['FFF'] = 1\n",
    "FFF10.columns = ['r', 'señal', 'FFF']\n",
    "FFF10['Area'] = 100\n",
    "FFF10['Limit'] = 50\n",
    "\n",
    "Open10 = pcropen10.iloc[:,:2]\n",
    "Open10['FFF'] = 0\n",
    "Open10.columns = ['r', 'señal', 'FFF']\n",
    "Open10['Area'] = 100\n",
    "Open10['Limit'] = 50\n",
    "\n",
    "FFF20 = pcrFFF20.iloc[:,:2]\n",
    "FFF20['FFF'] = 1\n",
    "FFF20.columns = ['r', 'señal', 'FFF']\n",
    "FFF20['Area'] = 400\n",
    "FFF20['Limit'] = 100\n",
    "\n",
    "Open20 = pcropen20.iloc[:,:2]\n",
    "Open20['FFF'] = 0\n",
    "Open20.columns = ['r', 'señal', 'FFF']\n",
    "Open20['Area'] = 400\n",
    "Open20['Limit'] = 100\n",
    "\n",
    "FFF40 = pcrFFF40.iloc[:,:2]\n",
    "FFF40['FFF'] = 1\n",
    "FFF40.columns = ['r', 'señal', 'FFF']\n",
    "FFF40['Area'] = 1600\n",
    "FFF40['Limit'] = 200\n",
    "\n",
    "Open40 = pcropen40.iloc[:,:2]\n",
    "Open40['FFF'] = 0\n",
    "Open40.columns = ['r', 'señal', 'FFF']\n",
    "Open40['Area'] = 1600\n",
    "Open40['Limit'] = 200\n",
    "\n",
    "MixedCR = pd.concat([Open5, FFF5, Open10, FFF10, Open20, FFF20, Open40, FFF40]) \n",
    "MixedCR['In'] = 0\n",
    "MixedCR['Z'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b55f35",
   "metadata": {},
   "source": [
    "## Z = 85; In = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5309703",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF5 = pinFFF5_85.iloc[:,:2]\n",
    "FFF5['FFF'] = 1\n",
    "FFF5.columns = ['r', 'señal', 'FFF']\n",
    "FFF5['Area'] = 25\n",
    "FFF5['Limit'] = 25\n",
    "\n",
    "Open5 = pinopen5_85.iloc[:,:2]\n",
    "Open5['FFF'] = 0\n",
    "Open5.columns = ['r', 'señal', 'FFF']\n",
    "Open5['Area'] = 25\n",
    "Open5['Limit'] = 25\n",
    "\n",
    "FFF10 = pinFFF10_85.iloc[:,:2]\n",
    "FFF10['FFF'] = 1\n",
    "FFF10.columns = ['r', 'señal', 'FFF']\n",
    "FFF10['Area'] = 100\n",
    "FFF10['Limit'] = 50\n",
    "\n",
    "Open10 = pinopen10_85.iloc[:,:2]\n",
    "Open10['FFF'] = 0\n",
    "Open10.columns = ['r', 'señal', 'FFF']\n",
    "Open10['Area'] = 100\n",
    "Open10['Limit'] = 50\n",
    "\n",
    "FFF20 = pinFFF20_85.iloc[:,:2]\n",
    "FFF20['FFF'] = 1\n",
    "FFF20.columns = ['r', 'señal', 'FFF']\n",
    "FFF20['Area'] = 400\n",
    "FFF20['Limit'] = 100\n",
    "\n",
    "Open20 = pinopen20_85.iloc[:,:2]\n",
    "Open20['FFF'] = 0\n",
    "Open20.columns = ['r', 'señal', 'FFF']\n",
    "Open20['Area'] = 400\n",
    "Open20['Limit'] = 100\n",
    "\n",
    "FFF40 = pinFFF40_85.iloc[:,:2]\n",
    "FFF40['FFF'] = 1\n",
    "FFF40.columns = ['r', 'señal', 'FFF']\n",
    "FFF40['Area'] = 1600\n",
    "FFF40['Limit'] = 200\n",
    "\n",
    "Open40 = pinopen40_85.iloc[:,:2]\n",
    "Open40['FFF'] = 0\n",
    "Open40.columns = ['r', 'señal', 'FFF']\n",
    "Open40['Area'] = 1600\n",
    "Open40['Limit'] = 200\n",
    "\n",
    "MixedIN85 = pd.concat([Open5, FFF5, Open10, FFF10, Open20, FFF20, Open40, FFF40]) \n",
    "MixedIN85['In'] = 1\n",
    "MixedIN85['Z'] = 85"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ee668c",
   "metadata": {},
   "source": [
    "## Z = 85; In = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "388074ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF5 = pcrFFF5_85.iloc[:,:2]\n",
    "FFF5['FFF'] = 1\n",
    "FFF5.columns = ['r', 'señal', 'FFF']\n",
    "FFF5['Area'] = 25\n",
    "FFF5['Limit'] = 25\n",
    "\n",
    "Open5 = pcropen5_85.iloc[:,:2]\n",
    "Open5['FFF'] = 0\n",
    "Open5.columns = ['r', 'señal', 'FFF']\n",
    "Open5['Area'] = 25\n",
    "Open5['Limit'] = 25\n",
    "\n",
    "FFF10 = pcrFFF10_85.iloc[:,:2]\n",
    "FFF10['FFF'] = 1\n",
    "FFF10.columns = ['r', 'señal', 'FFF']\n",
    "FFF10['Area'] = 100\n",
    "FFF10['Limit'] = 50\n",
    "\n",
    "Open10 = pcropen10_85.iloc[:,:2]\n",
    "Open10['FFF'] = 0\n",
    "Open10.columns = ['r', 'señal', 'FFF']\n",
    "Open10['Area'] = 100\n",
    "Open10['Limit'] = 50\n",
    "\n",
    "FFF20 = pcrFFF20_85.iloc[:,:2]\n",
    "FFF20['FFF'] = 1\n",
    "FFF20.columns = ['r', 'señal', 'FFF']\n",
    "FFF20['Area'] = 400\n",
    "FFF20['Limit'] = 100\n",
    "\n",
    "Open20 = pcropen20_85.iloc[:,:2]\n",
    "Open20['FFF'] = 0\n",
    "Open20.columns = ['r', 'señal', 'FFF']\n",
    "Open20['Area'] = 400\n",
    "Open20['Limit'] = 100\n",
    "\n",
    "FFF40 = pcrFFF40_85.iloc[:,:2]\n",
    "FFF40['FFF'] = 1\n",
    "FFF40.columns = ['r', 'señal', 'FFF']\n",
    "FFF40['Area'] = 1600\n",
    "FFF40['Limit'] = 200\n",
    "\n",
    "Open40 = pcropen40_85.iloc[:,:2]\n",
    "Open40['FFF'] = 0\n",
    "Open40.columns = ['r', 'señal', 'FFF']\n",
    "Open40['Area'] = 1600\n",
    "Open40['Limit'] = 200\n",
    "\n",
    "MixedCR85 = pd.concat([Open5, FFF5, Open10, FFF10, Open20, FFF20, Open40, FFF40]) \n",
    "MixedCR85['In'] = 0\n",
    "MixedCR85['Z'] = 85\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda89b3d",
   "metadata": {},
   "source": [
    "## Z = 115; In = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fca7e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF5 = pinFFF5_115.iloc[:,:2]\n",
    "FFF5['FFF'] = 1\n",
    "FFF5.columns = ['r', 'señal', 'FFF']\n",
    "FFF5['Area'] = 25\n",
    "FFF5['Limit'] = 25\n",
    "\n",
    "Open5 = pinopen5_115.iloc[:,:2]\n",
    "Open5['FFF'] = 0\n",
    "Open5.columns = ['r', 'señal', 'FFF']\n",
    "Open5['Area'] = 25\n",
    "Open5['Limit'] = 25\n",
    "\n",
    "FFF10 = pinFFF10_115.iloc[:,:2]\n",
    "FFF10['FFF'] = 1\n",
    "FFF10.columns = ['r', 'señal', 'FFF']\n",
    "FFF10['Area'] = 100\n",
    "FFF10['Limit'] = 50\n",
    "\n",
    "Open10 = pinopen10_115.iloc[:,:2]\n",
    "Open10['FFF'] = 0\n",
    "Open10.columns = ['r', 'señal', 'FFF']\n",
    "Open10['Area'] = 100\n",
    "Open10['Limit'] = 50\n",
    "\n",
    "FFF20 = pinFFF20_115.iloc[:,:2]\n",
    "FFF20['FFF'] = 1\n",
    "FFF20.columns = ['r', 'señal', 'FFF']\n",
    "FFF20['Area'] = 400\n",
    "FFF20['Limit'] = 100\n",
    "\n",
    "Open20 = pinopen20_115.iloc[:,:2]\n",
    "Open20['FFF'] = 0\n",
    "Open20.columns = ['r', 'señal', 'FFF']\n",
    "Open20['Area'] = 400\n",
    "Open20['Limit'] = 100\n",
    "\n",
    "FFF40 = pinFFF40_115.iloc[:,:2]\n",
    "FFF40['FFF'] = 1\n",
    "FFF40.columns = ['r', 'señal', 'FFF']\n",
    "FFF40['Area'] = 1600\n",
    "FFF40['Limit'] = 200\n",
    "\n",
    "Open40 = pinopen40_115.iloc[:,:2]\n",
    "Open40['FFF'] = 0\n",
    "Open40.columns = ['r', 'señal', 'FFF']\n",
    "Open40['Area'] = 1600\n",
    "Open40['Limit'] = 200\n",
    "\n",
    "MixedIN115 = pd.concat([Open5, FFF5, Open10, FFF10, Open20, FFF20, Open40, FFF40]) \n",
    "MixedIN115['In'] = 1\n",
    "MixedIN115['Z'] = 115"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa62e57",
   "metadata": {},
   "source": [
    "## Z = 115; In = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f75c2c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF5 = pcrFFF5_115.iloc[:,:2]\n",
    "FFF5['FFF'] = 1\n",
    "FFF5.columns = ['r', 'señal', 'FFF']\n",
    "FFF5['Area'] = 25\n",
    "FFF5['Limit'] = 25\n",
    "\n",
    "Open5 = pcropen5_115.iloc[:,:2]\n",
    "Open5['FFF'] = 0\n",
    "Open5.columns = ['r', 'señal', 'FFF']\n",
    "Open5['Area'] = 25\n",
    "Open5['Limit'] = 25\n",
    "\n",
    "FFF10 = pcrFFF10_115.iloc[:,:2]\n",
    "FFF10['FFF'] = 1\n",
    "FFF10.columns = ['r', 'señal', 'FFF']\n",
    "FFF10['Area'] = 100\n",
    "FFF10['Limit'] = 50\n",
    "\n",
    "Open10 = pcropen10_115.iloc[:,:2]\n",
    "Open10['FFF'] = 0\n",
    "Open10.columns = ['r', 'señal', 'FFF']\n",
    "Open10['Area'] = 100\n",
    "Open10['Limit'] = 50\n",
    "\n",
    "FFF20 = pcrFFF20_115.iloc[:,:2]\n",
    "FFF20['FFF'] = 1\n",
    "FFF20.columns = ['r', 'señal', 'FFF']\n",
    "FFF20['Area'] = 400\n",
    "FFF20['Limit'] = 100\n",
    "\n",
    "Open20 = pcropen20_115.iloc[:,:2]\n",
    "Open20['FFF'] = 0\n",
    "Open20.columns = ['r', 'señal', 'FFF']\n",
    "Open20['Area'] = 400\n",
    "Open20['Limit'] = 100\n",
    "\n",
    "FFF40 = pcrFFF40_115.iloc[:,:2]\n",
    "FFF40['FFF'] = 1\n",
    "FFF40.columns = ['r', 'señal', 'FFF']\n",
    "FFF40['Area'] = 1600\n",
    "FFF40['Limit'] = 200\n",
    "\n",
    "Open40 = pcropen40_115.iloc[:,:2]\n",
    "Open40['FFF'] = 0\n",
    "Open40.columns = ['r', 'señal', 'FFF']\n",
    "Open40['Area'] = 1600\n",
    "Open40['Limit'] = 200\n",
    "\n",
    "MixedCR115 = pd.concat([Open5, FFF5, Open10, FFF10, Open20, FFF20, Open40, FFF40]) \n",
    "MixedCR115['In'] = 0\n",
    "MixedCR115['Z'] = 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac1286bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mixed = pd.concat([MixedCR, MixedIN, MixedIN85, MixedCR85, MixedCR115, MixedIN115]).reset_index(drop=True)\n",
    "Mixed['Limit'] = Mixed['Limit'].values*2\n",
    "Mixed = Mixed.loc[:,['r', 'señal', 'FFF', 'Limit', 'In', 'Z']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06ada41",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\\\\[ \\Phi_\\gamma (x,y,z) = w_0 \\Phi_0(x,y,z) \\Phi_{horn}^\\gamma (x,y,z) \\\\]\n",
    "\n",
    "Primero calcularemos \\\\(\\Phi_0^\\gamma\\\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90143c4",
   "metadata": {},
   "source": [
    "\\\\[ \\Phi_\\alpha = Z(z; z_D^x, z_D^y, z_\\alpha) T_\\alpha(x_\\alpha^+, x_\\alpha^-) T_\\alpha(y_\\alpha^+, y_\\alpha^- ) \\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbdc318",
   "metadata": {},
   "source": [
    "\\\\[ Z(z; z^x_D, z^y_D, z_0) = \\frac{1}{4} \\frac{(z_D^x - z_0) (z^y_D - z_0 )}{(z-z_0)^2} \\\\]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Donde \\\\( z_U^x  = 43.1cm ; z_U^y = 29.8cm ; z^x_D = 50.9cm ; z_D^y= 42.6cm \\\\)\n",
    "\n",
    "\n",
    "\\\\[ Z(z; z^x_D, z^y_D, z_0) = \\frac{1}{4} \\frac{(50.9 - z_0) (42.6 - z_0 )}{(z-z_0)^2} \\\\]\n",
    "\\\\[ Z(z; z^x_D, z^y_D, z_s) = \\frac{1}{4} \\frac{(50.9 - z_s) (42.6 - z_s )}{(z-z_s)^2} \\\\]\n",
    "\n",
    "\n",
    "Vamos a establecer z_0 como 0\n",
    "\n",
    "\\\\[ Z(z; z^x_D, z^y_D, z_0) = \\frac{1}{4} \\frac{(50.9) (42.6)}{(z)^2} \\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff262400",
   "metadata": {},
   "source": [
    "# Z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07b903d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_s = []\n",
    "\n",
    "for i in np.arange(0, Mixed.shape[0]):\n",
    "    if Mixed['FFF'].loc[i]==1:\n",
    "        Z_s.append(12.47)\n",
    "    else:\n",
    "        Z_s.append(0)\n",
    "        \n",
    "Mixed['Zs'] = Z_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3133c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_x_u = 43.1\n",
    "z_y_u = 29.8\n",
    "\n",
    "z_x_d = 50.9\n",
    "z_y_d = 42.6\n",
    "\n",
    "\n",
    "\n",
    "Mixed['Big Z'] = (0.25*z_x_d*z_y_d)/(Mixed['Z']**2)\n",
    "Mixed['Big Z Col'] = (0.25*(z_x_d-Mixed[['Zs']].to_numpy())*(z_y_d-Mixed[['Zs']].to_numpy()))/(Mixed[['Z']].to_numpy()**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890eded3",
   "metadata": {},
   "source": [
    "Por tanto:\n",
    "\n",
    "\\\\[X_0 = \\frac{\\frac{x_0^+}{\\delta_0}}{\\sqrt{1+\\frac{x_0^+}{\\delta_0}}} + \\frac{\\frac{x_0^-}{\\delta_0}}{\\sqrt{1-\\frac{x_0^-}{\\delta_0}}}\\\\]\n",
    "\n",
    "\\\\[Y_0 = \\frac{\\frac{y_0^+}{\\delta_0}}{\\sqrt{1+\\frac{y_0^+}{\\delta_0}}} + \\frac{\\frac{y_0^-}{\\delta_0}}{\\sqrt{1-\\frac{y_0^-}{\\delta_0}}}\\\\]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4704cd1",
   "metadata": {},
   "source": [
    "\\\\[ \\Phi_\\alpha = \\frac{542.085}{z^2}* (\\frac{\\frac{x_0^+}{\\delta_0}}{\\sqrt{1+\\frac{x_0^+}{\\delta_0}}} + \\frac{\\frac{x_0^-}{\\delta_0}}{\\sqrt{1-\\frac{x_0^-}{\\delta_0}}}) * (\\frac{\\frac{y_0^+}{\\delta_0}}{\\sqrt{1+\\frac{y_0^+}{\\delta_0}}} + \\frac{\\frac{y_0^-}{\\delta_0}}{\\sqrt{1-\\frac{y_0^-}{\\delta_0}}}) \\\\]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72caf90",
   "metadata": {},
   "source": [
    "Donde \\\\(x_\\alpha; y_\\alpha\\\\)\n",
    "\n",
    "\\\\[x_\\alpha^{\\pm}  = min[\\frac{w_I^xz_U^x(z-z_0) \\pm 2xz_I(z_0 - z_U^x)}{2z_I(z-z_U^x)}, \\frac{w_I^xz_D^x(z-z_0) \\pm 2xz_I (z_0-z_D^x)}{2z_I(z-z_D^x)}] \\\\]\n",
    "\n",
    "\\\\[y_\\alpha^{\\pm}  = min[\\frac{w_I^yz_U^y(z-z_0) \\pm 2yz_I(z_0 - z_U^y)}{2z_I(z-z_U^y)}, \\frac{w_I^yz_D^y(z-z_0) \\pm 2yz_I (z_0-z_D^y)}{2z_I(z-z_D^y)}] \\\\]\n",
    "\n",
    "\n",
    "Por tanto sabiendo que \\\\(z_0\\\\) es 0 y \\\\Z_I = 100\\\\)\n",
    "\n",
    "\\\\[x_\\alpha^{\\pm} = min[ \\frac{43.1*w_I^x*z \\pm -8620*x}{200(z-43.1)} , \\frac{ 50.9* w_I^x*(z) \\pm -10180*x* }{200(z-50.9)}] \\\\]\n",
    "\n",
    "\\\\[y_\\alpha^{\\pm}  = min[\\frac{29.8*w_I^y * z \\pm -5960*y}{200(z-29.8)}, \\frac{42.6*w_I^y*(z) \\pm -8520*y)}{200(z-42.6)}] \\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ec3ca",
   "metadata": {},
   "source": [
    "# Ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf36ccb",
   "metadata": {},
   "source": [
    "In = 1 -> X \n",
    "In = 0 -> Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52606a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def pos_neg(number, zs):\n",
    "\n",
    "    x_01pos = []\n",
    "    x_01neg = []\n",
    "    x_02pos = []\n",
    "    x_02neg = []\n",
    "    y_01pos = []\n",
    "    y_01neg = []\n",
    "    y_02pos = []\n",
    "    y_02neg = []\n",
    "\n",
    "    for i in np.arange(number, Mixed.shape[0]):\n",
    "        if Mixed[['In']].loc[i].to_numpy() == 1:\n",
    "            x_01pos.append(float((z_x_u*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs) + (zs - z_x_u)*2*100*Mixed[['r']].loc[i].to_numpy())/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_x_u))))\n",
    "            x_01neg.append(float((z_x_u*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs) - (zs - z_x_u)*2*100*Mixed[['r']].loc[i].to_numpy())/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_x_u))))\n",
    "            x_02pos.append(float((z_x_d*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs) + (zs - z_x_u)*2*100*Mixed[['r']].loc[i].to_numpy())/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_x_d))))\n",
    "            x_02neg.append(float((z_x_d*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs) - (zs - z_x_u)*2*100*Mixed[['r']].loc[i].to_numpy())/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_x_d))))\n",
    "\n",
    "            y_01pos.append(float((z_y_u*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs))/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_y_u))))\n",
    "            y_01neg.append(float((z_y_u*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs))/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_y_u))))\n",
    "            y_02pos.append(float((z_y_d*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs))/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_y_d))))\n",
    "            y_02neg.append(float((z_y_d*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs))/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_y_d))))\n",
    "\n",
    "\n",
    "\n",
    "        else:    \n",
    "            x_01pos.append(float((z_x_u*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs))/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_x_u))))\n",
    "            x_01neg.append(float((z_x_u*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs))/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_x_u))))\n",
    "            x_02pos.append(float((z_x_d*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs))/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_x_d))))\n",
    "            x_02neg.append(float((z_x_d*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs))/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_x_d))))\n",
    "\n",
    "\n",
    "            y_01pos.append(float((z_y_u*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs) + (zs - z_y_u)*2*100*Mixed[['r']].loc[i].to_numpy())/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_y_u))))\n",
    "            y_01neg.append(float((z_y_u*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs) - (zs - z_y_u)*2*100*Mixed[['r']].loc[i].to_numpy())/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_y_u))))\n",
    "            y_02pos.append(float((z_y_d*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs) + (zs - z_y_u)*2*100*Mixed[['r']].loc[i].to_numpy())/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_y_d))))\n",
    "            y_02neg.append(float((z_y_d*Mixed[['Limit']].loc[i].to_numpy()*(Mixed[['Z']].loc[i].to_numpy()-zs) - (zs - z_y_u)*2*100*Mixed[['r']].loc[i].to_numpy())/(2*100*(Mixed[['Z']].loc[i].to_numpy() - z_y_d))))\n",
    "\n",
    "\n",
    "\n",
    "    x_0pos = []\n",
    "    for i, j in zip(x_01pos, x_02pos):\n",
    "        if i<j:\n",
    "            x_0pos.append(float(i))\n",
    "        else:\n",
    "            x_0pos.append(float(j))\n",
    "\n",
    "    y_0pos = []\n",
    "    for i, j in zip(y_01pos, y_02pos):\n",
    "        if i<j:\n",
    "            y_0pos.append(float(i))\n",
    "        else:\n",
    "            y_0pos.append(float(j))\n",
    "\n",
    "\n",
    "    x_0neg = []\n",
    "    for i, j in zip(x_01neg, x_02neg):\n",
    "        if i<j:\n",
    "            x_0neg.append(float(i))\n",
    "        else:\n",
    "            x_0neg.append(float(j))\n",
    "\n",
    "    y_0neg = []\n",
    "    for i, j in zip(y_01neg, y_02neg):\n",
    "        if i<j:\n",
    "            y_0neg.append(float(i))\n",
    "        else:\n",
    "            y_0neg.append(float(j))\n",
    "\n",
    "    if zs==0:\n",
    "        \n",
    "    \n",
    "        Mixed['xpos'] = x_0pos\n",
    "        Mixed['xneg'] = x_0neg\n",
    "\n",
    "        Mixed['ypos'] = y_0pos\n",
    "        Mixed['yneg'] = y_0neg\n",
    "    \n",
    "    if zs!=0:\n",
    "        Mixed['xpos col'] = x_0pos\n",
    "        Mixed['xneg col'] = x_0neg\n",
    "\n",
    "        Mixed['ypos col'] = y_0pos\n",
    "        Mixed['yneg col'] = y_0neg\n",
    "\n",
    "    \n",
    "\n",
    "pos_neg(0, 0)\n",
    "pos_neg(0, Mixed[['Zs']].loc[i].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51021e4a",
   "metadata": {},
   "source": [
    "Volviendo a la ecuación mostrada antes\n",
    "\n",
    "\\\\[ \\Phi_\\alpha = \\frac{542.085}{z^2}* (\\frac{\\frac{x_0^+}{\\delta_0}}{\\sqrt{1+\\frac{x_0^+}{\\delta_0}}} + \\frac{\\frac{x_0^-}{\\delta_0}}{\\sqrt{1+\\frac{x_0^-}{\\delta_0}}}) * (\\frac{\\frac{y_0^+}{\\delta_0}}{\\sqrt{1+\\frac{y_0^+}{\\delta_0}}} + \\frac{\\frac{y_0^-}{\\delta_0}}{\\sqrt{1+\\frac{y_0^-}{\\delta_0}}}) \\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a44f12",
   "metadata": {},
   "source": [
    "\\\\[ \\Phi_\\gamma (x,y,z) = w_0 \\Phi_0(x,y,z) \\Phi_{horn}^\\gamma (x,y,z) \\\\]\n",
    "\n",
    "w_0 es la importancia de la fluencia primaria, que es la que estamos usando únicamente.\n",
    "\n",
    "\\\\[ \\Phi_\\gamma (x,y,z) = \\Phi_0(x,y,z) * \\Phi_{horn}^\\gamma (x,y,z) \\\\]\n",
    "\n",
    "\n",
    "Por lo que tenemos ya una de las dos partes, ahora calculamos \\\\(\\phi^\\gamma_{horn}\\\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e750970",
   "metadata": {},
   "source": [
    "\\\\[\\Phi_{horn} = 1+ \\rho^2\\sum^4_{j=0} h_j^{\\gamma, e} \\rho^j \\\\]\n",
    "\n",
    "Donde\n",
    "\n",
    "\\\\[\\rho = \\frac{\\sqrt{x^2 + y^2}}{z-z_0} \\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd01cc9",
   "metadata": {},
   "source": [
    "# Rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "526c708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mixed['Rho'] = np.abs((Mixed['r']))/(Mixed['Z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74bd822",
   "metadata": {},
   "source": [
    "# Analytic equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "393ad1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv('Scores30Oct.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32d0d453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta 0 = 1.55; h0 = 125.0; h1 =-2625.0; h2 = 40000.0; h3 = -762500.0h; 4 =725000.0\n"
     ]
    }
   ],
   "source": [
    "print(scores.loc[0]['Combination used'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7073a490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 0.85, 1.15])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIXEDF0['Z'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f9bb9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Arg1 = (Mixed[Mixed['FFF']==0]['xpos']/1.55)/((1 + (Mixed[Mixed['FFF']==0]['xpos']/1.55)**2)**(1/2))\n",
    "Arg2 = (Mixed[Mixed['FFF']==0]['xneg']/1.55)/((1 + (Mixed[Mixed['FFF']==0]['xneg']/1.55)**2)**(1/2))\n",
    "\n",
    "Arg3 = (Mixed[Mixed['FFF']==0]['ypos']/1.55)/((1 + (Mixed[Mixed['FFF']==0]['ypos']/1.55)**2)**(1/2))\n",
    "Arg4 = (Mixed[Mixed['FFF']==0]['yneg']/1.55)/((1 + (Mixed[Mixed['FFF']==0]['yneg']/1.55)**2)**(1/2))\n",
    "\n",
    "a = Mixed[Mixed['FFF']==0]['Big Z'] * (Arg1+Arg2) * (Arg3+Arg4) * (1 + (Mixed[Mixed['FFF']==0]['Rho']**2) * (125.01 * Mixed[Mixed['FFF']==0]['Rho'] -2625 * Mixed[Mixed['FFF']==0]['Rho'] + 40000 * Mixed[Mixed['FFF']==0]['Rho'] -762500 * Mixed[Mixed['FFF']==0]['Rho'] + 725000 * Mixed[Mixed['FFF']==0]['Rho']))\n",
    "\n",
    "a = a.reset_index(drop=True)\n",
    "\n",
    "MIXEDF0 = Mixed[Mixed['FFF']==0].reset_index(drop=True)\n",
    "\n",
    "\n",
    "NewA = []\n",
    "for i in np.arange(0, len(a)):\n",
    "    if MIXEDF0.loc[i, 'Limit']== 400:\n",
    "        NewA.append(a[i]*3.573564632926567)\n",
    "    if MIXEDF0.loc[i, 'Limit']== 200:\n",
    "        NewA.append(a[i]*4.256146812362383)\n",
    "    if MIXEDF0.loc[i, 'Limit']== 100:\n",
    "        NewA.append(a[i]*5.250154520100614)\n",
    "    if MIXEDF0.loc[i, 'Limit']== 50:\n",
    "        NewA.append(a[i]*14.7506341128751757)\n",
    "\n",
    "\n",
    "\n",
    "MIXEDF0['Analytic function'] = NewA\n",
    "MIXEDF0['x'] = Arg1*Arg2\n",
    "MIXEDF0['y'] = Arg3*Arg4\n",
    "MIXEDF0['2nd leg'] = Arg3*Arg4*Arg1*Arg2\n",
    "MIXEDF0['Signal'] = MIXEDF0['señal'] \n",
    "MIXEDF0['r (cm)'] = MIXEDF0['r'] \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ffef6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = MIXEDF0.set_index('r')[['señal']]\n",
    "x = MIXEDF0[['r', 'Limit', 'In', 'Z', 'Big Z', 'xpos', 'ypos', 'xneg', 'yneg', 'Rho', 'Analytic function']]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1e34a1",
   "metadata": {},
   "source": [
    "# Trying Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a1658daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0f246744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f24492a",
   "metadata": {},
   "source": [
    "## Dense Adamax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a2a20358",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.5165 - MAE: 0.5165\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.4383 - MAE: 0.4383\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.3834 - MAE: 0.3834\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.3579 - MAE: 0.3579\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.3398 - MAE: 0.3398\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.3239 - MAE: 0.3239\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 891us/step - loss: 0.3056 - MAE: 0.3056\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 992us/step - loss: 0.2804 - MAE: 0.2804\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.2550 - MAE: 0.2550\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.2317 - MAE: 0.2317\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 982us/step - loss: 0.2151 - MAE: 0.2151\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 745us/step - loss: 0.1978 - MAE: 0.1978\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1925 - MAE: 0.1925\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1877 - MAE: 0.1877\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1712 - MAE: 0.1712\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1678 - MAE: 0.1678\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.1618 - MAE: 0.1618\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1614 - MAE: 0.1614\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.1556 - MAE: 0.1556\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 896us/step - loss: 0.1486 - MAE: 0.1486\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1562 - MAE: 0.1562\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 949us/step - loss: 0.1554 - MAE: 0.1554\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 884us/step - loss: 0.1381 - MAE: 0.1381\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 785us/step - loss: 0.1383 - MAE: 0.1383\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 794us/step - loss: 0.1369 - MAE: 0.1369 0s - loss: \n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 968us/step - loss: 0.1327 - MAE: 0.1327\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 951us/step - loss: 0.1333 - MAE: 0.1333\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 996us/step - loss: 0.1286 - MAE: 0.1286\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 891us/step - loss: 0.1244 - MAE: 0.1244\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 872us/step - loss: 0.1244 - MAE: 0.1244\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 992us/step - loss: 0.1176 - MAE: 0.1176\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 967us/step - loss: 0.1168 - MAE: 0.1168\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 867us/step - loss: 0.1173 - MAE: 0.1173\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 917us/step - loss: 0.1132 - MAE: 0.1132\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 879us/step - loss: 0.1089 - MAE: 0.1089\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 869us/step - loss: 0.1083 - MAE: 0.1083\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 867us/step - loss: 0.1019 - MAE: 0.1019\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 894us/step - loss: 0.1051 - MAE: 0.1051\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.1075 - MAE: 0.1075\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 916us/step - loss: 0.1001 - MAE: 0.1001\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.1004 - MAE: 0.1004\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 887us/step - loss: 0.0920 - MAE: 0.0920\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 916us/step - loss: 0.0921 - MAE: 0.0921\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0940 - MAE: 0.0940\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 947us/step - loss: 0.0944 - MAE: 0.0944\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 878us/step - loss: 0.0902 - MAE: 0.0902\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0897 - MAE: 0.0897\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.0823 - MAE: 0.0823\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 908us/step - loss: 0.0899 - MAE: 0.0899\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 901us/step - loss: 0.0795 - MAE: 0.0795\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 863us/step - loss: 0.0817 - MAE: 0.0817\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0843 - MAE: 0.0843\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 916us/step - loss: 0.0792 - MAE: 0.0792\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 899us/step - loss: 0.0756 - MAE: 0.0756\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 914us/step - loss: 0.0806 - MAE: 0.0806\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0791 - MAE: 0.0791\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0724 - MAE: 0.0724\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0798 - MAE: 0.0798\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 863us/step - loss: 0.0766 - MAE: 0.0766\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 907us/step - loss: 0.0779 - MAE: 0.0779\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 932us/step - loss: 0.0726 - MAE: 0.0726\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 932us/step - loss: 0.0760 - MAE: 0.0760\n",
      "Test score: 0.07395046286455154\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ModelDenseAdamax1 = Sequential()\n",
    "ModelDenseAdamax1.add(Dense(14))\n",
    "ModelDenseAdamax1.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdamax1.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdamax1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax1.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax1.fit(x_train.values, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseAdamaxPrediction1 = ModelDenseAdamax1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ebaa724f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 943us/step - loss: 2.0905 - MAE: 2.0905\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.6447 - MAE: 0.6447\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.4970 - MAE: 0.4970\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.4779 - MAE: 0.4779\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.4589 - MAE: 0.4589\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 798us/step - loss: 0.4506 - MAE: 0.4506\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 957us/step - loss: 0.4399 - MAE: 0.4399\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.4357 - MAE: 0.4357\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.4176 - MAE: 0.4176\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.3999 - MAE: 0.3999\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.3922 - MAE: 0.3922\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.3844 - MAE: 0.3844\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.3770 - MAE: 0.3770\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.3754 - MAE: 0.3754\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 969us/step - loss: 0.3716 - MAE: 0.3716\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.3572 - MAE: 0.3572\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 790us/step - loss: 0.3645 - MAE: 0.3645\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 786us/step - loss: 0.3601 - MAE: 0.3601\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 750us/step - loss: 0.3561 - MAE: 0.3561\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 978us/step - loss: 0.3469 - MAE: 0.3469\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 858us/step - loss: 0.3403 - MAE: 0.3403\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 777us/step - loss: 0.3398 - MAE: 0.3398\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.3126 - MAE: 0.3126\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.3241 - MAE: 0.3241\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.3159 - MAE: 0.3159\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 768us/step - loss: 0.3077 - MAE: 0.3077\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.3140 - MAE: 0.3140\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 845us/step - loss: 0.3009 - MAE: 0.3009\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.2913 - MAE: 0.2913\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 755us/step - loss: 0.2915 - MAE: 0.2915\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 787us/step - loss: 0.2861 - MAE: 0.2861\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 809us/step - loss: 0.2802 - MAE: 0.2802\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.2612 - MAE: 0.2612\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 858us/step - loss: 0.2716 - MAE: 0.2716\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 870us/step - loss: 0.2568 - MAE: 0.2568\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.2505 - MAE: 0.2505\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.2460 - MAE: 0.2460\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 893us/step - loss: 0.2480 - MAE: 0.2480\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 892us/step - loss: 0.2341 - MAE: 0.2341\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 869us/step - loss: 0.2498 - MAE: 0.2498\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 840us/step - loss: 0.2410 - MAE: 0.2410\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.2386 - MAE: 0.2386\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 852us/step - loss: 0.2331 - MAE: 0.2331\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.2270 - MAE: 0.2270\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.2370 - MAE: 0.2370\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.2217 - MAE: 0.2217\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 871us/step - loss: 0.2235 - MAE: 0.2235\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.2257 - MAE: 0.2257\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.2194 - MAE: 0.2194\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.2177 - MAE: 0.2177\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.2102 - MAE: 0.2102\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 887us/step - loss: 0.2145 - MAE: 0.2145\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 851us/step - loss: 0.2062 - MAE: 0.2062\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 841us/step - loss: 0.2096 - MAE: 0.2096\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 793us/step - loss: 0.2148 - MAE: 0.2148\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.2044 - MAE: 0.2044\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.2036 - MAE: 0.2036\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.2116 - MAE: 0.2116\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.2093 - MAE: 0.2093\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.2040 - MAE: 0.2040\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.2055 - MAE: 0.2055\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.1951 - MAE: 0.1951\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.1972 - MAE: 0.1972\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 885us/step - loss: 0.1953 - MAE: 0.1953\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.1925 - MAE: 0.1925\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.1913 - MAE: 0.1913\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.1852 - MAE: 0.1852\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 807us/step - loss: 0.1988 - MAE: 0.1988\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.1867 - MAE: 0.1867\n",
      "Epoch 70/100\n",
      "2160/2160 [==============================] - 2s 786us/step - loss: 0.1883 - MAE: 0.1883\n",
      "Epoch 71/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.1852 - MAE: 0.1852\n",
      "Epoch 72/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1823 - MAE: 0.1823\n",
      "Epoch 73/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.1788 - MAE: 0.1788\n",
      "Epoch 74/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.1831 - MAE: 0.1831\n",
      "Epoch 75/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.1856 - MAE: 0.1856\n",
      "Epoch 76/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.1779 - MAE: 0.1779\n",
      "Epoch 77/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.1828 - MAE: 0.1828\n",
      "Epoch 78/100\n",
      "2160/2160 [==============================] - 2s 880us/step - loss: 0.1800 - MAE: 0.1800\n",
      "Epoch 79/100\n",
      "2160/2160 [==============================] - 2s 893us/step - loss: 0.1753 - MAE: 0.1753\n",
      "Epoch 80/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.1813 - MAE: 0.1813\n",
      "Epoch 81/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.1705 - MAE: 0.1705\n",
      "Epoch 82/100\n",
      "2160/2160 [==============================] - 2s 885us/step - loss: 0.1793 - MAE: 0.1793\n",
      "Epoch 83/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.1674 - MAE: 0.1674\n",
      "Epoch 84/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.1748 - MAE: 0.1748\n",
      "Epoch 85/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.1737 - MAE: 0.1737\n",
      "Epoch 86/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.1694 - MAE: 0.1694\n",
      "Epoch 87/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.1748 - MAE: 0.1748\n",
      "Epoch 88/100\n",
      "2160/2160 [==============================] - 2s 852us/step - loss: 0.1652 - MAE: 0.1652\n",
      "Epoch 89/100\n",
      "2160/2160 [==============================] - 2s 798us/step - loss: 0.1637 - MAE: 0.1637\n",
      "Epoch 90/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.1648 - MAE: 0.1648\n",
      "Epoch 91/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.1640 - MAE: 0.1640\n",
      "Epoch 92/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1589 - MAE: 0.1589\n",
      "Epoch 93/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.1579 - MAE: 0.1579\n",
      "Epoch 94/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.1551 - MAE: 0.1551\n",
      "Epoch 95/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.1541 - MAE: 0.1541\n",
      "Epoch 96/100\n",
      "2160/2160 [==============================] - 2s 857us/step - loss: 0.1569 - MAE: 0.1569\n",
      "Epoch 97/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.1546 - MAE: 0.1546\n",
      "Epoch 98/100\n",
      "2160/2160 [==============================] - 2s 806us/step - loss: 0.1545 - MAE: 0.1545\n",
      "Epoch 99/100\n",
      "2160/2160 [==============================] - 2s 807us/step - loss: 0.1518 - MAE: 0.1518\n",
      "Epoch 100/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.1457 - MAE: 0.1457\n",
      "Test score: 0.09205336981029062\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ModelDenseAdamax1_1 = Sequential()\n",
    "ModelDenseAdamax1_1.add(Dense(14))\n",
    "ModelDenseAdamax1_1.add(Dropout(0.1))\n",
    "ModelDenseAdamax1_1.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdamax1_1.add(Dropout(0.1))\n",
    "ModelDenseAdamax1_1.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdamax1_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax1_1.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax1_1.fit(x_train.values, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseAdamaxPrediction1_1 = ModelDenseAdamax1_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction1_1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc5d667d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 1.6984 - MAE: 1.6984\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.9850 - MAE: 0.9850\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 987us/step - loss: 0.7988 - MAE: 0.7988\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.6202 - MAE: 0.6202\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.5520 - MAE: 0.5520\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.4936 - MAE: 0.4936\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.4257 - MAE: 0.4257\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.3856 - MAE: 0.3856\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 776us/step - loss: 0.2823 - MAE: 0.2823\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 938us/step - loss: 0.2605 - MAE: 0.2605\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.2434 - MAE: 0.2434\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 886us/step - loss: 0.2167 - MAE: 0.2167\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.1968 - MAE: 0.1968\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 853us/step - loss: 0.1902 - MAE: 0.1902\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.1798 - MAE: 0.1798\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 830us/step - loss: 0.1687 - MAE: 0.1687\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.1639 - MAE: 0.1639\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 863us/step - loss: 0.1559 - MAE: 0.1559\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 843us/step - loss: 0.1555 - MAE: 0.1555\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.1499 - MAE: 0.1499\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.1414 - MAE: 0.1414\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.1424 - MAE: 0.1424\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.1334 - MAE: 0.1334\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 996us/step - loss: 0.1294 - MAE: 0.1294\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 873us/step - loss: 0.1278 - MAE: 0.1278\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.1255 - MAE: 0.1255\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.1207 - MAE: 0.1207\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 840us/step - loss: 0.1258 - MAE: 0.1258\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 873us/step - loss: 0.1171 - MAE: 0.1171\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.1193 - MAE: 0.1193\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 792us/step - loss: 0.1177 - MAE: 0.1177\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 884us/step - loss: 0.1109 - MAE: 0.1109\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.1117 - MAE: 0.1117\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 0.1123 - MAE: 0.1123\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 842us/step - loss: 0.1099 - MAE: 0.1099\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 875us/step - loss: 0.1095 - MAE: 0.1095\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 835us/step - loss: 0.1088 - MAE: 0.1088\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.1035 - MAE: 0.1035\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 857us/step - loss: 0.1032 - MAE: 0.1032\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.1040 - MAE: 0.1040\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 962us/step - loss: 0.1002 - MAE: 0.1002\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 912us/step - loss: 0.1008 - MAE: 0.1008\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 845us/step - loss: 0.1019 - MAE: 0.1019\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 999us/step - loss: 0.1016 - MAE: 0.1016\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 949us/step - loss: 0.1007 - MAE: 0.1007\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.0971 - MAE: 0.0971\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 805us/step - loss: 0.0972 - MAE: 0.0972\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.0978 - MAE: 0.0978\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 971us/step - loss: 0.0987 - MAE: 0.0987\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 885us/step - loss: 0.0977 - MAE: 0.0977\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 876us/step - loss: 0.0920 - MAE: 0.0920\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.0948 - MAE: 0.0948\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 884us/step - loss: 0.0956 - MAE: 0.0956\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 871us/step - loss: 0.0921 - MAE: 0.0921\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 913us/step - loss: 0.0887 - MAE: 0.0887\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 875us/step - loss: 0.0910 - MAE: 0.0910\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.0909 - MAE: 0.0909\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0899 - MAE: 0.0899\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.0917 - MAE: 0.0917\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 847us/step - loss: 0.0883 - MAE: 0.0883\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.0866 - MAE: 0.0866\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.0856 - MAE: 0.0856\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.0897 - MAE: 0.0897\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.0830 - MAE: 0.0830\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.0843 - MAE: 0.0843\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 855us/step - loss: 0.0862 - MAE: 0.0862\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 853us/step - loss: 0.0846 - MAE: 0.0846\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0832 - MAE: 0.0832\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.0844 - MAE: 0.0844\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.08283143233523978\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdamax2 = Sequential()\n",
    "ModelDenseAdamax2.add(Dense(14))\n",
    "ModelDenseAdamax2.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdamax2.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdamax2.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax2.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax2.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax2.summary()\n",
    "\n",
    "DenseAdamaxPrediction2 = ModelDenseAdamax2.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction2, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ec1392c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 878us/step - loss: 1.8942 - MAE: 1.8942\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.5349 - MAE: 0.5349\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 941us/step - loss: 0.5450 - MAE: 0.5450\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 816us/step - loss: 0.5174 - MAE: 0.5174\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 803us/step - loss: 0.5213 - MAE: 0.5213\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 843us/step - loss: 0.5275 - MAE: 0.5275\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 835us/step - loss: 0.5151 - MAE: 0.5151\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.5235 - MAE: 0.5235\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.5147 - MAE: 0.5147\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 845us/step - loss: 0.5132 - MAE: 0.5132\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.5088 - MAE: 0.5088\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.5108 - MAE: 0.5108\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.4975 - MAE: 0.4975\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 845us/step - loss: 0.4974 - MAE: 0.4974\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.4829 - MAE: 0.4829\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 877us/step - loss: 0.4808 - MAE: 0.4808\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.4714 - MAE: 0.4714\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 798us/step - loss: 0.4754 - MAE: 0.4754\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.4590 - MAE: 0.4590\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 880us/step - loss: 0.4544 - MAE: 0.4544\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.4516 - MAE: 0.4516\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.4527 - MAE: 0.4527\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.4463 - MAE: 0.4463\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 843us/step - loss: 0.4402 - MAE: 0.4402\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.4281 - MAE: 0.4281\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.4392 - MAE: 0.4392\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 833us/step - loss: 0.4393 - MAE: 0.4393\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 852us/step - loss: 0.4524 - MAE: 0.4524\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.4206 - MAE: 0.4206\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 916us/step - loss: 0.4182 - MAE: 0.4182\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.4077 - MAE: 0.4077\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 857us/step - loss: 0.3986 - MAE: 0.3986\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 843us/step - loss: 0.3954 - MAE: 0.3954\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.3822 - MAE: 0.3822\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 871us/step - loss: 0.3815 - MAE: 0.3815\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.3797 - MAE: 0.3797\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.3731 - MAE: 0.3731\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 858us/step - loss: 0.3735 - MAE: 0.3735\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 863us/step - loss: 0.3682 - MAE: 0.3682\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 876us/step - loss: 0.3734 - MAE: 0.3734\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 794us/step - loss: 0.3680 - MAE: 0.3680\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.3708 - MAE: 0.3708\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 886us/step - loss: 0.3735 - MAE: 0.3735\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 856us/step - loss: 0.3584 - MAE: 0.3584\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.3605 - MAE: 0.3605\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 908us/step - loss: 0.3732 - MAE: 0.3732\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 880us/step - loss: 0.3580 - MAE: 0.3580\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.3608 - MAE: 0.3608\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 988us/step - loss: 0.3558 - MAE: 0.3558\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.3550 - MAE: 0.3550\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 892us/step - loss: 0.3675 - MAE: 0.3675\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.3536 - MAE: 0.3536\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.3564 - MAE: 0.3564\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.3590 - MAE: 0.3590\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 843us/step - loss: 0.3423 - MAE: 0.3423\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 806us/step - loss: 0.3415 - MAE: 0.3415\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.3556 - MAE: 0.3556\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.3393 - MAE: 0.3393\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.3442 - MAE: 0.3442\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.3439 - MAE: 0.3439\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.3421 - MAE: 0.3421\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 851us/step - loss: 0.3445 - MAE: 0.3445\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 868us/step - loss: 0.3490 - MAE: 0.3490\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (1, 14)                   0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (1, 70)                   0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.30670438744456185\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdamax2_1 = Sequential()\n",
    "ModelDenseAdamax2_1.add(Dense(14))\n",
    "ModelDenseAdamax2_1.add(Dropout(0.1))\n",
    "ModelDenseAdamax2_1.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdamax2_1.add(Dropout(0.1))\n",
    "ModelDenseAdamax2_1.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdamax2_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax2_1.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax2_1.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax2_1.summary()\n",
    "\n",
    "DenseAdamaxPrediction2_1 = ModelDenseAdamax2_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction2_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "73bfce15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 864us/step - loss: 0.7540 - MAE: 0.7540\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.4914 - MAE: 0.4914\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.4855 - MAE: 0.4855\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.4740 - MAE: 0.4740\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.4628 - MAE: 0.4628\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.4546 - MAE: 0.4546\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 833us/step - loss: 0.4462 - MAE: 0.4462\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.4406 - MAE: 0.4406\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 859us/step - loss: 0.4369 - MAE: 0.4369\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.4353 - MAE: 0.4353\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 839us/step - loss: 0.4325 - MAE: 0.4325\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.4327 - MAE: 0.4327\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.4241 - MAE: 0.4241\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.4111 - MAE: 0.4111\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.3984 - MAE: 0.3984\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 829us/step - loss: 0.3700 - MAE: 0.3700\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.3163 - MAE: 0.3163\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 781us/step - loss: 0.2808 - MAE: 0.2808\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 894us/step - loss: 0.2712 - MAE: 0.2712\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 841us/step - loss: 0.2612 - MAE: 0.2612\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.2453 - MAE: 0.2453\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.2436 - MAE: 0.2436\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 835us/step - loss: 0.2352 - MAE: 0.2352\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 864us/step - loss: 0.2274 - MAE: 0.2274\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.2337 - MAE: 0.2337\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 806us/step - loss: 0.2198 - MAE: 0.2198\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.2158 - MAE: 0.2158\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.2151 - MAE: 0.2151\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.2136 - MAE: 0.2136\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 867us/step - loss: 0.2105 - MAE: 0.2105\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 816us/step - loss: 0.2075 - MAE: 0.2075\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.2030 - MAE: 0.2030\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 908us/step - loss: 0.2023 - MAE: 0.2023\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 856us/step - loss: 0.2007 - MAE: 0.2007\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 816us/step - loss: 0.1969 - MAE: 0.1969\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.1954 - MAE: 0.1954\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 829us/step - loss: 0.1961 - MAE: 0.1961\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.1926 - MAE: 0.1926\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.1844 - MAE: 0.1844\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 871us/step - loss: 0.1839 - MAE: 0.1839\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1849 - MAE: 0.1849\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.1821 - MAE: 0.1821\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 794us/step - loss: 0.1807 - MAE: 0.1807\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 857us/step - loss: 0.1783 - MAE: 0.1783\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.1715 - MAE: 0.1715\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1690 - MAE: 0.1690\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.1741 - MAE: 0.1741\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.1707 - MAE: 0.1707\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 868us/step - loss: 0.1689 - MAE: 0.1689\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.1658 - MAE: 0.1658\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.1678 - MAE: 0.1678\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 969us/step - loss: 0.1650 - MAE: 0.1650\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.1571 - MAE: 0.1571\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.1559 - MAE: 0.1559\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.1667 - MAE: 0.1667\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 0.1610 - MAE: 0.1610\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.1599 - MAE: 0.1599\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.1548 - MAE: 0.1548\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.1547 - MAE: 0.1547\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.1517 - MAE: 0.1517\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.1533 - MAE: 0.1533\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 863us/step - loss: 0.1508 - MAE: 0.1508\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.1480 - MAE: 0.1480\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.1493 - MAE: 0.1493\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 878us/step - loss: 0.1521 - MAE: 0.1521\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.1420 - MAE: 0.1420\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.1443 - MAE: 0.1443\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.1394 - MAE: 0.1394 \n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 856us/step - loss: 0.1383 - MAE: 0.1383\n",
      "Epoch 70/100\n",
      "2160/2160 [==============================] - 2s 911us/step - loss: 0.1414 - MAE: 0.1414\n",
      "Epoch 71/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.1409 - MAE: 0.1409\n",
      "Epoch 72/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.1366 - MAE: 0.1366\n",
      "Epoch 73/100\n",
      "2160/2160 [==============================] - 2s 988us/step - loss: 0.1359 - MAE: 0.1359\n",
      "Epoch 74/100\n",
      "2160/2160 [==============================] - 2s 883us/step - loss: 0.1296 - MAE: 0.1296\n",
      "Epoch 75/100\n",
      "2160/2160 [==============================] - 2s 855us/step - loss: 0.1335 - MAE: 0.1335\n",
      "Epoch 76/100\n",
      "2160/2160 [==============================] - 2s 841us/step - loss: 0.1323 - MAE: 0.1323\n",
      "Epoch 77/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.1326 - MAE: 0.1326\n",
      "Epoch 78/100\n",
      "2160/2160 [==============================] - 2s 791us/step - loss: 0.1237 - MAE: 0.1237\n",
      "Epoch 79/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.1265 - MAE: 0.1265\n",
      "Epoch 80/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.1246 - MAE: 0.1246\n",
      "Epoch 81/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.1266 - MAE: 0.1266\n",
      "Epoch 82/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.1286 - MAE: 0.1286\n",
      "Epoch 83/100\n",
      "2160/2160 [==============================] - 2s 794us/step - loss: 0.1225 - MAE: 0.1225\n",
      "Epoch 84/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.1213 - MAE: 0.1213\n",
      "Epoch 85/100\n",
      "2160/2160 [==============================] - 2s 869us/step - loss: 0.1242 - MAE: 0.1242\n",
      "Epoch 86/100\n",
      "2160/2160 [==============================] - 2s 863us/step - loss: 0.1157 - MAE: 0.1157\n",
      "Epoch 87/100\n",
      "2160/2160 [==============================] - 2s 793us/step - loss: 0.1143 - MAE: 0.1143\n",
      "Epoch 88/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.1191 - MAE: 0.1191\n",
      "Epoch 89/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.1082 - MAE: 0.1082\n",
      "Epoch 90/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.1096 - MAE: 0.1096\n",
      "Epoch 91/100\n",
      "2160/2160 [==============================] - 2s 869us/step - loss: 0.1068 - MAE: 0.1068\n",
      "Epoch 92/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.1034 - MAE: 0.1034\n",
      "Epoch 93/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.1025 - MAE: 0.1025\n",
      "Epoch 94/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.0991 - MAE: 0.0991\n",
      "Epoch 95/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.0993 - MAE: 0.0993\n",
      "Epoch 96/100\n",
      "2160/2160 [==============================] - 2s 835us/step - loss: 0.1017 - MAE: 0.1017\n",
      "Epoch 97/100\n",
      "2160/2160 [==============================] - 2s 789us/step - loss: 0.0993 - MAE: 0.0993\n",
      "Epoch 98/100\n",
      "2160/2160 [==============================] - 2s 835us/step - loss: 0.0964 - MAE: 0.0964\n",
      "Epoch 99/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.0976 - MAE: 0.0976\n",
      "Epoch 100/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.0981 - MAE: 0.0981\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.07694342452257846\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdamax3 = Sequential()\n",
    "ModelDenseAdamax3.add(Dense(14))\n",
    "ModelDenseAdamax3.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdamax3.add(Dense(7, activation='selu'))\n",
    "ModelDenseAdamax3.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax3.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax3.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax3.summary()\n",
    "\n",
    "DenseAdamaxPrediction3 = ModelDenseAdamax3.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction3, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c681c355",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 2.4078 - MAE: 2.4078\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 1.7826 - MAE: 1.7826 0s - loss: 1.7961 - MAE\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 1.3130 - MAE: 1.3130\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 858us/step - loss: 1.1305 - MAE: 1.1305\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.9342 - MAE: 0.9342\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 947us/step - loss: 0.7928 - MAE: 0.7928\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 843us/step - loss: 0.6461 - MAE: 0.6461\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 833us/step - loss: 0.5997 - MAE: 0.5997\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.4993 - MAE: 0.4993\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.4428 - MAE: 0.4428\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 875us/step - loss: 0.4321 - MAE: 0.4321\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.3590 - MAE: 0.3590\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.3261 - MAE: 0.3261\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.2911 - MAE: 0.2911\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.2753 - MAE: 0.2753\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 869us/step - loss: 0.2445 - MAE: 0.2445\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.2338 - MAE: 0.2338\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 845us/step - loss: 0.2185 - MAE: 0.2185\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.2104 - MAE: 0.2104\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.1937 - MAE: 0.1937\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 809us/step - loss: 0.1810 - MAE: 0.1810\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.1747 - MAE: 0.1747\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.1659 - MAE: 0.1659\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 830us/step - loss: 0.1618 - MAE: 0.1618\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.1529 - MAE: 0.1529\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 954us/step - loss: 0.1482 - MAE: 0.1482\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.1402 - MAE: 0.1402\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 847us/step - loss: 0.1371 - MAE: 0.1371\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 852us/step - loss: 0.1380 - MAE: 0.1380\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.1277 - MAE: 0.1277\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.1285 - MAE: 0.1285\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 856us/step - loss: 0.1176 - MAE: 0.1176\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.1211 - MAE: 0.1211\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 830us/step - loss: 0.1167 - MAE: 0.1167\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 805us/step - loss: 0.1115 - MAE: 0.1115\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 847us/step - loss: 0.1059 - MAE: 0.1059 0s - loss: 0.\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.1040 - MAE: 0.1040\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.1055 - MAE: 0.1055\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.1017 - MAE: 0.1017\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.0967 - MAE: 0.0967\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 853us/step - loss: 0.0943 - MAE: 0.0943\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 858us/step - loss: 0.0919 - MAE: 0.0919\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 806us/step - loss: 0.0890 - MAE: 0.0890\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0880 - MAE: 0.0880\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.0885 - MAE: 0.0885\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 863us/step - loss: 0.0860 - MAE: 0.0860\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 787us/step - loss: 0.0864 - MAE: 0.0864\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.0833 - MAE: 0.0833\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.0840 - MAE: 0.0840\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.0808 - MAE: 0.0808\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 816us/step - loss: 0.0766 - MAE: 0.0766\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 797us/step - loss: 0.0791 - MAE: 0.0791\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.0781 - MAE: 0.0781\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.0781 - MAE: 0.0781\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.0731 - MAE: 0.0731\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 959us/step - loss: 0.0730 - MAE: 0.0730\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.0747 - MAE: 0.0747\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.0732 - MAE: 0.0732\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.0702 - MAE: 0.0702\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 845us/step - loss: 0.0702 - MAE: 0.0702\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.0679 - MAE: 0.0679\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 807us/step - loss: 0.0703 - MAE: 0.0703\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.0667 - MAE: 0.0667\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.0663 - MAE: 0.0663\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.0660 - MAE: 0.0660\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.0639 - MAE: 0.0639\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.0650 - MAE: 0.0650\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 829us/step - loss: 0.0632 - MAE: 0.0632\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 840us/step - loss: 0.0635 - MAE: 0.0635\n",
      "Epoch 70/100\n",
      "2160/2160 [==============================] - 2s 885us/step - loss: 0.0614 - MAE: 0.0614\n",
      "Epoch 71/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.0617 - MAE: 0.0617\n",
      "Epoch 72/100\n",
      "2160/2160 [==============================] - 2s 869us/step - loss: 0.0627 - MAE: 0.0627\n",
      "Epoch 73/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.0618 - MAE: 0.0618\n",
      "Epoch 74/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.0620 - MAE: 0.0620\n",
      "Epoch 75/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.0591 - MAE: 0.0591\n",
      "Epoch 76/100\n",
      "2160/2160 [==============================] - 2s 929us/step - loss: 0.0597 - MAE: 0.0597\n",
      "Epoch 77/100\n",
      "2160/2160 [==============================] - 2s 840us/step - loss: 0.0604 - MAE: 0.0604\n",
      "Epoch 78/100\n",
      "2160/2160 [==============================] - 2s 797us/step - loss: 0.0591 - MAE: 0.0591\n",
      "Epoch 79/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.0595 - MAE: 0.0595\n",
      "Epoch 80/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0597 - MAE: 0.0597\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.04968288016936541\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdamax4 = Sequential()\n",
    "ModelDenseAdamax4.add(Dense(14))\n",
    "ModelDenseAdamax4.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdamax4.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdamax4.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax4.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax4.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax4.summary()\n",
    "\n",
    "DenseAdamaxPrediction4 = ModelDenseAdamax4.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction4, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bfb5a89b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 2.6249 - MAE: 2.6249\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 785us/step - loss: 1.4273 - MAE: 1.4273\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 857us/step - loss: 1.2399 - MAE: 1.2399\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 1.0049 - MAE: 1.0049\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 798us/step - loss: 0.8225 - MAE: 0.8225\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 833us/step - loss: 0.7099 - MAE: 0.7099\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.6031 - MAE: 0.6031\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.4760 - MAE: 0.4760\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.4145 - MAE: 0.4145\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.3628 - MAE: 0.3628\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 833us/step - loss: 0.2990 - MAE: 0.2990\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.2770 - MAE: 0.2770\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 999us/step - loss: 0.2519 - MAE: 0.2519\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.2374 - MAE: 0.2374\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 829us/step - loss: 0.2143 - MAE: 0.2143\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.2020 - MAE: 0.2020\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.1852 - MAE: 0.1852\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 841us/step - loss: 0.1836 - MAE: 0.1836\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 968us/step - loss: 0.1762 - MAE: 0.1762\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1642 - MAE: 0.1642\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.1568 - MAE: 0.1568\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.1538 - MAE: 0.1538\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.1478 - MAE: 0.1478\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 994us/step - loss: 0.1420 - MAE: 0.1420\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1358 - MAE: 0.1358\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.1333 - MAE: 0.1333\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.1319 - MAE: 0.1319\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 843us/step - loss: 0.1293 - MAE: 0.1293\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.1263 - MAE: 0.1263\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.1251 - MAE: 0.1251\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.1205 - MAE: 0.1205\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.1225 - MAE: 0.1225\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 858us/step - loss: 0.1178 - MAE: 0.1178\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 835us/step - loss: 0.1171 - MAE: 0.1171\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.1155 - MAE: 0.1155\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 878us/step - loss: 0.1155 - MAE: 0.1155\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.1131 - MAE: 0.1131\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.1070 - MAE: 0.1070\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 943us/step - loss: 0.1095 - MAE: 0.1095\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.1091 - MAE: 0.1091\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.1064 - MAE: 0.1064 0s - loss: 0.1103 - M\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 805us/step - loss: 0.1041 - MAE: 0.1041\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 783us/step - loss: 0.1018 - MAE: 0.1018\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 855us/step - loss: 0.0991 - MAE: 0.0991\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.0965 - MAE: 0.0965\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.0956 - MAE: 0.0956\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.0934 - MAE: 0.0934\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 800us/step - loss: 0.0939 - MAE: 0.0939\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 805us/step - loss: 0.0928 - MAE: 0.0928\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.0933 - MAE: 0.0933\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.0892 - MAE: 0.0892\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 853us/step - loss: 0.0890 - MAE: 0.0890\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.0842 - MAE: 0.0842\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.0864 - MAE: 0.0864\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.0816 - MAE: 0.0816\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.0819 - MAE: 0.0819\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.0798 - MAE: 0.0798\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 855us/step - loss: 0.0805 - MAE: 0.0805\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.0793 - MAE: 0.0793\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.0780 - MAE: 0.0780\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.0745 - MAE: 0.0745\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 769us/step - loss: 0.0766 - MAE: 0.0766\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.0750 - MAE: 0.0750\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.0710 - MAE: 0.0710\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 868us/step - loss: 0.0709 - MAE: 0.0709\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 884us/step - loss: 0.0694 - MAE: 0.0694\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0713 - MAE: 0.0713\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.0705 - MAE: 0.0705\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 0.0701 - MAE: 0.0701\n",
      "Epoch 70/100\n",
      "2160/2160 [==============================] - 2s 805us/step - loss: 0.0674 - MAE: 0.0674\n",
      "Epoch 71/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.0683 - MAE: 0.0683\n",
      "Epoch 72/100\n",
      "2160/2160 [==============================] - 2s 803us/step - loss: 0.0698 - MAE: 0.0698\n",
      "Epoch 73/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.0659 - MAE: 0.0659\n",
      "Epoch 74/100\n",
      "2160/2160 [==============================] - 2s 876us/step - loss: 0.0662 - MAE: 0.0662\n",
      "Epoch 75/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.0682 - MAE: 0.0682\n",
      "Epoch 76/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.0670 - MAE: 0.0670\n",
      "Epoch 77/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.0653 - MAE: 0.0653\n",
      "Epoch 78/100\n",
      "2160/2160 [==============================] - 2s 873us/step - loss: 0.0646 - MAE: 0.0646\n",
      "Epoch 79/100\n",
      "2160/2160 [==============================] - 2s 803us/step - loss: 0.0639 - MAE: 0.0639\n",
      "Epoch 80/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.0651 - MAE: 0.0651\n",
      "Epoch 81/100\n",
      "2160/2160 [==============================] - 2s 840us/step - loss: 0.0642 - MAE: 0.0642\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.0659 - MAE: 0.0659\n",
      "Epoch 83/100\n",
      "2160/2160 [==============================] - 2s 882us/step - loss: 0.0633 - MAE: 0.0633\n",
      "Epoch 84/100\n",
      "2160/2160 [==============================] - 2s 872us/step - loss: 0.0622 - MAE: 0.0622\n",
      "Epoch 85/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 0.0615 - MAE: 0.0615\n",
      "Epoch 86/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.0637 - MAE: 0.0637\n",
      "Epoch 87/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.0654 - MAE: 0.0654\n",
      "Epoch 88/100\n",
      "2160/2160 [==============================] - 2s 883us/step - loss: 0.0630 - MAE: 0.0630\n",
      "Epoch 89/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.0613 - MAE: 0.0613\n",
      "Epoch 90/100\n",
      "2160/2160 [==============================] - 2s 987us/step - loss: 0.0600 - MAE: 0.0600\n",
      "Epoch 91/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.0595 - MAE: 0.0595\n",
      "Epoch 92/100\n",
      "2160/2160 [==============================] - 2s 786us/step - loss: 0.0601 - MAE: 0.0601\n",
      "Epoch 93/100\n",
      "2160/2160 [==============================] - 2s 783us/step - loss: 0.0614 - MAE: 0.0614\n",
      "Epoch 94/100\n",
      "2160/2160 [==============================] - 2s 791us/step - loss: 0.0595 - MAE: 0.0595\n",
      "Epoch 95/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.0578 - MAE: 0.0578\n",
      "Epoch 96/100\n",
      "2160/2160 [==============================] - 2s 809us/step - loss: 0.0595 - MAE: 0.0595\n",
      "Epoch 97/100\n",
      "2160/2160 [==============================] - 2s 787us/step - loss: 0.0620 - MAE: 0.0620\n",
      "Epoch 98/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.0596 - MAE: 0.0596\n",
      "Epoch 99/100\n",
      "2160/2160 [==============================] - 2s 903us/step - loss: 0.0575 - MAE: 0.0575\n",
      "Epoch 100/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0590 - MAE: 0.0590\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.06645748332060085\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdamax5 = Sequential()\n",
    "ModelDenseAdamax5.add(Dense(14))\n",
    "ModelDenseAdamax5.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdamax5.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdamax5.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax5.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax5.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax5.summary()\n",
    "\n",
    "DenseAdamaxPrediction5 = ModelDenseAdamax5.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction5, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "81e6280d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 857us/step - loss: 4.3559 - MAE: 4.3559\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 2.8054 - MAE: 2.8054\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 0.5323 - MAE: 0.5323\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 794us/step - loss: 0.5184 - MAE: 0.5184\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.5097 - MAE: 0.5097\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 981us/step - loss: 0.4981 - MAE: 0.4981\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.4882 - MAE: 0.4882\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.4634 - MAE: 0.4634\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 830us/step - loss: 0.4359 - MAE: 0.4359\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.4090 - MAE: 0.4090\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.3845 - MAE: 0.3845\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 786us/step - loss: 0.3831 - MAE: 0.3831\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.3705 - MAE: 0.3705\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 798us/step - loss: 0.3558 - MAE: 0.3558\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.3508 - MAE: 0.3508\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.3467 - MAE: 0.3467\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 784us/step - loss: 0.3413 - MAE: 0.3413\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.3359 - MAE: 0.3359\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.3392 - MAE: 0.3392\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.3344 - MAE: 0.3344\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.3296 - MAE: 0.3296\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 916us/step - loss: 0.3211 - MAE: 0.3211\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 774us/step - loss: 0.3324 - MAE: 0.3324\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 851us/step - loss: 0.3167 - MAE: 0.3167\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.3210 - MAE: 0.3210\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 774us/step - loss: 0.3129 - MAE: 0.3129\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.2998 - MAE: 0.2998\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.3109 - MAE: 0.3109\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 847us/step - loss: 0.3054 - MAE: 0.3054\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 893us/step - loss: 0.2924 - MAE: 0.2924\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.2951 - MAE: 0.2951\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.2922 - MAE: 0.2922\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.2902 - MAE: 0.2902\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 0.2874 - MAE: 0.2874\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 913us/step - loss: 0.2867 - MAE: 0.2867\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.2881 - MAE: 0.2881\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.2842 - MAE: 0.2842\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.2763 - MAE: 0.2763\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 855us/step - loss: 0.2693 - MAE: 0.2693\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.2649 - MAE: 0.2649\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.2653 - MAE: 0.2653\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.2674 - MAE: 0.2674\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 793us/step - loss: 0.2637 - MAE: 0.2637\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 792us/step - loss: 0.2695 - MAE: 0.2695\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.2580 - MAE: 0.2580\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.2615 - MAE: 0.2615\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 841us/step - loss: 0.2597 - MAE: 0.2597\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.2642 - MAE: 0.2642\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.2397 - MAE: 0.2397\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 851us/step - loss: 0.2356 - MAE: 0.2356\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 843us/step - loss: 0.2430 - MAE: 0.2430\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.2390 - MAE: 0.2390\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.2179 - MAE: 0.2179\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 942us/step - loss: 0.2058 - MAE: 0.2058\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 917us/step - loss: 0.1847 - MAE: 0.1847\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 856us/step - loss: 0.1782 - MAE: 0.1782 \n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 843us/step - loss: 0.1674 - MAE: 0.1674\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 775us/step - loss: 0.1636 - MAE: 0.1636\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.1569 - MAE: 0.1569\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 882us/step - loss: 0.1624 - MAE: 0.1624\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.1639 - MAE: 0.1639\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 794us/step - loss: 0.1620 - MAE: 0.1620\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.1636 - MAE: 0.1636\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 839us/step - loss: 0.1585 - MAE: 0.1585\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.14229355624134804\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdamax6 = Sequential()\n",
    "ModelDenseAdamax6.add(Dense(14))\n",
    "ModelDenseAdamax6.add(Dense(70))\n",
    "ModelDenseAdamax6.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdamax6.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax6.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax6.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax6.summary()\n",
    "\n",
    "DenseAdamaxPrediction6 = ModelDenseAdamax6.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction6, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a67bc413",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 5.5558 - MAE: 5.5558\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.6789 - MAE: 0.6789\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.5584 - MAE: 0.5584\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 895us/step - loss: 0.5301 - MAE: 0.5301\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.5032 - MAE: 0.5032\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.5056 - MAE: 0.5056\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 864us/step - loss: 0.4980 - MAE: 0.4980\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 830us/step - loss: 0.4932 - MAE: 0.4932\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 803us/step - loss: 0.4881 - MAE: 0.4881\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 774us/step - loss: 0.4860 - MAE: 0.4860\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 797us/step - loss: 0.4765 - MAE: 0.4765\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 883us/step - loss: 0.4824 - MAE: 0.4824\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 881us/step - loss: 0.4764 - MAE: 0.4764\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.4752 - MAE: 0.4752\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.4733 - MAE: 0.4733\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.4865 - MAE: 0.4865\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 856us/step - loss: 0.4729 - MAE: 0.4729\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.4803 - MAE: 0.4803\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 950us/step - loss: 0.4666 - MAE: 0.4666\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.4723 - MAE: 0.4723\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.4673 - MAE: 0.4673\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 787us/step - loss: 0.4634 - MAE: 0.4634\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 797us/step - loss: 0.4621 - MAE: 0.4621\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.4635 - MAE: 0.4635\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.4587 - MAE: 0.4587\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.4625 - MAE: 0.4625\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.4562 - MAE: 0.4562\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 859us/step - loss: 0.4616 - MAE: 0.4616\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 853us/step - loss: 0.4576 - MAE: 0.4576\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.4540 - MAE: 0.4540\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 794us/step - loss: 0.4597 - MAE: 0.4597\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 943us/step - loss: 0.4618 - MAE: 0.4618\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 793us/step - loss: 0.4549 - MAE: 0.4549\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.4598 - MAE: 0.4598\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.4500 - MAE: 0.4500\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.4573 - MAE: 0.4573\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.4779 - MAE: 0.4779\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.4521 - MAE: 0.4521\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.4488 - MAE: 0.4488\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.4747 - MAE: 0.4747\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 843us/step - loss: 0.4496 - MAE: 0.4496\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.4485 - MAE: 0.4485\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 989us/step - loss: 0.4510 - MAE: 0.4510\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 847us/step - loss: 0.4468 - MAE: 0.4468\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.4526 - MAE: 0.4526\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 798us/step - loss: 0.4611 - MAE: 0.4611\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.4560 - MAE: 0.4560\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.4519 - MAE: 0.4519\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.4535 - MAE: 0.4535\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (1, 14)                   0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (1, 70)                   0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.415526068527138\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdamax6_1 = Sequential()\n",
    "ModelDenseAdamax6_1.add(Dense(14))\n",
    "ModelDenseAdamax6_1.add(Dropout(0.1))\n",
    "ModelDenseAdamax6_1.add(Dense(70))\n",
    "ModelDenseAdamax6_1.add(Dropout(0.1))\n",
    "ModelDenseAdamax6_1.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdamax6_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax6_1.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax6_1.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax6_1.summary()\n",
    "\n",
    "DenseAdamaxPrediction6_1 = ModelDenseAdamax6_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction6_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3116ce0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 1.3581 - MAE: 1.3581\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 911us/step - loss: 0.4647 - MAE: 0.4647\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.3527 - MAE: 0.3527\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 841us/step - loss: 0.3168 - MAE: 0.3168\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.2703 - MAE: 0.2703\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.2402 - MAE: 0.2402\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.2088 - MAE: 0.2088\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.1986 - MAE: 0.1986\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 893us/step - loss: 0.1769 - MAE: 0.1769\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.1648 - MAE: 0.1648\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1627 - MAE: 0.1627\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.1489 - MAE: 0.1489\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.1461 - MAE: 0.1461\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.1431 - MAE: 0.1431\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 872us/step - loss: 0.1372 - MAE: 0.1372\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.1340 - MAE: 0.1340\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 829us/step - loss: 0.1192 - MAE: 0.1192\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.1172 - MAE: 0.1172\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.1154 - MAE: 0.1154\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 851us/step - loss: 0.1138 - MAE: 0.1138\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 977us/step - loss: 0.1112 - MAE: 0.1112\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 877us/step - loss: 0.1090 - MAE: 0.1090\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 870us/step - loss: 0.1038 - MAE: 0.1038\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.1040 - MAE: 0.1040\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 895us/step - loss: 0.1048 - MAE: 0.1048\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.0994 - MAE: 0.0994\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.1026 - MAE: 0.1026\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.0977 - MAE: 0.0977\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.0892 - MAE: 0.0892\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 867us/step - loss: 0.0982 - MAE: 0.0982\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 835us/step - loss: 0.0967 - MAE: 0.0967\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.0926 - MAE: 0.0926\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 867us/step - loss: 0.0939 - MAE: 0.0939\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 866us/step - loss: 0.0935 - MAE: 0.0935\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (1, 192)                  2880      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (1, 24)                   4632      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (1, 9)                    225       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (1, 1)                    10        \n",
      "=================================================================\n",
      "Total params: 7,915\n",
      "Trainable params: 7,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.12102778292840348\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdamax7 = Sequential()\n",
    "ModelDenseAdamax7.add(Dense(14))\n",
    "ModelDenseAdamax7.add(Dense(192, activation='relu'))\n",
    "ModelDenseAdamax7.add(Dense(24, activation='relu'))\n",
    "ModelDenseAdamax7.add(Dense(9, activation='relu'))\n",
    "ModelDenseAdamax7.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdamax7.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdamax7.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdamax7.summary()\n",
    "\n",
    "DenseAdamaxPrediction7 = ModelDenseAdamax7.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction7, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b649b5f",
   "metadata": {},
   "source": [
    "## Dense RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0b659133",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 830us/step - loss: 0.9142 - MAE: 0.9142\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 798us/step - loss: 0.5074 - MAE: 0.5074\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 782us/step - loss: 0.5071 - MAE: 0.5071\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 797us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 845us/step - loss: 0.5071 - MAE: 0.5071\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 790us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 769us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 911us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.5068 - MAE: 0.5068\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 943us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 965us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 789us/step - loss: 0.5069 - MAE: 0.5069\n",
      "Test score: 0.4851861285521762\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ModelDenseRMSprop1 = Sequential()\n",
    "ModelDenseRMSprop1.add(Dense(14))\n",
    "ModelDenseRMSprop1.add(Dense(70, activation='relu'))\n",
    "ModelDenseRMSprop1.add(Dense(7, activation='relu'))\n",
    "ModelDenseRMSprop1.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop1.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop1.fit(x_train.values, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseRMSpropPrediction1 = ModelDenseRMSprop1.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2645150e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 839us/step - loss: 0.8027 - MAE: 0.8027\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.5173 - MAE: 0.5173\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 851us/step - loss: 0.5086 - MAE: 0.5086\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.5174 - MAE: 0.5174\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.5170 - MAE: 0.5170\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 894us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.4724 - MAE: 0.4724\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 805us/step - loss: 0.4559 - MAE: 0.4559\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 746us/step - loss: 0.4452 - MAE: 0.4452\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 776us/step - loss: 0.4393 - MAE: 0.4393 0s - loss: 0.4356 - \n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 762us/step - loss: 0.4298 - MAE: 0.4298\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 784us/step - loss: 0.4456 - MAE: 0.4456\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 798us/step - loss: 0.4247 - MAE: 0.4247\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 770us/step - loss: 0.4166 - MAE: 0.4166\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 781us/step - loss: 0.4210 - MAE: 0.4210\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.4160 - MAE: 0.4160\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.4165 - MAE: 0.4165\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 793us/step - loss: 0.4099 - MAE: 0.4099\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.4151 - MAE: 0.4151\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 796us/step - loss: 0.4234 - MAE: 0.4234\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 765us/step - loss: 0.4084 - MAE: 0.4084\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 800us/step - loss: 0.4109 - MAE: 0.4109\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 773us/step - loss: 0.4089 - MAE: 0.4089\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 786us/step - loss: 0.4101 - MAE: 0.4101\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 794us/step - loss: 0.4083 - MAE: 0.4083\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 855us/step - loss: 0.4185 - MAE: 0.4185\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.4073 - MAE: 0.4073\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.4218 - MAE: 0.4218\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.4050 - MAE: 0.4050\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.4079 - MAE: 0.4079\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 807us/step - loss: 0.4073 - MAE: 0.4073\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.4060 - MAE: 0.4060\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 879us/step - loss: 0.4037 - MAE: 0.4037\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 805us/step - loss: 0.4053 - MAE: 0.4053\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.4039 - MAE: 0.4039\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.4056 - MAE: 0.4056\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 843us/step - loss: 0.4029 - MAE: 0.4029\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.4059 - MAE: 0.4059\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.4035 - MAE: 0.4035\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 793us/step - loss: 0.4027 - MAE: 0.4027\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.4051 - MAE: 0.4051\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.4026 - MAE: 0.4026\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.4032 - MAE: 0.4032\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 792us/step - loss: 0.4031 - MAE: 0.4031\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 792us/step - loss: 0.4077 - MAE: 0.4077\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 807us/step - loss: 0.4012 - MAE: 0.4012\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.4019 - MAE: 0.4019\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 851us/step - loss: 0.4025 - MAE: 0.4025\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.4074 - MAE: 0.4074\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 847us/step - loss: 0.4038 - MAE: 0.4038\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.4010 - MAE: 0.4010\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.4041 - MAE: 0.4041\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.4026 - MAE: 0.4026\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.4002 - MAE: 0.4002\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 768us/step - loss: 0.4026 - MAE: 0.4026\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 780us/step - loss: 0.4038 - MAE: 0.4038\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 752us/step - loss: 0.4038 - MAE: 0.4038\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.4030 - MAE: 0.4030\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 792us/step - loss: 0.4011 - MAE: 0.4011 0s - loss: 0.3999 - M\n",
      "Test score: 0.3834629186906841\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ModelDenseRMSprop1_1 = Sequential()\n",
    "ModelDenseRMSprop1_1.add(Dense(14))\n",
    "ModelDenseRMSprop1_1.add(Dropout(0.1))\n",
    "ModelDenseRMSprop1_1.add(Dense(70, activation='relu'))\n",
    "ModelDenseRMSprop1_1.add(Dropout(0.1))\n",
    "ModelDenseRMSprop1_1.add(Dense(7, activation='relu'))\n",
    "ModelDenseRMSprop1_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop1_1.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop1_1.fit(x_train.values, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseRMSpropPrediction1_1 = ModelDenseRMSprop1_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction1_1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "29b088d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 1.0493 - MAE: 1.0493\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.3735 - MAE: 0.3735\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 779us/step - loss: 0.2984 - MAE: 0.2984\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 761us/step - loss: 0.2702 - MAE: 0.2702\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 730us/step - loss: 0.2424 - MAE: 0.2424\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 761us/step - loss: 0.2170 - MAE: 0.2170\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 727us/step - loss: 0.2116 - MAE: 0.2116\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 773us/step - loss: 0.1967 - MAE: 0.1967\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 908us/step - loss: 0.1861 - MAE: 0.1861\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 840us/step - loss: 0.1772 - MAE: 0.1772\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.1722 - MAE: 0.1722\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.1621 - MAE: 0.1621\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 842us/step - loss: 0.1606 - MAE: 0.1606\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.1497 - MAE: 0.1497\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.1509 - MAE: 0.1509\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.1425 - MAE: 0.1425\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 757us/step - loss: 0.1419 - MAE: 0.1419\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 773us/step - loss: 0.1360 - MAE: 0.1360\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 760us/step - loss: 0.1367 - MAE: 0.1367\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 783us/step - loss: 0.1359 - MAE: 0.1359\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 764us/step - loss: 0.1358 - MAE: 0.1358\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.1319 - MAE: 0.1319\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 974us/step - loss: 0.1274 - MAE: 0.1274\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.1239 - MAE: 0.1239\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 921us/step - loss: 0.1200 - MAE: 0.1200\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1271 - MAE: 0.1271\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.1260 - MAE: 0.1260\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 738us/step - loss: 0.1296 - MAE: 0.1296\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 753us/step - loss: 0.1243 - MAE: 0.1243\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 720us/step - loss: 0.1264 - MAE: 0.1264\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.16063453475248496\n"
     ]
    }
   ],
   "source": [
    "ModelDenseRMSprop2 = Sequential()\n",
    "ModelDenseRMSprop2.add(Dense(14))\n",
    "ModelDenseRMSprop2.add(Dense(70, activation='relu'))\n",
    "ModelDenseRMSprop2.add(Dense(7, activation='elu'))\n",
    "ModelDenseRMSprop2.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop2.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop2.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop2.summary()\n",
    "\n",
    "DenseRMSpropPrediction2 = ModelDenseRMSprop2.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction2, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "98edf772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 896us/step - loss: 0.8273 - MAE: 0.8273\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 874us/step - loss: 0.4353 - MAE: 0.4353\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.3808 - MAE: 0.3808\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.3400 - MAE: 0.3400\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.3146 - MAE: 0.3146\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 800us/step - loss: 0.2951 - MAE: 0.2951\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.2639 - MAE: 0.2639\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.2408 - MAE: 0.2408\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.2371 - MAE: 0.2371\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.2247 - MAE: 0.2247\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 841us/step - loss: 0.2258 - MAE: 0.2258\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.2083 - MAE: 0.2083\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 792us/step - loss: 0.2125 - MAE: 0.2125\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.2090 - MAE: 0.2090\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.1984 - MAE: 0.1984\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.1916 - MAE: 0.1916\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.1888 - MAE: 0.1888\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 798us/step - loss: 0.1807 - MAE: 0.1807\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.1806 - MAE: 0.1806\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.1836 - MAE: 0.1836\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.1741 - MAE: 0.1741\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.1732 - MAE: 0.1732\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1654 - MAE: 0.1654\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 868us/step - loss: 0.1659 - MAE: 0.1659\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.1615 - MAE: 0.1615\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 840us/step - loss: 0.1557 - MAE: 0.1557\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.1544 - MAE: 0.1544\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 857us/step - loss: 0.1494 - MAE: 0.1494 0s - loss: 0.1474 - MAE: \n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.1508 - MAE: 0.1508\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 876us/step - loss: 0.1542 - MAE: 0.1542\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.1510 - MAE: 0.1510\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.1472 - MAE: 0.1472\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.1419 - MAE: 0.1419\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 916us/step - loss: 0.1384 - MAE: 0.1384\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 908us/step - loss: 0.1463 - MAE: 0.1463\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 847us/step - loss: 0.1432 - MAE: 0.1432\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.1430 - MAE: 0.1430\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.1383 - MAE: 0.1383\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 878us/step - loss: 0.1399 - MAE: 0.1399\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 911us/step - loss: 0.1394 - MAE: 0.1394\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1390 - MAE: 0.1390\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 869us/step - loss: 0.1387 - MAE: 0.1387\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 988us/step - loss: 0.1307 - MAE: 0.1307\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 948us/step - loss: 0.1368 - MAE: 0.1368\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 984us/step - loss: 0.1293 - MAE: 0.1293\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1356 - MAE: 0.1356\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 960us/step - loss: 0.1362 - MAE: 0.1362\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.1233 - MAE: 0.1233\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.1289 - MAE: 0.1289\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 914us/step - loss: 0.1279 - MAE: 0.1279\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.1254 - MAE: 0.1254\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 877us/step - loss: 0.1253 - MAE: 0.1253\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1252 - MAE: 0.1252\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (1, 14)                   0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (1, 70)                   0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.10341606033050643\n"
     ]
    }
   ],
   "source": [
    "ModelDenseRMSprop2_1 = Sequential()\n",
    "ModelDenseRMSprop2_1.add(Dense(14))\n",
    "ModelDenseRMSprop2_1.add(Dropout(0.1))\n",
    "ModelDenseRMSprop2_1.add(Dense(70, activation='relu'))\n",
    "ModelDenseRMSprop2_1.add(Dropout(0.1))\n",
    "ModelDenseRMSprop2_1.add(Dense(7, activation='elu'))\n",
    "ModelDenseRMSprop2_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop2_1.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop2_1.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop2_1.summary()\n",
    "\n",
    "DenseRMSpropPrediction2_1 = ModelDenseRMSprop2_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction2_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1c0db0d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 882us/step - loss: 0.7503 - MAE: 0.7503\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 852us/step - loss: 0.4332 - MAE: 0.4332\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.4242 - MAE: 0.4242\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 875us/step - loss: 0.3450 - MAE: 0.3450\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.2985 - MAE: 0.2985\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.2954 - MAE: 0.2954\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 996us/step - loss: 0.2845 - MAE: 0.2845\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.2692 - MAE: 0.2692\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 982us/step - loss: 0.2604 - MAE: 0.2604\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.2562 - MAE: 0.2562\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.2665 - MAE: 0.2665\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.2523 - MAE: 0.2523\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.2517 - MAE: 0.2517\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.2493 - MAE: 0.2493\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 772us/step - loss: 0.2381 - MAE: 0.2381\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 771us/step - loss: 0.2384 - MAE: 0.2384\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.2306 - MAE: 0.2306\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 746us/step - loss: 0.2377 - MAE: 0.2377\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 875us/step - loss: 0.2213 - MAE: 0.2213\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 871us/step - loss: 0.2152 - MAE: 0.2152\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.2243 - MAE: 0.2243\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.2154 - MAE: 0.2154\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.2033 - MAE: 0.2033\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.1940 - MAE: 0.1940\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 942us/step - loss: 0.2004 - MAE: 0.2004\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.2122 - MAE: 0.2122\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.1988 - MAE: 0.1988\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.1874 - MAE: 0.1874\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.2077 - MAE: 0.2077\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.1978 - MAE: 0.1978\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 797us/step - loss: 0.1974 - MAE: 0.1974\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 783us/step - loss: 0.1965 - MAE: 0.1965\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 794us/step - loss: 0.1956 - MAE: 0.1956\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.16432598575834506\n"
     ]
    }
   ],
   "source": [
    "ModelDenseRMSprop3 = Sequential()\n",
    "ModelDenseRMSprop3.add(Dense(14))\n",
    "ModelDenseRMSprop3.add(Dense(70, activation='relu'))\n",
    "ModelDenseRMSprop3.add(Dense(7, activation='selu'))\n",
    "ModelDenseRMSprop3.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop3.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop3.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop3.summary()\n",
    "\n",
    "DenseRMSpropPrediction3 = ModelDenseRMSprop3.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction3, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b7d45c06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.5938 - MAE: 0.5938\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 852us/step - loss: 0.3669 - MAE: 0.3669\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 786us/step - loss: 0.3154 - MAE: 0.3154\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 780us/step - loss: 0.3023 - MAE: 0.3023\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 742us/step - loss: 0.3109 - MAE: 0.3109\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 760us/step - loss: 0.2843 - MAE: 0.2843\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 747us/step - loss: 0.2714 - MAE: 0.2714\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.2605 - MAE: 0.2605\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 767us/step - loss: 0.2410 - MAE: 0.2410\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 756us/step - loss: 0.2220 - MAE: 0.2220 0s - loss: 0.2210 \n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 797us/step - loss: 0.2088 - MAE: 0.2088\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.2016 - MAE: 0.2016\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 765us/step - loss: 0.1940 - MAE: 0.1940\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 789us/step - loss: 0.1870 - MAE: 0.1870\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 745us/step - loss: 0.1824 - MAE: 0.1824\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 734us/step - loss: 0.1834 - MAE: 0.1834\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 738us/step - loss: 0.1772 - MAE: 0.1772\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 784us/step - loss: 0.1719 - MAE: 0.1719\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 737us/step - loss: 0.1661 - MAE: 0.1661\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.1627 - MAE: 0.1627\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 721us/step - loss: 0.1611 - MAE: 0.1611\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 728us/step - loss: 0.1573 - MAE: 0.1573\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 797us/step - loss: 0.1586 - MAE: 0.1586\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1538 - MAE: 0.1538\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1509 - MAE: 0.1509\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1465 - MAE: 0.1465\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1443 - MAE: 0.1443\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1446 - MAE: 0.1446\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1445 - MAE: 0.1445\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1464 - MAE: 0.1464\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1412 - MAE: 0.1412\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 944us/step - loss: 0.1420 - MAE: 0.1420\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.1407 - MAE: 0.1407\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 781us/step - loss: 0.1419 - MAE: 0.1419\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 983us/step - loss: 0.1386 - MAE: 0.1386\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.1377 - MAE: 0.1377\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 897us/step - loss: 0.1407 - MAE: 0.1407\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1345 - MAE: 0.1345\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 913us/step - loss: 0.1348 - MAE: 0.1348\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1340 - MAE: 0.1340\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 956us/step - loss: 0.1312 - MAE: 0.1312\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 958us/step - loss: 0.1333 - MAE: 0.1333\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 912us/step - loss: 0.1285 - MAE: 0.1285\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 913us/step - loss: 0.1290 - MAE: 0.1290\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 899us/step - loss: 0.1273 - MAE: 0.1273\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1291 - MAE: 0.1291\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1293 - MAE: 0.1293\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1269 - MAE: 0.1269\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 961us/step - loss: 0.1269 - MAE: 0.1269\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 894us/step - loss: 0.1265 - MAE: 0.1265\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 881us/step - loss: 0.1223 - MAE: 0.1223\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 842us/step - loss: 0.1227 - MAE: 0.1227\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 886us/step - loss: 0.1209 - MAE: 0.1209\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 883us/step - loss: 0.1201 - MAE: 0.1201\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 992us/step - loss: 0.1185 - MAE: 0.1185\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.1235 - MAE: 0.1235\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 903us/step - loss: 0.1163 - MAE: 0.1163\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.1169 - MAE: 0.1169\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 0.1161 - MAE: 0.1161\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 768us/step - loss: 0.1147 - MAE: 0.1147\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.1130 - MAE: 0.1130\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.1183 - MAE: 0.1183\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 806us/step - loss: 0.1136 - MAE: 0.1136\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1109 - MAE: 0.1109\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.1113 - MAE: 0.1113\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 887us/step - loss: 0.1128 - MAE: 0.1128\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 886us/step - loss: 0.1088 - MAE: 0.1088\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 951us/step - loss: 0.1130 - MAE: 0.1130\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1193 - MAE: 0.1193\n",
      "Epoch 70/100\n",
      "2160/2160 [==============================] - 2s 866us/step - loss: 0.1087 - MAE: 0.1087\n",
      "Epoch 71/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.1162 - MAE: 0.1162\n",
      "Epoch 72/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.1124 - MAE: 0.1124\n",
      "Epoch 73/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.1105 - MAE: 0.1105\n",
      "Epoch 74/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 0.1138 - MAE: 0.1138\n",
      "Epoch 75/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.1083 - MAE: 0.1083\n",
      "Epoch 76/100\n",
      "2160/2160 [==============================] - 2s 984us/step - loss: 0.1091 - MAE: 0.1091\n",
      "Epoch 77/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.1057 - MAE: 0.1057\n",
      "Epoch 78/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.1082 - MAE: 0.1082\n",
      "Epoch 79/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.1106 - MAE: 0.1106\n",
      "Epoch 80/100\n",
      "2160/2160 [==============================] - 2s 901us/step - loss: 0.1095 - MAE: 0.1095\n",
      "Epoch 81/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.1073 - MAE: 0.1073\n",
      "Epoch 82/100\n",
      "2160/2160 [==============================] - 2s 785us/step - loss: 0.1078 - MAE: 0.1078\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.09862329412188073\n"
     ]
    }
   ],
   "source": [
    "ModelDenseRMSprop4 = Sequential()\n",
    "ModelDenseRMSprop4.add(Dense(14))\n",
    "ModelDenseRMSprop4.add(Dense(70, activation='relu'))\n",
    "ModelDenseRMSprop4.add(Dense(7, activation='elu'))\n",
    "ModelDenseRMSprop4.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop4.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop4.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop4.summary()\n",
    "\n",
    "DenseRMSpropPrediction4 = ModelDenseRMSprop4.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction4, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bdab649c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.5580 - MAE: 0.5580\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 878us/step - loss: 0.3842 - MAE: 0.3842\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 839us/step - loss: 0.3155 - MAE: 0.3155\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 830us/step - loss: 0.2684 - MAE: 0.2684\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.2356 - MAE: 0.2356\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 754us/step - loss: 0.2201 - MAE: 0.2201\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 758us/step - loss: 0.1985 - MAE: 0.1985\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 726us/step - loss: 0.1874 - MAE: 0.1874\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 774us/step - loss: 0.1792 - MAE: 0.1792\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 756us/step - loss: 0.1674 - MAE: 0.1674\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.1639 - MAE: 0.1639\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 747us/step - loss: 0.1555 - MAE: 0.1555 1s - lo\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 742us/step - loss: 0.1533 - MAE: 0.1533\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 748us/step - loss: 0.1487 - MAE: 0.1487\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 932us/step - loss: 0.1425 - MAE: 0.1425\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 885us/step - loss: 0.1427 - MAE: 0.1427\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 0.1374 - MAE: 0.1374\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.1343 - MAE: 0.1343\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.1376 - MAE: 0.1376\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.1317 - MAE: 0.1317\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 966us/step - loss: 0.1356 - MAE: 0.1356\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.1330 - MAE: 0.1330\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 859us/step - loss: 0.1340 - MAE: 0.1340\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 885us/step - loss: 0.1360 - MAE: 0.1360\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 763us/step - loss: 0.1321 - MAE: 0.1321\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.13405587031424088\n"
     ]
    }
   ],
   "source": [
    "ModelDenseRMSprop5 = Sequential()\n",
    "ModelDenseRMSprop5.add(Dense(14))\n",
    "ModelDenseRMSprop5.add(Dense(70, activation='relu'))\n",
    "ModelDenseRMSprop5.add(Dense(7, activation='elu'))\n",
    "ModelDenseRMSprop5.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop5.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop5.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop5.summary()\n",
    "\n",
    "DenseRMSpropPrediction5 = ModelDenseRMSprop5.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction5, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c6d4a067",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.7079 - MAE: 0.7079\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.5084 - MAE: 0.5084\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 770us/step - loss: 0.4538 - MAE: 0.4538\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 751us/step - loss: 0.3943 - MAE: 0.3943\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.3535 - MAE: 0.3535\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 912us/step - loss: 0.3132 - MAE: 0.3132\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.2607 - MAE: 0.2607\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.2449 - MAE: 0.2449\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.2330 - MAE: 0.2330\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 833us/step - loss: 0.2238 - MAE: 0.2238\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 883us/step - loss: 0.2129 - MAE: 0.2129\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 772us/step - loss: 0.2022 - MAE: 0.2022\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 792us/step - loss: 0.1976 - MAE: 0.1976\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1955 - MAE: 0.1955\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 962us/step - loss: 0.1862 - MAE: 0.1862\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.1828 - MAE: 0.1828\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 853us/step - loss: 0.1780 - MAE: 0.1780\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1721 - MAE: 0.1721\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 995us/step - loss: 0.1724 - MAE: 0.1724\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 999us/step - loss: 0.1689 - MAE: 0.1689\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.1657 - MAE: 0.1657\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 782us/step - loss: 0.1629 - MAE: 0.1629\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 928us/step - loss: 0.1610 - MAE: 0.1610\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 876us/step - loss: 0.1556 - MAE: 0.1556\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 757us/step - loss: 0.1558 - MAE: 0.1558\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 955us/step - loss: 0.1516 - MAE: 0.1516\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.1526 - MAE: 0.1526\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 927us/step - loss: 0.1512 - MAE: 0.1512 1s - l\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 859us/step - loss: 0.1447 - MAE: 0.1447\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 769us/step - loss: 0.1436 - MAE: 0.1436\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 773us/step - loss: 0.1432 - MAE: 0.1432\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.1416 - MAE: 0.1416\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.1419 - MAE: 0.1419\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 991us/step - loss: 0.1382 - MAE: 0.1382\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.1394 - MAE: 0.1394\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 863us/step - loss: 0.1356 - MAE: 0.1356\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.1354 - MAE: 0.1354\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.1362 - MAE: 0.1362\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 833us/step - loss: 0.1345 - MAE: 0.1345\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.1342 - MAE: 0.1342\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 777us/step - loss: 0.1332 - MAE: 0.1332 0s - loss: 0.1337 - MAE: 0.133 - ETA: 0s - loss: 0.1335 - MAE: 0.133\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 744us/step - loss: 0.1326 - MAE: 0.1326\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 789us/step - loss: 0.1289 - MAE: 0.1289\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 757us/step - loss: 0.1313 - MAE: 0.1313\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 772us/step - loss: 0.1290 - MAE: 0.1290\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 797us/step - loss: 0.1302 - MAE: 0.1302\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 858us/step - loss: 0.1286 - MAE: 0.1286\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 829us/step - loss: 0.1282 - MAE: 0.1282\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.1272 - MAE: 0.1272\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.1265 - MAE: 0.1265\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 805us/step - loss: 0.1269 - MAE: 0.1269\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1255 - MAE: 0.1255\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 845us/step - loss: 0.1266 - MAE: 0.1266\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 759us/step - loss: 0.1253 - MAE: 0.1253\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 768us/step - loss: 0.1280 - MAE: 0.1280\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.1227 - MAE: 0.1227\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 875us/step - loss: 0.1267 - MAE: 0.1267\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.1243 - MAE: 0.1243\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 0.1245 - MAE: 0.1245\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 741us/step - loss: 0.1221 - MAE: 0.1221\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 975us/step - loss: 0.1222 - MAE: 0.1222\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.1240 - MAE: 0.1240\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 857us/step - loss: 0.1224 - MAE: 0.1224\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 893us/step - loss: 0.1213 - MAE: 0.1213\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 962us/step - loss: 0.1211 - MAE: 0.1211\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 958us/step - loss: 0.1260 - MAE: 0.1260\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 855us/step - loss: 0.1280 - MAE: 0.1280\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1228 - MAE: 0.1228\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.1279 - MAE: 0.1279\n",
      "Epoch 70/100\n",
      "2160/2160 [==============================] - 2s 841us/step - loss: 0.1214 - MAE: 0.1214\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_69 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.12609543838682202\n"
     ]
    }
   ],
   "source": [
    "ModelDenseRMSprop6 = Sequential()\n",
    "ModelDenseRMSprop6.add(Dense(14))\n",
    "ModelDenseRMSprop6.add(Dense(70))\n",
    "ModelDenseRMSprop6.add(Dense(7, activation='relu'))\n",
    "ModelDenseRMSprop6.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop6.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop6.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop6.summary()\n",
    "\n",
    "DenseRMSpropPrediction6 = ModelDenseRMSprop6.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction6, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cb8dc6c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 805us/step - loss: 0.7129 - MAE: 0.7129\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.5166 - MAE: 0.5166\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.5071 - MAE: 0.5071\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 793us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 763us/step - loss: 0.5086 - MAE: 0.5086\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 769us/step - loss: 0.5088 - MAE: 0.5088\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.5096 - MAE: 0.5096\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 864us/step - loss: 0.5112 - MAE: 0.5112\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.5072 - MAE: 0.5072\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (1, 14)                   0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (1, 70)                   0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.4839633435689121\n"
     ]
    }
   ],
   "source": [
    "ModelDenseRMSprop6_1 = Sequential()\n",
    "ModelDenseRMSprop6_1.add(Dense(14))\n",
    "ModelDenseRMSprop6_1.add(Dropout(0.1))\n",
    "ModelDenseRMSprop6_1.add(Dense(70))\n",
    "ModelDenseRMSprop6_1.add(Dropout(0.1))\n",
    "ModelDenseRMSprop6_1.add(Dense(7, activation='relu'))\n",
    "ModelDenseRMSprop6_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop6_1.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop6_1.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop6_1.summary()\n",
    "\n",
    "DenseRMSpropPrediction6_1 = ModelDenseRMSprop6_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction6_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "08211524",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 895us/step - loss: 0.5859 - MAE: 0.5859\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 887us/step - loss: 0.3710 - MAE: 0.3710\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 858us/step - loss: 0.3026 - MAE: 0.3026\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 892us/step - loss: 0.2506 - MAE: 0.2506\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 868us/step - loss: 0.2124 - MAE: 0.2124\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 879us/step - loss: 0.1948 - MAE: 0.1948\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.1841 - MAE: 0.1841\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 865us/step - loss: 0.1671 - MAE: 0.1671\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 879us/step - loss: 0.1578 - MAE: 0.1578\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.1497 - MAE: 0.1497\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.1426 - MAE: 0.1426\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 809us/step - loss: 0.1441 - MAE: 0.1441 1s - l\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 793us/step - loss: 0.1384 - MAE: 0.1384\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.1399 - MAE: 0.1399\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.1370 - MAE: 0.1370\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.1348 - MAE: 0.1348\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 796us/step - loss: 0.1298 - MAE: 0.1298\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.1286 - MAE: 0.1286\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 914us/step - loss: 0.1284 - MAE: 0.1284\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 954us/step - loss: 0.1237 - MAE: 0.1237\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.1194 - MAE: 0.1194\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 873us/step - loss: 0.1201 - MAE: 0.1201\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.1217 - MAE: 0.1217\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 932us/step - loss: 0.1180 - MAE: 0.1180\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 843us/step - loss: 0.1168 - MAE: 0.1168\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.1164 - MAE: 0.1164\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 907us/step - loss: 0.1140 - MAE: 0.1140\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1125 - MAE: 0.1125\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.1141 - MAE: 0.1141\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 867us/step - loss: 0.1110 - MAE: 0.1110\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.1030 - MAE: 0.1030\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.1116 - MAE: 0.1116\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 902us/step - loss: 0.1093 - MAE: 0.1093\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.1088 - MAE: 0.1088\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 894us/step - loss: 0.1057 - MAE: 0.1057\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 887us/step - loss: 0.1052 - MAE: 0.1052\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_77 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (1, 192)                  2880      \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (1, 24)                   4632      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (1, 9)                    225       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (1, 1)                    10        \n",
      "=================================================================\n",
      "Total params: 7,915\n",
      "Trainable params: 7,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.06185809187048567\n"
     ]
    }
   ],
   "source": [
    "ModelDenseRMSprop7 = Sequential()\n",
    "ModelDenseRMSprop7.add(Dense(14))\n",
    "ModelDenseRMSprop7.add(Dense(192, activation='relu'))\n",
    "ModelDenseRMSprop7.add(Dense(24, activation='relu'))\n",
    "ModelDenseRMSprop7.add(Dense(9, activation='relu'))\n",
    "ModelDenseRMSprop7.add(Dense(1, activation='linear'))\n",
    "ModelDenseRMSprop7.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseRMSprop7.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseRMSprop7.summary()\n",
    "\n",
    "DenseRMSpropPrediction7 = ModelDenseRMSprop7.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction7, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639117b",
   "metadata": {},
   "source": [
    "## Dense Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9d93180d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.6613 - MAE: 0.6613\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.5076 - MAE: 0.5076\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 883us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.5071 - MAE: 0.5071\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 895us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.5071 - MAE: 0.5071\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 951us/step - loss: 0.5071 - MAE: 0.5071\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.5069 - MAE: 0.5069\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.5067 - MAE: 0.5067\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 807us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.5069 - MAE: 0.5069\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 968us/step - loss: 0.5071 - MAE: 0.5071\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.5069 - MAE: 0.5069\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.5067 - MAE: 0.5067\n",
      "Test score: 0.48515913953898115\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ModelDenseAdam1 = Sequential()\n",
    "ModelDenseAdam1.add(Dense(14))\n",
    "ModelDenseAdam1.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdam1.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdam1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam1.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam1.fit(x_train.values, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseAdamPrediction1 = ModelDenseAdam1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fe1dbdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 872us/step - loss: 4.4188 - MAE: 4.4188\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 858us/step - loss: 0.7467 - MAE: 0.7467\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.5302 - MAE: 0.5302\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.4631 - MAE: 0.4631\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 866us/step - loss: 0.4158 - MAE: 0.4158\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 835us/step - loss: 0.3400 - MAE: 0.3400\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.2901 - MAE: 0.2901\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.2688 - MAE: 0.2688\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.2386 - MAE: 0.2386\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 871us/step - loss: 0.2226 - MAE: 0.2226\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.2212 - MAE: 0.2212\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.2138 - MAE: 0.2138\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.1981 - MAE: 0.1981\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.2032 - MAE: 0.2032\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.1952 - MAE: 0.1952\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.1822 - MAE: 0.1822\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.1772 - MAE: 0.1772\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 880us/step - loss: 0.1795 - MAE: 0.1795\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.1757 - MAE: 0.1757\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 877us/step - loss: 0.1691 - MAE: 0.1691\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 858us/step - loss: 0.1651 - MAE: 0.1651\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.1690 - MAE: 0.1690\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 994us/step - loss: 0.1567 - MAE: 0.1567\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.1627 - MAE: 0.1627\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.1588 - MAE: 0.1588\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.1458 - MAE: 0.1458\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.1469 - MAE: 0.1469\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.1564 - MAE: 0.1564\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.1571 - MAE: 0.1571\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1532 - MAE: 0.1532\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1509 - MAE: 0.1509\n",
      "Test score: 0.1530268231096598\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ModelDenseAdam1_1 = Sequential()\n",
    "ModelDenseAdam1_1.add(Dense(14))\n",
    "ModelDenseAdam1_1.add(Dropout(0.1))\n",
    "ModelDenseAdam1_1.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdam1_1.add(Dropout(0.1))\n",
    "ModelDenseAdam1_1.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdam1_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam1_1.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam1_1.fit(x_train.values, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseAdamPrediction1_1 = ModelDenseAdam1_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction1_1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2ef60986",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.8599 - MAE: 0.8599\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 816us/step - loss: 0.4164 - MAE: 0.4164\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 914us/step - loss: 0.3210 - MAE: 0.3210\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.2625 - MAE: 0.2625\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.2334 - MAE: 0.2334\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.2135 - MAE: 0.2135\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 790us/step - loss: 0.1984 - MAE: 0.1984\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.1810 - MAE: 0.1810\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.1702 - MAE: 0.1702\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.1604 - MAE: 0.1604\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 782us/step - loss: 0.1554 - MAE: 0.1554\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 784us/step - loss: 0.1486 - MAE: 0.1486\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 806us/step - loss: 0.1316 - MAE: 0.1316\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.1362 - MAE: 0.1362\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 781us/step - loss: 0.1352 - MAE: 0.1352\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.1367 - MAE: 0.1367\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.1293 - MAE: 0.1293\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.1324 - MAE: 0.1324\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.1329 - MAE: 0.1329\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.1209 - MAE: 0.1209\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.1246 - MAE: 0.1246\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 907us/step - loss: 0.1174 - MAE: 0.1174\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 776us/step - loss: 0.1200 - MAE: 0.1200\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 791us/step - loss: 0.1256 - MAE: 0.1256 0s - loss: 0.1271 - MAE: 0.\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.1262 - MAE: 0.1262\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 842us/step - loss: 0.1173 - MAE: 0.1173\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 863us/step - loss: 0.1099 - MAE: 0.1099\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.1094 - MAE: 0.1094\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 902us/step - loss: 0.1092 - MAE: 0.1092\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.1088 - MAE: 0.1088\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.1135 - MAE: 0.1135\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 784us/step - loss: 0.1056 - MAE: 0.1056\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.1044 - MAE: 0.1044\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.1039 - MAE: 0.1039\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 840us/step - loss: 0.1028 - MAE: 0.1028\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.1005 - MAE: 0.1005\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.0980 - MAE: 0.0980\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 787us/step - loss: 0.1076 - MAE: 0.1076\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 806us/step - loss: 0.0998 - MAE: 0.0998\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 783us/step - loss: 0.1067 - MAE: 0.1067\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 783us/step - loss: 0.1038 - MAE: 0.1038\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 785us/step - loss: 0.0977 - MAE: 0.0977\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 805us/step - loss: 0.0938 - MAE: 0.0938\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 847us/step - loss: 0.0994 - MAE: 0.0994\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.0888 - MAE: 0.0888\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 784us/step - loss: 0.0988 - MAE: 0.0988\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 852us/step - loss: 0.0975 - MAE: 0.0975\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 986us/step - loss: 0.0980 - MAE: 0.0980\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 830us/step - loss: 0.0942 - MAE: 0.0942\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 792us/step - loss: 0.0965 - MAE: 0.0965\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_90 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.06585297890603173\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdam2 = Sequential()\n",
    "ModelDenseAdam2.add(Dense(14))\n",
    "ModelDenseAdam2.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdam2.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdam2.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam2.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam2.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam2.summary()\n",
    "\n",
    "DenseAdamPrediction2 = ModelDenseAdam2.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction2, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ccb02be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 1.2568 - MAE: 1.2568\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 807us/step - loss: 0.4763 - MAE: 0.4763\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.4171 - MAE: 0.4171\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 857us/step - loss: 0.3917 - MAE: 0.3917\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 877us/step - loss: 0.3484 - MAE: 0.3484\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.3215 - MAE: 0.3215\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.2952 - MAE: 0.2952\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 842us/step - loss: 0.2727 - MAE: 0.2727\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.2551 - MAE: 0.2551\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 890us/step - loss: 0.2485 - MAE: 0.2485\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.2362 - MAE: 0.2362\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.2282 - MAE: 0.2282\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.2180 - MAE: 0.2180\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 805us/step - loss: 0.2074 - MAE: 0.2074\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.1946 - MAE: 0.1946\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.1914 - MAE: 0.1914\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.1892 - MAE: 0.1892\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.1870 - MAE: 0.1870\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.1886 - MAE: 0.1886\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.1801 - MAE: 0.1801\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.1727 - MAE: 0.1727\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.1735 - MAE: 0.1735\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 785us/step - loss: 0.1711 - MAE: 0.1711\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.1710 - MAE: 0.1710\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.1686 - MAE: 0.1686\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.1633 - MAE: 0.1633\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.1607 - MAE: 0.1607\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.1580 - MAE: 0.1580\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.1610 - MAE: 0.1610\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.1585 - MAE: 0.1585\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.1565 - MAE: 0.1565\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.1511 - MAE: 0.1511\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 807us/step - loss: 0.1548 - MAE: 0.1548\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 807us/step - loss: 0.1506 - MAE: 0.1506\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.1476 - MAE: 0.1476\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.1507 - MAE: 0.1507\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 881us/step - loss: 0.1484 - MAE: 0.1484\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.1469 - MAE: 0.1469\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 903us/step - loss: 0.1470 - MAE: 0.1470\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 871us/step - loss: 0.1354 - MAE: 0.1354\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.1450 - MAE: 0.1450\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 890us/step - loss: 0.1387 - MAE: 0.1387\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 876us/step - loss: 0.1410 - MAE: 0.1410\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.1397 - MAE: 0.1397\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 901us/step - loss: 0.1397 - MAE: 0.1397\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_94 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (1, 14)                   0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (1, 70)                   0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.11063853880807982\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdam2_1 = Sequential()\n",
    "ModelDenseAdam2_1.add(Dense(14))\n",
    "ModelDenseAdam2_1.add(Dropout(0.1))\n",
    "ModelDenseAdam2_1.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdam2_1.add(Dropout(0.1))\n",
    "ModelDenseAdam2_1.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdam2_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam2_1.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam2_1.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam2_1.summary()\n",
    "\n",
    "DenseAdamPrediction2_1 = ModelDenseAdam2_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction2_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "55bc36e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.7517 - MAE: 0.7517\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.3947 - MAE: 0.3947\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 929us/step - loss: 0.3769 - MAE: 0.3769\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.3755 - MAE: 0.3755\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 896us/step - loss: 0.3429 - MAE: 0.3429\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.3120 - MAE: 0.3120\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.2878 - MAE: 0.2878\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 858us/step - loss: 0.2683 - MAE: 0.2683\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 901us/step - loss: 0.2375 - MAE: 0.2375\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.2152 - MAE: 0.2152\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1961 - MAE: 0.1961\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.2036 - MAE: 0.2036\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 870us/step - loss: 0.1938 - MAE: 0.1938\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 833us/step - loss: 0.1979 - MAE: 0.1979\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 877us/step - loss: 0.1780 - MAE: 0.1780\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 789us/step - loss: 0.1653 - MAE: 0.1653\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 775us/step - loss: 0.1582 - MAE: 0.1582\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 942us/step - loss: 0.1532 - MAE: 0.1532\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.1436 - MAE: 0.1436\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.1374 - MAE: 0.1374\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1445 - MAE: 0.1445\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.1330 - MAE: 0.1330\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 789us/step - loss: 0.1337 - MAE: 0.1337\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 800us/step - loss: 0.1276 - MAE: 0.1276\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 871us/step - loss: 0.1240 - MAE: 0.1240\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 807us/step - loss: 0.1225 - MAE: 0.1225\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 793us/step - loss: 0.1251 - MAE: 0.1251\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.1283 - MAE: 0.1283\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1230 - MAE: 0.1230\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.1222 - MAE: 0.1222\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 796us/step - loss: 0.1201 - MAE: 0.1201\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 800us/step - loss: 0.1179 - MAE: 0.1179\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 775us/step - loss: 0.1160 - MAE: 0.1160\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.1187 - MAE: 0.1187\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.1116 - MAE: 0.1116\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.1150 - MAE: 0.1150\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 835us/step - loss: 0.1151 - MAE: 0.1151\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 809us/step - loss: 0.1093 - MAE: 0.1093\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 908us/step - loss: 0.1096 - MAE: 0.1096\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.1025 - MAE: 0.1025\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.1106 - MAE: 0.1106\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.1103 - MAE: 0.1103\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 791us/step - loss: 0.1085 - MAE: 0.1085\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 773us/step - loss: 0.1088 - MAE: 0.1088\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 772us/step - loss: 0.1067 - MAE: 0.1067\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_98 (Dense)             (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.10188140768549761\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdam3 = Sequential()\n",
    "ModelDenseAdam3.add(Dense(14))\n",
    "ModelDenseAdam3.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdam3.add(Dense(7, activation='selu'))\n",
    "ModelDenseAdam3.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam3.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam3.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam3.summary()\n",
    "\n",
    "DenseAdamPrediction3 = ModelDenseAdam3.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction3, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9549f002",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 1.4552 - MAE: 1.4552\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 833us/step - loss: 0.6486 - MAE: 0.6486\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.4284 - MAE: 0.4284\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 870us/step - loss: 0.3331 - MAE: 0.3331\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.2635 - MAE: 0.2635\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.2259 - MAE: 0.2259\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.2055 - MAE: 0.2055\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.1899 - MAE: 0.1899\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.1727 - MAE: 0.1727\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 809us/step - loss: 0.1508 - MAE: 0.1508\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.1519 - MAE: 0.1519\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.1446 - MAE: 0.1446\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 889us/step - loss: 0.1431 - MAE: 0.1431\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 864us/step - loss: 0.1448 - MAE: 0.1448\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 912us/step - loss: 0.1348 - MAE: 0.1348\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.1276 - MAE: 0.1276\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.1371 - MAE: 0.1371\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.1415 - MAE: 0.1415\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 963us/step - loss: 0.1546 - MAE: 0.1546\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 867us/step - loss: 0.1286 - MAE: 0.1286\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.1398 - MAE: 0.1398\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_102 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.2052963238623156\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdam4 = Sequential()\n",
    "ModelDenseAdam4.add(Dense(14))\n",
    "ModelDenseAdam4.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdam4.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdam4.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam4.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam4.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam4.summary()\n",
    "\n",
    "DenseAdamPrediction4 = ModelDenseAdam4.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction4, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e808be23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.6188 - MAE: 0.6188\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 794us/step - loss: 0.3936 - MAE: 0.3936\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.3429 - MAE: 0.3429\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.3132 - MAE: 0.3132\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 840us/step - loss: 0.2606 - MAE: 0.2606\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.2301 - MAE: 0.2301\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.1962 - MAE: 0.1962\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.1797 - MAE: 0.1797\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.1677 - MAE: 0.1677\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.1512 - MAE: 0.1512\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.1602 - MAE: 0.1602\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.1520 - MAE: 0.1520\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.1440 - MAE: 0.1440\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 807us/step - loss: 0.1461 - MAE: 0.1461\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.1404 - MAE: 0.1404\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 867us/step - loss: 0.1461 - MAE: 0.1461\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 782us/step - loss: 0.1331 - MAE: 0.1331\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.1286 - MAE: 0.1286\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 894us/step - loss: 0.1292 - MAE: 0.1292\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 874us/step - loss: 0.1228 - MAE: 0.1228\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.1231 - MAE: 0.1231\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 890us/step - loss: 0.1214 - MAE: 0.1214\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 803us/step - loss: 0.1248 - MAE: 0.1248\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.1245 - MAE: 0.1245\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.1200 - MAE: 0.1200\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 780us/step - loss: 0.1176 - MAE: 0.1176\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.1183 - MAE: 0.1183\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 809us/step - loss: 0.1207 - MAE: 0.1207\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.1237 - MAE: 0.1237\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 790us/step - loss: 0.1158 - MAE: 0.1158\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.1126 - MAE: 0.1126\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 789us/step - loss: 0.1129 - MAE: 0.1129\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 851us/step - loss: 0.1113 - MAE: 0.1113\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 851us/step - loss: 0.1125 - MAE: 0.1125\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.1109 - MAE: 0.1109\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.1150 - MAE: 0.1150\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.1067 - MAE: 0.1067\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.1120 - MAE: 0.1120\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1121 - MAE: 0.1121\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 800us/step - loss: 0.1037 - MAE: 0.1037\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 781us/step - loss: 0.1004 - MAE: 0.1004\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.1000 - MAE: 0.1000\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 816us/step - loss: 0.1074 - MAE: 0.1074\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 840us/step - loss: 0.1046 - MAE: 0.1046\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 809us/step - loss: 0.0983 - MAE: 0.0983\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 796us/step - loss: 0.0941 - MAE: 0.0941\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.0952 - MAE: 0.0952\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.1042 - MAE: 0.1042\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0923 - MAE: 0.0923\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 842us/step - loss: 0.0911 - MAE: 0.0911\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 976us/step - loss: 0.0875 - MAE: 0.0875\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 833us/step - loss: 0.0938 - MAE: 0.0938\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 816us/step - loss: 0.0961 - MAE: 0.0961\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 839us/step - loss: 0.1021 - MAE: 0.1021\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.0933 - MAE: 0.0933\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 845us/step - loss: 0.0836 - MAE: 0.0836\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.0887 - MAE: 0.0887\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0923 - MAE: 0.0923\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.0838 - MAE: 0.0838\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 789us/step - loss: 0.0886 - MAE: 0.0886\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.0890 - MAE: 0.0890\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_106 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.07585065674434131\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdam5 = Sequential()\n",
    "ModelDenseAdam5.add(Dense(14))\n",
    "ModelDenseAdam5.add(Dense(70, activation='relu'))\n",
    "ModelDenseAdam5.add(Dense(7, activation='elu'))\n",
    "ModelDenseAdam5.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam5.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam5.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam5.summary()\n",
    "\n",
    "DenseAdamPrediction5 = ModelDenseAdam5.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction5, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "def5b4ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 870us/step - loss: 4.5814 - MAE: 4.5814\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 871us/step - loss: 1.9469 - MAE: 1.9469\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.8838 - MAE: 0.8838\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 867us/step - loss: 0.5374 - MAE: 0.5374\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.4434 - MAE: 0.4434\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.4231 - MAE: 0.4231\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 803us/step - loss: 0.4254 - MAE: 0.4254\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.4121 - MAE: 0.4121\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.4022 - MAE: 0.4022\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 869us/step - loss: 0.3700 - MAE: 0.3700\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.3312 - MAE: 0.3312\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.3063 - MAE: 0.3063\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.2951 - MAE: 0.2951\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 783us/step - loss: 0.2873 - MAE: 0.2873\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 870us/step - loss: 0.2749 - MAE: 0.2749\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.2712 - MAE: 0.2712\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.2585 - MAE: 0.2585 1s\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.2478 - MAE: 0.2478\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.2356 - MAE: 0.2356\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.2311 - MAE: 0.2311\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.2264 - MAE: 0.2264\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 989us/step - loss: 0.2142 - MAE: 0.2142\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.1956 - MAE: 0.1956\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 866us/step - loss: 0.1875 - MAE: 0.1875\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.1789 - MAE: 0.1789\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 843us/step - loss: 0.1781 - MAE: 0.1781\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 792us/step - loss: 0.1731 - MAE: 0.1731\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.1688 - MAE: 0.1688\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 798us/step - loss: 0.1673 - MAE: 0.1673\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.1632 - MAE: 0.1632\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 773us/step - loss: 0.1621 - MAE: 0.1621\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.1567 - MAE: 0.1567\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 865us/step - loss: 0.1532 - MAE: 0.1532\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.1540 - MAE: 0.1540\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 777us/step - loss: 0.1518 - MAE: 0.1518\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 797us/step - loss: 0.1540 - MAE: 0.1540\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.1498 - MAE: 0.1498\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.1486 - MAE: 0.1486\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.1471 - MAE: 0.1471\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.1418 - MAE: 0.1418\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 816us/step - loss: 0.1439 - MAE: 0.1439\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 989us/step - loss: 0.1456 - MAE: 0.1456\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.1397 - MAE: 0.1397\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 866us/step - loss: 0.1401 - MAE: 0.1401\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 807us/step - loss: 0.1391 - MAE: 0.1391\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.1407 - MAE: 0.1407\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 840us/step - loss: 0.1353 - MAE: 0.1353\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.1310 - MAE: 0.1310\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.1360 - MAE: 0.1360\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.1339 - MAE: 0.1339\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 785us/step - loss: 0.1272 - MAE: 0.1272\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 853us/step - loss: 0.1340 - MAE: 0.1340\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 794us/step - loss: 0.1308 - MAE: 0.1308\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.1282 - MAE: 0.1282\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.1273 - MAE: 0.1273\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.1284 - MAE: 0.1284\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_110 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.11986550581775614\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdam6 = Sequential()\n",
    "ModelDenseAdam6.add(Dense(14))\n",
    "ModelDenseAdam6.add(Dense(70))\n",
    "ModelDenseAdam6.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdam6.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam6.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam6.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam6.summary()\n",
    "\n",
    "DenseAdamPrediction6 = ModelDenseAdam6.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction6, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "42883b45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 1.6905 - MAE: 1.6905\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.5176 - MAE: 0.5176 1s -\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.5077 - MAE: 0.5077\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.5010 - MAE: 0.5010\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.5269 - MAE: 0.5269\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 782us/step - loss: 0.4968 - MAE: 0.4968\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 857us/step - loss: 0.5016 - MAE: 0.5016\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 0.4962 - MAE: 0.4962\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.5008 - MAE: 0.5008\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.4847 - MAE: 0.4847\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 830us/step - loss: 0.4940 - MAE: 0.4940\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.4759 - MAE: 0.4759\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 807us/step - loss: 0.4701 - MAE: 0.4701\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.4620 - MAE: 0.4620\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.4614 - MAE: 0.4614\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.4727 - MAE: 0.4727\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 816us/step - loss: 0.4619 - MAE: 0.4619\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.4543 - MAE: 0.4543\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.4487 - MAE: 0.4487\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 880us/step - loss: 0.4534 - MAE: 0.4534\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 968us/step - loss: 0.4512 - MAE: 0.4512\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 835us/step - loss: 0.4537 - MAE: 0.4537\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.4477 - MAE: 0.4477\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.4412 - MAE: 0.4412\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 807us/step - loss: 0.4887 - MAE: 0.4887\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.4381 - MAE: 0.4381\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 787us/step - loss: 0.4404 - MAE: 0.4404\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.4403 - MAE: 0.4403\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.4411 - MAE: 0.4411\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.4370 - MAE: 0.4370\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.4539 - MAE: 0.4539\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 805us/step - loss: 0.4422 - MAE: 0.4422\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 829us/step - loss: 0.4400 - MAE: 0.4400\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.4436 - MAE: 0.4436\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 856us/step - loss: 0.4408 - MAE: 0.4408\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (1, 14)                   0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (1, 70)                   0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.4200770623353359\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdam6_1 = Sequential()\n",
    "ModelDenseAdam6_1.add(Dense(14))\n",
    "ModelDenseAdam6_1.add(Dropout(0.1))\n",
    "ModelDenseAdam6_1.add(Dense(70))\n",
    "ModelDenseAdam6_1.add(Dropout(0.1))\n",
    "ModelDenseAdam6_1.add(Dense(7, activation='relu'))\n",
    "ModelDenseAdam6_1.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam6_1.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam6_1.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam6_1.summary()\n",
    "\n",
    "DenseAdamPrediction6_1 = ModelDenseAdam6_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction6_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1532e015",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.6103 - MAE: 0.6103\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 869us/step - loss: 0.5076 - MAE: 0.5076\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.5069 - MAE: 0.5069\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.5068 - MAE: 0.5068\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.5071 - MAE: 0.5071\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.5070 - MAE: 0.5070\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.5071 - MAE: 0.5071\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 897us/step - loss: 0.5071 - MAE: 0.5071\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.5070 - MAE: 0.5070\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_118 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (1, 192)                  2880      \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (1, 24)                   4632      \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (1, 9)                    225       \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (1, 1)                    10        \n",
      "=================================================================\n",
      "Total params: 7,915\n",
      "Trainable params: 7,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.48444183309396527\n"
     ]
    }
   ],
   "source": [
    "ModelDenseAdam7 = Sequential()\n",
    "ModelDenseAdam7.add(Dense(14))\n",
    "ModelDenseAdam7.add(Dense(192, activation='relu'))\n",
    "ModelDenseAdam7.add(Dense(24, activation='relu'))\n",
    "ModelDenseAdam7.add(Dense(9, activation='relu'))\n",
    "ModelDenseAdam7.add(Dense(1, activation='linear'))\n",
    "ModelDenseAdam7.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "ModelDenseAdam7.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "ModelDenseAdam7.summary()\n",
    "\n",
    "DenseAdamPrediction7 = ModelDenseAdam7.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction7, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132514d",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9574ca73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.049683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.061858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.065853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.066457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.075851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.082831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.092053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.098623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.101881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.103416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.110639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.119866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.121028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.126095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.134056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.142294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.153027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.160635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.164326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.205296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.306704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.383463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.415526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.420077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.483963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.484442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.485159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.485186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "5   0.049683\n",
       "19  0.061858\n",
       "22  0.065853\n",
       "6   0.066457\n",
       "0   0.073950\n",
       "26  0.075851\n",
       "4   0.076943\n",
       "2   0.082831\n",
       "1   0.092053\n",
       "15  0.098623\n",
       "24  0.101881\n",
       "13  0.103416\n",
       "23  0.110639\n",
       "27  0.119866\n",
       "9   0.121028\n",
       "17  0.126095\n",
       "16  0.134056\n",
       "7   0.142294\n",
       "21  0.153027\n",
       "12  0.160635\n",
       "14  0.164326\n",
       "25  0.205296\n",
       "3   0.306704\n",
       "11  0.383463\n",
       "8   0.415526\n",
       "28  0.420077\n",
       "18  0.483963\n",
       "29  0.484442\n",
       "20  0.485159\n",
       "10  0.485186"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).sort_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ed8d18d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Analytic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Analytic'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-17f5f2fb87ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mREP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenseAdamaxPrediction3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mREP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Analytic'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Analytic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mREP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Analytic'"
     ]
    }
   ],
   "source": [
    "REP = y_test.copy()\n",
    "\n",
    "REP['Pred'] = DenseAdamaxPrediction3\n",
    "REP['Analytic'] = x_test['Analytic'].values\n",
    "REP.sort_index().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807bdc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(REP['señal'], REP['Pred']))\n",
    "print(mean_absolute_error(REP['señal'], REP['Analytic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dc8445",
   "metadata": {},
   "source": [
    "# Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7d6222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "MMS = MinMaxScaler()\n",
    "NewX = pd.DataFrame(MMS.fit_transform(x), index=x.index, columns=x.columns)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(NewX, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af305d1",
   "metadata": {},
   "source": [
    "# Trying Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d649b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e627b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142c102d",
   "metadata": {},
   "source": [
    "## Dense Adamax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7e040ef1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.2617 - MAE: 0.2617\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0992 - MAE: 0.0992\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 971us/step - loss: 0.0861 - MAE: 0.0861\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 916us/step - loss: 0.0838 - MAE: 0.0838\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 907us/step - loss: 0.0827 - MAE: 0.0827\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0801 - MAE: 0.0801\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 895us/step - loss: 0.0811 - MAE: 0.0811\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 917us/step - loss: 0.0787 - MAE: 0.0787\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 917us/step - loss: 0.0776 - MAE: 0.0776\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0774 - MAE: 0.0774\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 914us/step - loss: 0.0759 - MAE: 0.0759\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0750 - MAE: 0.0750\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0745 - MAE: 0.0745\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0714 - MAE: 0.0714\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 926us/step - loss: 0.0718 - MAE: 0.0718\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.0731 - MAE: 0.0731\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 901us/step - loss: 0.0718 - MAE: 0.0718\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0696 - MAE: 0.0696\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 896us/step - loss: 0.0701 - MAE: 0.0701\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 902us/step - loss: 0.0697 - MAE: 0.0697\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 886us/step - loss: 0.0688 - MAE: 0.0688\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 895us/step - loss: 0.0678 - MAE: 0.0678\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 913us/step - loss: 0.0679 - MAE: 0.0679\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.0666 - MAE: 0.0666\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 907us/step - loss: 0.0658 - MAE: 0.0658\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 896us/step - loss: 0.0646 - MAE: 0.0646\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.0651 - MAE: 0.0651\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.0645 - MAE: 0.0645\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0632 - MAE: 0.0632\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 908us/step - loss: 0.0636 - MAE: 0.0636\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 929us/step - loss: 0.0620 - MAE: 0.0620\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.0610 - MAE: 0.0610\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.0622 - MAE: 0.0622\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0608 - MAE: 0.0608\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.0606 - MAE: 0.0606\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 890us/step - loss: 0.0594 - MAE: 0.0594\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.0598 - MAE: 0.0598\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 914us/step - loss: 0.0594 - MAE: 0.0594\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0594 - MAE: 0.0594\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0590 - MAE: 0.0590\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0590 - MAE: 0.0590\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 974us/step - loss: 0.0587 - MAE: 0.0587\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0575 - MAE: 0.0575\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 942us/step - loss: 0.0569 - MAE: 0.0569\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 926us/step - loss: 0.0571 - MAE: 0.0571\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.0562 - MAE: 0.0562 1s - los\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 908us/step - loss: 0.0556 - MAE: 0.0556\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0553 - MAE: 0.0553\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 902us/step - loss: 0.0558 - MAE: 0.0558\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.0551 - MAE: 0.0551\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 926us/step - loss: 0.0557 - MAE: 0.0557\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 919us/step - loss: 0.0545 - MAE: 0.0545\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0541 - MAE: 0.0541\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0549 - MAE: 0.0549\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 942us/step - loss: 0.0538 - MAE: 0.0538\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 935us/step - loss: 0.0531 - MAE: 0.0531\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 913us/step - loss: 0.0531 - MAE: 0.0531\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 997us/step - loss: 0.0530 - MAE: 0.0530\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0529 - MAE: 0.0529\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 897us/step - loss: 0.0521 - MAE: 0.0521\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0515 - MAE: 0.0515\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 958us/step - loss: 0.0526 - MAE: 0.0526\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 965us/step - loss: 0.0517 - MAE: 0.0517\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 902us/step - loss: 0.0517 - MAE: 0.0517\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 897us/step - loss: 0.0522 - MAE: 0.0522\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0509 - MAE: 0.0509\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 926us/step - loss: 0.0503 - MAE: 0.0503\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0505 - MAE: 0.0505\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0507 - MAE: 0.0507\n",
      "Epoch 70/100\n",
      "2160/2160 [==============================] - 2s 917us/step - loss: 0.0506 - MAE: 0.0506\n",
      "Epoch 71/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0497 - MAE: 0.0497\n",
      "Epoch 72/100\n",
      "2160/2160 [==============================] - 2s 903us/step - loss: 0.0499 - MAE: 0.0499\n",
      "Epoch 73/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0494 - MAE: 0.0494\n",
      "Epoch 74/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0489 - MAE: 0.0489\n",
      "Epoch 75/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.0491 - MAE: 0.0491\n",
      "Epoch 76/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0492 - MAE: 0.0492\n",
      "Epoch 77/100\n",
      "2160/2160 [==============================] - 2s 913us/step - loss: 0.0485 - MAE: 0.0485\n",
      "Epoch 78/100\n",
      "2160/2160 [==============================] - 2s 941us/step - loss: 0.0488 - MAE: 0.0488\n",
      "Epoch 79/100\n",
      "2160/2160 [==============================] - 2s 926us/step - loss: 0.0488 - MAE: 0.0488\n",
      "Epoch 80/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0476 - MAE: 0.0476\n",
      "Epoch 81/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0482 - MAE: 0.0482\n",
      "Epoch 82/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.0478 - MAE: 0.0478\n",
      "Epoch 83/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0480 - MAE: 0.0480\n",
      "Epoch 84/100\n",
      "2160/2160 [==============================] - 2s 911us/step - loss: 0.0478 - MAE: 0.0478\n",
      "Epoch 85/100\n",
      "2160/2160 [==============================] - 2s 899us/step - loss: 0.0477 - MAE: 0.0477\n",
      "Test score: 0.04618874454538769\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Model22DenseAdamax1 = Sequential()\n",
    "Model22DenseAdamax1.add(Dense(14))\n",
    "Model22DenseAdamax1.add(Dense(70, activation='relu'))\n",
    "Model22DenseAdamax1.add(Dense(7, activation='relu'))\n",
    "Model22DenseAdamax1.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdamax1.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdamax1.fit(x_train.values, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseAdamaxPrediction1 = Model22DenseAdamax1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "334799ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 957us/step - loss: 0.3817 - MAE: 0.3817\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 965us/step - loss: 0.2219 - MAE: 0.2219\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 944us/step - loss: 0.1777 - MAE: 0.1777\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 960us/step - loss: 0.1612 - MAE: 0.1612\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.1470 - MAE: 0.1470\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1407 - MAE: 0.1407\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 947us/step - loss: 0.1298 - MAE: 0.1298\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.1264 - MAE: 0.1264\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 913us/step - loss: 0.1180 - MAE: 0.1180\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 914us/step - loss: 0.1149 - MAE: 0.1149\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 935us/step - loss: 0.1116 - MAE: 0.1116\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 943us/step - loss: 0.1050 - MAE: 0.1050\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 928us/step - loss: 0.1020 - MAE: 0.1020\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 938us/step - loss: 0.1016 - MAE: 0.1016\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.0980 - MAE: 0.0980\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0974 - MAE: 0.0974\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0972 - MAE: 0.0972\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 941us/step - loss: 0.0945 - MAE: 0.0945\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 952us/step - loss: 0.0928 - MAE: 0.0928\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0935 - MAE: 0.0935\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0912 - MAE: 0.0912\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.0907 - MAE: 0.0907\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 948us/step - loss: 0.0897 - MAE: 0.0897\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0890 - MAE: 0.0890\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 935us/step - loss: 0.0923 - MAE: 0.0923\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0868 - MAE: 0.0868\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 998us/step - loss: 0.0883 - MAE: 0.0883\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 992us/step - loss: 0.0864 - MAE: 0.0864\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 932us/step - loss: 0.0844 - MAE: 0.0844\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0889 - MAE: 0.0889\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0833 - MAE: 0.0833\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 990us/step - loss: 0.0861 - MAE: 0.0861\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0857 - MAE: 0.0857\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 948us/step - loss: 0.0877 - MAE: 0.0877\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 929us/step - loss: 0.0827 - MAE: 0.0827\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.0843 - MAE: 0.0843\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 961us/step - loss: 0.0826 - MAE: 0.0826\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0852 - MAE: 0.0852\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 955us/step - loss: 0.0859 - MAE: 0.0859\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0830 - MAE: 0.0830\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0827 - MAE: 0.0827\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 992us/step - loss: 0.0808 - MAE: 0.0808\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0830 - MAE: 0.0830\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0825 - MAE: 0.0825\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0824 - MAE: 0.0824\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 966us/step - loss: 0.0831 - MAE: 0.0831\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0815 - MAE: 0.0815\n",
      "Test score: 0.061669735938649516\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Model22DenseAdamax1_1 = Sequential()\n",
    "Model22DenseAdamax1_1.add(Dense(14))\n",
    "Model22DenseAdamax1_1.add(Dropout(0.1))\n",
    "Model22DenseAdamax1_1.add(Dense(70, activation='relu'))\n",
    "Model22DenseAdamax1_1.add(Dropout(0.1))\n",
    "Model22DenseAdamax1_1.add(Dense(7, activation='relu'))\n",
    "Model22DenseAdamax1_1.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdamax1_1.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdamax1_1.fit(x_train.values, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseAdamaxPrediction1_1 = Model22DenseAdamax1_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction1_1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "afe1efc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 954us/step - loss: 0.2754 - MAE: 0.2754\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 971us/step - loss: 0.1169 - MAE: 0.1169\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 972us/step - loss: 0.1034 - MAE: 0.1034\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.1007 - MAE: 0.1007\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 907us/step - loss: 0.0968 - MAE: 0.0968\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0930 - MAE: 0.0930\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0916 - MAE: 0.0916\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 982us/step - loss: 0.0926 - MAE: 0.0926\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 948us/step - loss: 0.0894 - MAE: 0.0894\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 943us/step - loss: 0.0858 - MAE: 0.0858\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 952us/step - loss: 0.0853 - MAE: 0.0853\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 970us/step - loss: 0.0832 - MAE: 0.0832\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 976us/step - loss: 0.0838 - MAE: 0.0838\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 975us/step - loss: 0.0805 - MAE: 0.0805\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0802 - MAE: 0.0802\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 987us/step - loss: 0.0776 - MAE: 0.0776\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 938us/step - loss: 0.0789 - MAE: 0.0789\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 938us/step - loss: 0.0773 - MAE: 0.0773\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0742 - MAE: 0.0742\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 950us/step - loss: 0.0743 - MAE: 0.0743\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.0740 - MAE: 0.0740\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0733 - MAE: 0.0733\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 973us/step - loss: 0.0726 - MAE: 0.0726\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0732 - MAE: 0.0732\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0728 - MAE: 0.0728\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 969us/step - loss: 0.0719 - MAE: 0.0719\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 944us/step - loss: 0.0703 - MAE: 0.0703\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 954us/step - loss: 0.0706 - MAE: 0.0706\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 0.0690 - MAE: 0.0690\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0695 - MAE: 0.0695\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0682 - MAE: 0.0682\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 947us/step - loss: 0.0667 - MAE: 0.0667\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0665 - MAE: 0.0665\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 967us/step - loss: 0.0662 - MAE: 0.0662\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0667 - MAE: 0.0667\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.0670 - MAE: 0.0670\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.0650 - MAE: 0.0650\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0655 - MAE: 0.0655\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 981us/step - loss: 0.0656 - MAE: 0.0656\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0640 - MAE: 0.0640\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 943us/step - loss: 0.0629 - MAE: 0.0629\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 961us/step - loss: 0.0635 - MAE: 0.0635\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0629 - MAE: 0.0629\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0631 - MAE: 0.0631\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 938us/step - loss: 0.0634 - MAE: 0.0634\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.0613 - MAE: 0.0613\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0625 - MAE: 0.0625\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0616 - MAE: 0.0616\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 941us/step - loss: 0.0606 - MAE: 0.0606\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 0.0607 - MAE: 0.0607\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0603 - MAE: 0.0603\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0603 - MAE: 0.0603\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 959us/step - loss: 0.0592 - MAE: 0.0592\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 960us/step - loss: 0.0597 - MAE: 0.0597\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 963us/step - loss: 0.0589 - MAE: 0.0589\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 954us/step - loss: 0.0585 - MAE: 0.0585\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0587 - MAE: 0.0587\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 947us/step - loss: 0.0577 - MAE: 0.0577\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 935us/step - loss: 0.0582 - MAE: 0.0582\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0583 - MAE: 0.0583\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0570 - MAE: 0.0570\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 949us/step - loss: 0.0564 - MAE: 0.0564\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.0563 - MAE: 0.0563\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 932us/step - loss: 0.0566 - MAE: 0.0566\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.0558 - MAE: 0.0558\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0550 - MAE: 0.0550\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.0555 - MAE: 0.0555\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 951us/step - loss: 0.0552 - MAE: 0.0552\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 950us/step - loss: 0.0540 - MAE: 0.0540\n",
      "Epoch 70/100\n",
      "2160/2160 [==============================] - 2s 963us/step - loss: 0.0539 - MAE: 0.0539\n",
      "Epoch 71/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.0530 - MAE: 0.0530\n",
      "Epoch 72/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0534 - MAE: 0.0534\n",
      "Epoch 73/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 0.0520 - MAE: 0.0520\n",
      "Epoch 74/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.0532 - MAE: 0.0532\n",
      "Epoch 75/100\n",
      "2160/2160 [==============================] - 2s 992us/step - loss: 0.0522 - MAE: 0.0522\n",
      "Epoch 76/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0525 - MAE: 0.0525\n",
      "Epoch 77/100\n",
      "2160/2160 [==============================] - 2s 921us/step - loss: 0.0519 - MAE: 0.0519\n",
      "Epoch 78/100\n",
      "2160/2160 [==============================] - 2s 914us/step - loss: 0.0522 - MAE: 0.0522\n",
      "Epoch 79/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0515 - MAE: 0.0515\n",
      "Epoch 80/100\n",
      "2160/2160 [==============================] - 2s 929us/step - loss: 0.0514 - MAE: 0.0514\n",
      "Epoch 81/100\n",
      "2160/2160 [==============================] - 2s 926us/step - loss: 0.0517 - MAE: 0.0517\n",
      "Epoch 82/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.0501 - MAE: 0.0501\n",
      "Epoch 83/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0517 - MAE: 0.0517\n",
      "Epoch 84/100\n",
      "2160/2160 [==============================] - 2s 938us/step - loss: 0.0512 - MAE: 0.0512\n",
      "Epoch 85/100\n",
      "2160/2160 [==============================] - 2s 927us/step - loss: 0.0502 - MAE: 0.0502\n",
      "Epoch 86/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0498 - MAE: 0.0498\n",
      "Epoch 87/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.0499 - MAE: 0.0499\n",
      "Epoch 88/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0497 - MAE: 0.0497\n",
      "Epoch 89/100\n",
      "2160/2160 [==============================] - 2s 947us/step - loss: 0.0495 - MAE: 0.0495\n",
      "Epoch 90/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0498 - MAE: 0.0498\n",
      "Epoch 91/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.0487 - MAE: 0.0487\n",
      "Epoch 92/100\n",
      "2160/2160 [==============================] - 2s 913us/step - loss: 0.0494 - MAE: 0.0494\n",
      "Epoch 93/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.0494 - MAE: 0.0494\n",
      "Epoch 94/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0492 - MAE: 0.0492\n",
      "Epoch 95/100\n",
      "2160/2160 [==============================] - 2s 941us/step - loss: 0.0476 - MAE: 0.0476\n",
      "Epoch 96/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0479 - MAE: 0.0479\n",
      "Epoch 97/100\n",
      "2160/2160 [==============================] - 2s 944us/step - loss: 0.0479 - MAE: 0.0479\n",
      "Epoch 98/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0469 - MAE: 0.0469\n",
      "Epoch 99/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0474 - MAE: 0.0474\n",
      "Epoch 100/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0472 - MAE: 0.0472\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_131 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.0448484305063653\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdamax2 = Sequential()\n",
    "Model22DenseAdamax2.add(Dense(14))\n",
    "Model22DenseAdamax2.add(Dense(70, activation='relu'))\n",
    "Model22DenseAdamax2.add(Dense(7, activation='elu'))\n",
    "Model22DenseAdamax2.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdamax2.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdamax2.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdamax2.summary()\n",
    "\n",
    "DenseAdamaxPrediction2 = Model22DenseAdamax2.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction2, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "07b3d046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 962us/step - loss: 0.3322 - MAE: 0.3322\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 942us/step - loss: 0.2035 - MAE: 0.2035\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 988us/step - loss: 0.1722 - MAE: 0.1722\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 955us/step - loss: 0.1545 - MAE: 0.1545\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1472 - MAE: 0.1472\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 952us/step - loss: 0.1350 - MAE: 0.1350\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.1358 - MAE: 0.1358\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.1292 - MAE: 0.1292\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.1246 - MAE: 0.1246\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 970us/step - loss: 0.1165 - MAE: 0.1165\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 958us/step - loss: 0.1127 - MAE: 0.1127\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.1122 - MAE: 0.1122\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.1049 - MAE: 0.1049\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 972us/step - loss: 0.1049 - MAE: 0.1049\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 0.1006 - MAE: 0.1006\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 964us/step - loss: 0.1001 - MAE: 0.1001\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 942us/step - loss: 0.0998 - MAE: 0.0998\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 0.0960 - MAE: 0.0960\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0922 - MAE: 0.0922\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.0918 - MAE: 0.0918\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0912 - MAE: 0.0912\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.0915 - MAE: 0.0915\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 926us/step - loss: 0.0911 - MAE: 0.0911\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 932us/step - loss: 0.0892 - MAE: 0.0892\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.0898 - MAE: 0.0898\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.0900 - MAE: 0.0900\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 943us/step - loss: 0.0879 - MAE: 0.0879\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 950us/step - loss: 0.0868 - MAE: 0.0868\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.0864 - MAE: 0.0864\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 949us/step - loss: 0.0864 - MAE: 0.0864\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0898 - MAE: 0.0898\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.0876 - MAE: 0.0876\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 982us/step - loss: 0.0851 - MAE: 0.0851\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 0.0834 - MAE: 0.0834\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 951us/step - loss: 0.0850 - MAE: 0.0850\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.0851 - MAE: 0.0851\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0845 - MAE: 0.0845\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 947us/step - loss: 0.0831 - MAE: 0.0831\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.0827 - MAE: 0.0827\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 958us/step - loss: 0.0836 - MAE: 0.0836\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 998us/step - loss: 0.0828 - MAE: 0.0828\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0844 - MAE: 0.0844\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 950us/step - loss: 0.0820 - MAE: 0.0820\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0820 - MAE: 0.0820\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 928us/step - loss: 0.0808 - MAE: 0.0808\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 929us/step - loss: 0.0813 - MAE: 0.0813\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.0814 - MAE: 0.0814\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0815 - MAE: 0.0815\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0804 - MAE: 0.0804\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0789 - MAE: 0.0789\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0821 - MAE: 0.0821\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 935us/step - loss: 0.0794 - MAE: 0.0794\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0812 - MAE: 0.0812\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.0806 - MAE: 0.0806\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.0805 - MAE: 0.0805\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_135 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (1, 14)                   0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (1, 70)                   0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.06512580697267797\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdamax2_1 = Sequential()\n",
    "Model22DenseAdamax2_1.add(Dense(14))\n",
    "Model22DenseAdamax2_1.add(Dropout(0.1))\n",
    "Model22DenseAdamax2_1.add(Dense(70, activation='relu'))\n",
    "Model22DenseAdamax2_1.add(Dropout(0.1))\n",
    "Model22DenseAdamax2_1.add(Dense(7, activation='elu'))\n",
    "Model22DenseAdamax2_1.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdamax2_1.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdamax2_1.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdamax2_1.summary()\n",
    "\n",
    "DenseAdamaxPrediction2_1 = Model22DenseAdamax2_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction2_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "878d78f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.2244 - MAE: 0.2244\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 972us/step - loss: 0.1005 - MAE: 0.1005\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0968 - MAE: 0.0968\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 976us/step - loss: 0.0946 - MAE: 0.0946\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0912 - MAE: 0.0912\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 944us/step - loss: 0.0900 - MAE: 0.0900\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0860 - MAE: 0.0860\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0856 - MAE: 0.0856\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 911us/step - loss: 0.0831 - MAE: 0.0831\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 916us/step - loss: 0.0822 - MAE: 0.0822\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0815 - MAE: 0.0815\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0805 - MAE: 0.0805\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0830 - MAE: 0.0830\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0783 - MAE: 0.0783\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0781 - MAE: 0.0781\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 935us/step - loss: 0.0787 - MAE: 0.0787\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 943us/step - loss: 0.0776 - MAE: 0.0776\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0765 - MAE: 0.0765\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 971us/step - loss: 0.0741 - MAE: 0.0741\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 962us/step - loss: 0.0747 - MAE: 0.0747\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0732 - MAE: 0.0732\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0727 - MAE: 0.0727\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 932us/step - loss: 0.0730 - MAE: 0.0730\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 928us/step - loss: 0.0729 - MAE: 0.0729\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 899us/step - loss: 0.0716 - MAE: 0.0716\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.0723 - MAE: 0.0723\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0721 - MAE: 0.0721\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 958us/step - loss: 0.0702 - MAE: 0.0702\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 927us/step - loss: 0.0708 - MAE: 0.0708\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 944us/step - loss: 0.0690 - MAE: 0.0690\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 959us/step - loss: 0.0693 - MAE: 0.0693\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0694 - MAE: 0.0694\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 935us/step - loss: 0.0686 - MAE: 0.0686\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.0687 - MAE: 0.0687 0s - loss: 0.0684 - MAE: 0.06\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 894us/step - loss: 0.0677 - MAE: 0.0677\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0684 - MAE: 0.0684\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0685 - MAE: 0.0685\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.0674 - MAE: 0.0674\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 908us/step - loss: 0.0661 - MAE: 0.0661\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.0659 - MAE: 0.0659\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 891us/step - loss: 0.0674 - MAE: 0.0674\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 932us/step - loss: 0.0654 - MAE: 0.0654\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 949us/step - loss: 0.0649 - MAE: 0.0649\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0654 - MAE: 0.0654\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 919us/step - loss: 0.0643 - MAE: 0.0643\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0651 - MAE: 0.0651\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 941us/step - loss: 0.0628 - MAE: 0.0628\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0633 - MAE: 0.0633\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0630 - MAE: 0.0630\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 907us/step - loss: 0.0640 - MAE: 0.0640\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.0624 - MAE: 0.0624\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.0627 - MAE: 0.0627\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0616 - MAE: 0.0616\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0621 - MAE: 0.0621\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 928us/step - loss: 0.0628 - MAE: 0.0628\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 912us/step - loss: 0.0619 - MAE: 0.0619\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.0616 - MAE: 0.0616\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 908us/step - loss: 0.0614 - MAE: 0.0614\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0609 - MAE: 0.0609\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.0612 - MAE: 0.0612\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0612 - MAE: 0.0612\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0607 - MAE: 0.0607\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 911us/step - loss: 0.0606 - MAE: 0.0606\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0593 - MAE: 0.0593\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 941us/step - loss: 0.0601 - MAE: 0.0601\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 984us/step - loss: 0.0596 - MAE: 0.0596\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.0591 - MAE: 0.0591\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0596 - MAE: 0.0596\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.0603 - MAE: 0.0603\n",
      "Epoch 70/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.0605 - MAE: 0.0605\n",
      "Epoch 71/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0586 - MAE: 0.0586\n",
      "Epoch 72/100\n",
      "2160/2160 [==============================] - 2s 914us/step - loss: 0.0588 - MAE: 0.0588\n",
      "Epoch 73/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.0586 - MAE: 0.0586\n",
      "Epoch 74/100\n",
      "2160/2160 [==============================] - 2s 942us/step - loss: 0.0589 - MAE: 0.0589\n",
      "Epoch 75/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.0570 - MAE: 0.0570\n",
      "Epoch 76/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0572 - MAE: 0.0572\n",
      "Epoch 77/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0572 - MAE: 0.0572\n",
      "Epoch 78/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.0577 - MAE: 0.0577\n",
      "Epoch 79/100\n",
      "2160/2160 [==============================] - 2s 928us/step - loss: 0.0572 - MAE: 0.0572\n",
      "Epoch 80/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0570 - MAE: 0.0570\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_139 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.05398609063981162\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdamax3 = Sequential()\n",
    "Model22DenseAdamax3.add(Dense(14))\n",
    "Model22DenseAdamax3.add(Dense(70, activation='relu'))\n",
    "Model22DenseAdamax3.add(Dense(7, activation='selu'))\n",
    "Model22DenseAdamax3.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdamax3.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdamax3.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdamax3.summary()\n",
    "\n",
    "DenseAdamaxPrediction3 = Model22DenseAdamax3.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction3, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dfbe1ce8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 950us/step - loss: 0.3104 - MAE: 0.3104\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.1042 - MAE: 0.1042\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0987 - MAE: 0.0987\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.0931 - MAE: 0.0931\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0948 - MAE: 0.0948\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 919us/step - loss: 0.0887 - MAE: 0.0887\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 947us/step - loss: 0.0867 - MAE: 0.0867\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 951us/step - loss: 0.0867 - MAE: 0.0867\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 951us/step - loss: 0.0823 - MAE: 0.0823\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 971us/step - loss: 0.0816 - MAE: 0.0816\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0811 - MAE: 0.0811\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 972us/step - loss: 0.0810 - MAE: 0.0810\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0778 - MAE: 0.0778\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 932us/step - loss: 0.0767 - MAE: 0.0767\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 965us/step - loss: 0.0765 - MAE: 0.0765\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0748 - MAE: 0.0748\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0732 - MAE: 0.0732\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 927us/step - loss: 0.0736 - MAE: 0.0736\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0719 - MAE: 0.0719\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 927us/step - loss: 0.0724 - MAE: 0.0724\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0722 - MAE: 0.0722\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 957us/step - loss: 0.0719 - MAE: 0.0719\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0704 - MAE: 0.0704\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 952us/step - loss: 0.0711 - MAE: 0.0711\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.0697 - MAE: 0.0697\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.0704 - MAE: 0.0704\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 951us/step - loss: 0.0697 - MAE: 0.0697\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0682 - MAE: 0.0682\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 935us/step - loss: 0.0678 - MAE: 0.0678\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0681 - MAE: 0.0681\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0688 - MAE: 0.0688\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.0661 - MAE: 0.0661\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 917us/step - loss: 0.0677 - MAE: 0.0677\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0672 - MAE: 0.0672\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 917us/step - loss: 0.0663 - MAE: 0.0663\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 929us/step - loss: 0.0663 - MAE: 0.0663\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 912us/step - loss: 0.0651 - MAE: 0.0651\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0669 - MAE: 0.0669\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 961us/step - loss: 0.0649 - MAE: 0.0649\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0641 - MAE: 0.0641\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 967us/step - loss: 0.0654 - MAE: 0.0654\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.0638 - MAE: 0.0638\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0645 - MAE: 0.0645\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.0633 - MAE: 0.0633\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0641 - MAE: 0.0641\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0635 - MAE: 0.0635\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0625 - MAE: 0.0625\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0625 - MAE: 0.0625\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 952us/step - loss: 0.0620 - MAE: 0.0620\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0618 - MAE: 0.0618\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 932us/step - loss: 0.0616 - MAE: 0.0616\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 927us/step - loss: 0.0613 - MAE: 0.0613\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 954us/step - loss: 0.0608 - MAE: 0.0608\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 935us/step - loss: 0.0616 - MAE: 0.0616\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 947us/step - loss: 0.0602 - MAE: 0.0602\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0598 - MAE: 0.0598\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 0.0597 - MAE: 0.0597\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0594 - MAE: 0.0594\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0598 - MAE: 0.0598\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.0592 - MAE: 0.0592\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.0589 - MAE: 0.0589\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 919us/step - loss: 0.0591 - MAE: 0.0591\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 921us/step - loss: 0.0587 - MAE: 0.0587\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 928us/step - loss: 0.0581 - MAE: 0.0581\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 921us/step - loss: 0.0576 - MAE: 0.0576\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0577 - MAE: 0.0577\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 948us/step - loss: 0.0569 - MAE: 0.0569\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0569 - MAE: 0.0569\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 980us/step - loss: 0.0566 - MAE: 0.0566\n",
      "Epoch 70/100\n",
      "2160/2160 [==============================] - 2s 928us/step - loss: 0.0567 - MAE: 0.0567\n",
      "Epoch 71/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0563 - MAE: 0.0563\n",
      "Epoch 72/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0560 - MAE: 0.0560\n",
      "Epoch 73/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0558 - MAE: 0.0558\n",
      "Epoch 74/100\n",
      "2160/2160 [==============================] - 2s 968us/step - loss: 0.0551 - MAE: 0.0551\n",
      "Epoch 75/100\n",
      "2160/2160 [==============================] - 2s 926us/step - loss: 0.0549 - MAE: 0.0549\n",
      "Epoch 76/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.0554 - MAE: 0.0554\n",
      "Epoch 77/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0547 - MAE: 0.0547\n",
      "Epoch 78/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0539 - MAE: 0.0539\n",
      "Epoch 79/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0534 - MAE: 0.0534\n",
      "Epoch 80/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0535 - MAE: 0.0535\n",
      "Epoch 81/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.0534 - MAE: 0.0534\n",
      "Epoch 82/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0539 - MAE: 0.0539\n",
      "Epoch 83/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0525 - MAE: 0.0525\n",
      "Epoch 84/100\n",
      "2160/2160 [==============================] - 2s 943us/step - loss: 0.0524 - MAE: 0.0524\n",
      "Epoch 85/100\n",
      "2160/2160 [==============================] - 2s 935us/step - loss: 0.0520 - MAE: 0.0520\n",
      "Epoch 86/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.0525 - MAE: 0.0525\n",
      "Epoch 87/100\n",
      "2160/2160 [==============================] - 2s 955us/step - loss: 0.0521 - MAE: 0.0521\n",
      "Epoch 88/100\n",
      "2160/2160 [==============================] - 2s 935us/step - loss: 0.0508 - MAE: 0.0508\n",
      "Epoch 89/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0507 - MAE: 0.0507\n",
      "Epoch 90/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0513 - MAE: 0.0513\n",
      "Epoch 91/100\n",
      "2160/2160 [==============================] - 2s 917us/step - loss: 0.0505 - MAE: 0.0505\n",
      "Epoch 92/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0502 - MAE: 0.0502\n",
      "Epoch 93/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0504 - MAE: 0.0504\n",
      "Epoch 94/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.0495 - MAE: 0.0495\n",
      "Epoch 95/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0505 - MAE: 0.0505\n",
      "Epoch 96/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0495 - MAE: 0.0495\n",
      "Epoch 97/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0493 - MAE: 0.0493\n",
      "Epoch 98/100\n",
      "2160/2160 [==============================] - 2s 962us/step - loss: 0.0488 - MAE: 0.0488\n",
      "Epoch 99/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 0.0483 - MAE: 0.0483\n",
      "Epoch 100/100\n",
      "2160/2160 [==============================] - 2s 962us/step - loss: 0.0482 - MAE: 0.0482\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_143 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.04970185433414035\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdamax4 = Sequential()\n",
    "Model22DenseAdamax4.add(Dense(14))\n",
    "Model22DenseAdamax4.add(Dense(70, activation='relu'))\n",
    "Model22DenseAdamax4.add(Dense(7, activation='elu'))\n",
    "Model22DenseAdamax4.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdamax4.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdamax4.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdamax4.summary()\n",
    "\n",
    "DenseAdamaxPrediction4 = Model22DenseAdamax4.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction4, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8b2259bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.3144 - MAE: 0.3144\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 976us/step - loss: 0.1111 - MAE: 0.1111\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 973us/step - loss: 0.0935 - MAE: 0.0935\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 917us/step - loss: 0.0911 - MAE: 0.0911\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0884 - MAE: 0.0884\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.0867 - MAE: 0.0867\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0844 - MAE: 0.0844\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.0830 - MAE: 0.0830\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 926us/step - loss: 0.0833 - MAE: 0.0833\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 926us/step - loss: 0.0796 - MAE: 0.0796\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 919us/step - loss: 0.0822 - MAE: 0.0822\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 921us/step - loss: 0.0786 - MAE: 0.0786\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 948us/step - loss: 0.0776 - MAE: 0.0776\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 954us/step - loss: 0.0762 - MAE: 0.0762\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0755 - MAE: 0.0755\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 973us/step - loss: 0.0758 - MAE: 0.0758\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 948us/step - loss: 0.0755 - MAE: 0.0755\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0733 - MAE: 0.0733\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0729 - MAE: 0.0729\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 942us/step - loss: 0.0730 - MAE: 0.0730\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.0713 - MAE: 0.0713\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 957us/step - loss: 0.0711 - MAE: 0.0711\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0702 - MAE: 0.0702\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0696 - MAE: 0.0696\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 966us/step - loss: 0.0704 - MAE: 0.0704\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 927us/step - loss: 0.0686 - MAE: 0.0686\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0674 - MAE: 0.0674\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0688 - MAE: 0.0688\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 927us/step - loss: 0.0678 - MAE: 0.0678\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.0677 - MAE: 0.0677\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0669 - MAE: 0.0669\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 987us/step - loss: 0.0671 - MAE: 0.0671\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0657 - MAE: 0.0657\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 964us/step - loss: 0.0666 - MAE: 0.0666\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0650 - MAE: 0.0650\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 911us/step - loss: 0.0651 - MAE: 0.0651\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 927us/step - loss: 0.0637 - MAE: 0.0637\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0649 - MAE: 0.0649\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0648 - MAE: 0.0648\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0649 - MAE: 0.0649\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 954us/step - loss: 0.0630 - MAE: 0.0630\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.0635 - MAE: 0.0635\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 944us/step - loss: 0.0609 - MAE: 0.0609\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0622 - MAE: 0.0622\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0621 - MAE: 0.0621\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0618 - MAE: 0.0618\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0617 - MAE: 0.0617\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.0605 - MAE: 0.0605\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 912us/step - loss: 0.0598 - MAE: 0.0598\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.0601 - MAE: 0.0601\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0603 - MAE: 0.0603\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 949us/step - loss: 0.0594 - MAE: 0.0594\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0593 - MAE: 0.0593\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 970us/step - loss: 0.0588 - MAE: 0.0588\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0594 - MAE: 0.0594\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0598 - MAE: 0.0598\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0584 - MAE: 0.0584\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0582 - MAE: 0.0582\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0569 - MAE: 0.0569\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0578 - MAE: 0.0578\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 996us/step - loss: 0.0567 - MAE: 0.0567\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0576 - MAE: 0.0576\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0570 - MAE: 0.0570\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0569 - MAE: 0.0569\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0565 - MAE: 0.0565\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0559 - MAE: 0.0559\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0554 - MAE: 0.0554\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0551 - MAE: 0.0551\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0551 - MAE: 0.0551\n",
      "Epoch 70/100\n",
      "2160/2160 [==============================] - 2s 964us/step - loss: 0.0549 - MAE: 0.0549\n",
      "Epoch 71/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.0548 - MAE: 0.0548\n",
      "Epoch 72/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0537 - MAE: 0.0537\n",
      "Epoch 73/100\n",
      "2160/2160 [==============================] - 2s 917us/step - loss: 0.0530 - MAE: 0.0530\n",
      "Epoch 74/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0529 - MAE: 0.0529\n",
      "Epoch 75/100\n",
      "2160/2160 [==============================] - 2s 912us/step - loss: 0.0524 - MAE: 0.0524\n",
      "Epoch 76/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0523 - MAE: 0.0523\n",
      "Epoch 77/100\n",
      "2160/2160 [==============================] - 2s 942us/step - loss: 0.0533 - MAE: 0.0533\n",
      "Epoch 78/100\n",
      "2160/2160 [==============================] - 2s 916us/step - loss: 0.0520 - MAE: 0.0520\n",
      "Epoch 79/100\n",
      "2160/2160 [==============================] - 2s 943us/step - loss: 0.0525 - MAE: 0.0525\n",
      "Epoch 80/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.0518 - MAE: 0.0518\n",
      "Epoch 81/100\n",
      "2160/2160 [==============================] - 2s 919us/step - loss: 0.0519 - MAE: 0.0519\n",
      "Epoch 82/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.0511 - MAE: 0.0511\n",
      "Epoch 83/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.0507 - MAE: 0.0507\n",
      "Epoch 84/100\n",
      "2160/2160 [==============================] - 2s 973us/step - loss: 0.0507 - MAE: 0.0507\n",
      "Epoch 85/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0509 - MAE: 0.0509\n",
      "Epoch 86/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 0.0501 - MAE: 0.0501\n",
      "Epoch 87/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.0497 - MAE: 0.0497\n",
      "Epoch 88/100\n",
      "2160/2160 [==============================] - 2s 938us/step - loss: 0.0492 - MAE: 0.0492\n",
      "Epoch 89/100\n",
      "2160/2160 [==============================] - 2s 970us/step - loss: 0.0492 - MAE: 0.0492\n",
      "Epoch 90/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0485 - MAE: 0.0485\n",
      "Epoch 91/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0484 - MAE: 0.0484\n",
      "Epoch 92/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.0473 - MAE: 0.0473\n",
      "Epoch 93/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0480 - MAE: 0.0480\n",
      "Epoch 94/100\n",
      "2160/2160 [==============================] - 2s 961us/step - loss: 0.0478 - MAE: 0.0478\n",
      "Epoch 95/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0478 - MAE: 0.0478\n",
      "Epoch 96/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0476 - MAE: 0.0476\n",
      "Epoch 97/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0463 - MAE: 0.0463\n",
      "Epoch 98/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0470 - MAE: 0.0470\n",
      "Epoch 99/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0466 - MAE: 0.0466\n",
      "Epoch 100/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0469 - MAE: 0.0469\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_147 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.0485444111573671\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdamax5 = Sequential()\n",
    "Model22DenseAdamax5.add(Dense(14))\n",
    "Model22DenseAdamax5.add(Dense(70, activation='relu'))\n",
    "Model22DenseAdamax5.add(Dense(7, activation='elu'))\n",
    "Model22DenseAdamax5.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdamax5.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdamax5.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdamax5.summary()\n",
    "\n",
    "DenseAdamaxPrediction5 = Model22DenseAdamax5.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction5, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bdbd8352",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.2455 - MAE: 0.2455\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1049 - MAE: 0.1049\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0997 - MAE: 0.0997\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0978 - MAE: 0.0978\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0971 - MAE: 0.0971\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0949 - MAE: 0.0949\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.0944 - MAE: 0.0944\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0902 - MAE: 0.0902\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 968us/step - loss: 0.0882 - MAE: 0.0882\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0894 - MAE: 0.0894\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0862 - MAE: 0.0862\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 884us/step - loss: 0.0847 - MAE: 0.0847\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 913us/step - loss: 0.0837 - MAE: 0.0837\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.0835 - MAE: 0.0835\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 986us/step - loss: 0.0818 - MAE: 0.0818\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 955us/step - loss: 0.0831 - MAE: 0.0831\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0808 - MAE: 0.0808\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0810 - MAE: 0.0810\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 995us/step - loss: 0.0806 - MAE: 0.0806\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 969us/step - loss: 0.0805 - MAE: 0.0805\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0796 - MAE: 0.0796\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0794 - MAE: 0.0794\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 994us/step - loss: 0.0801 - MAE: 0.0801\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 956us/step - loss: 0.0794 - MAE: 0.0794\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0787 - MAE: 0.0787\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 903us/step - loss: 0.0787 - MAE: 0.0787\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0803 - MAE: 0.0803\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0790 - MAE: 0.0790\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0793 - MAE: 0.0793\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0780 - MAE: 0.0780\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0774 - MAE: 0.0774\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 979us/step - loss: 0.0771 - MAE: 0.0771\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0779 - MAE: 0.0779\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0766 - MAE: 0.0766\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0781 - MAE: 0.0781\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 980us/step - loss: 0.0774 - MAE: 0.0774\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 929us/step - loss: 0.0771 - MAE: 0.0771\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0764 - MAE: 0.0764\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 988us/step - loss: 0.0770 - MAE: 0.0770\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0765 - MAE: 0.0765\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 947us/step - loss: 0.0760 - MAE: 0.0760\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0761 - MAE: 0.0761\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0756 - MAE: 0.0756\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0756 - MAE: 0.0756\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0754 - MAE: 0.0754\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0752 - MAE: 0.0752\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.0748 - MAE: 0.0748\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.0752 - MAE: 0.0752\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0747 - MAE: 0.0747\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.0756 - MAE: 0.0756\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 892us/step - loss: 0.0741 - MAE: 0.0741\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 889us/step - loss: 0.0739 - MAE: 0.0739\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 942us/step - loss: 0.0753 - MAE: 0.0753\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 894us/step - loss: 0.0742 - MAE: 0.0742\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 829us/step - loss: 0.0742 - MAE: 0.0742\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 840us/step - loss: 0.0739 - MAE: 0.0739\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.0742 - MAE: 0.0742\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_151 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.06650154902422574\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdamax6 = Sequential()\n",
    "Model22DenseAdamax6.add(Dense(14))\n",
    "Model22DenseAdamax6.add(Dense(70))\n",
    "Model22DenseAdamax6.add(Dense(7, activation='relu'))\n",
    "Model22DenseAdamax6.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdamax6.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdamax6.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdamax6.summary()\n",
    "\n",
    "DenseAdamaxPrediction6 = Model22DenseAdamax6.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction6, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1991bd26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.4632 - MAE: 0.4632\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.3273 - MAE: 0.3273\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 907us/step - loss: 0.2028 - MAE: 0.2028\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.1650 - MAE: 0.1650\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 997us/step - loss: 0.1465 - MAE: 0.1465\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 884us/step - loss: 0.1376 - MAE: 0.1376\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1336 - MAE: 0.1336\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1221 - MAE: 0.1221\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1173 - MAE: 0.1173\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1159 - MAE: 0.1159\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1104 - MAE: 0.1104\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1134 - MAE: 0.1134\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 964us/step - loss: 0.1132 - MAE: 0.1132\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1063 - MAE: 0.1063\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 949us/step - loss: 0.1042 - MAE: 0.1042\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.1065 - MAE: 0.1065\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 959us/step - loss: 0.1034 - MAE: 0.1034\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 992us/step - loss: 0.1027 - MAE: 0.1027\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 935us/step - loss: 0.1036 - MAE: 0.1036\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 941us/step - loss: 0.1030 - MAE: 0.1030\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 926us/step - loss: 0.0995 - MAE: 0.0995\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.0996 - MAE: 0.0996\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0979 - MAE: 0.0979\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0997 - MAE: 0.0997\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1001 - MAE: 0.1001\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0971 - MAE: 0.0971\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0984 - MAE: 0.0984\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0983 - MAE: 0.0983\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.0961 - MAE: 0.0961\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.0975 - MAE: 0.0975\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 859us/step - loss: 0.0965 - MAE: 0.0965\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 893us/step - loss: 0.0961 - MAE: 0.0961\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0950 - MAE: 0.0950\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 859us/step - loss: 0.0949 - MAE: 0.0949\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.0966 - MAE: 0.0966\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 941us/step - loss: 0.0961 - MAE: 0.0961\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 858us/step - loss: 0.0961 - MAE: 0.0961\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 994us/step - loss: 0.0972 - MAE: 0.0972\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 976us/step - loss: 0.0945 - MAE: 0.0945\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.0956 - MAE: 0.0956\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0937 - MAE: 0.0937\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0939 - MAE: 0.0939\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0944 - MAE: 0.0944\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0923 - MAE: 0.0923\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 998us/step - loss: 0.0922 - MAE: 0.0922\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0936 - MAE: 0.0936\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0917 - MAE: 0.0917\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 1000us/step - loss: 0.0920 - MAE: 0.0920\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 965us/step - loss: 0.0906 - MAE: 0.0906\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 976us/step - loss: 0.0901 - MAE: 0.0901\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 966us/step - loss: 0.0912 - MAE: 0.0912\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 959us/step - loss: 0.0913 - MAE: 0.0913\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 987us/step - loss: 0.0920 - MAE: 0.0920\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0901 - MAE: 0.0901\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.0895 - MAE: 0.0895\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 0.0919 - MAE: 0.0919\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0909 - MAE: 0.0909\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0896 - MAE: 0.0896\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0901 - MAE: 0.0901\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0895 - MAE: 0.0895\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0914 - MAE: 0.0914\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 917us/step - loss: 0.0878 - MAE: 0.0878\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 956us/step - loss: 0.0883 - MAE: 0.0883\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 967us/step - loss: 0.0895 - MAE: 0.0895\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 0.0883 - MAE: 0.0883\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 901us/step - loss: 0.0881 - MAE: 0.0881\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 954us/step - loss: 0.0896 - MAE: 0.0896\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_155 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (1, 14)                   0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (1, 70)                   0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.07336105339859007\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdamax6_1 = Sequential()\n",
    "Model22DenseAdamax6_1.add(Dense(14))\n",
    "Model22DenseAdamax6_1.add(Dropout(0.1))\n",
    "Model22DenseAdamax6_1.add(Dense(70))\n",
    "Model22DenseAdamax6_1.add(Dropout(0.1))\n",
    "Model22DenseAdamax6_1.add(Dense(7, activation='relu'))\n",
    "Model22DenseAdamax6_1.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdamax6_1.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdamax6_1.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdamax6_1.summary()\n",
    "\n",
    "DenseAdamaxPrediction6_1 = Model22DenseAdamax6_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction6_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "15af8df5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.3452 - MAE: 0.3452\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1190 - MAE: 0.1190\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1020 - MAE: 0.1020\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0934 - MAE: 0.0934\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0881 - MAE: 0.0881\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0847 - MAE: 0.0847\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0806 - MAE: 0.0806\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0777 - MAE: 0.0777\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0745 - MAE: 0.0745\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 1000us/step - loss: 0.0744 - MAE: 0.0744\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0716 - MAE: 0.0716\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0717 - MAE: 0.0717\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 975us/step - loss: 0.0683 - MAE: 0.0683\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 921us/step - loss: 0.0677 - MAE: 0.0677\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 991us/step - loss: 0.0676 - MAE: 0.0676\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 932us/step - loss: 0.0658 - MAE: 0.0658\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0642 - MAE: 0.0642\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 995us/step - loss: 0.0623 - MAE: 0.0623\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 955us/step - loss: 0.0609 - MAE: 0.0609\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 984us/step - loss: 0.0616 - MAE: 0.0616\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 928us/step - loss: 0.0600 - MAE: 0.0600\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0582 - MAE: 0.0582\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0580 - MAE: 0.0580\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 949us/step - loss: 0.0569 - MAE: 0.0569\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0568 - MAE: 0.0568\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 976us/step - loss: 0.0550 - MAE: 0.0550\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.0549 - MAE: 0.0549\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0530 - MAE: 0.0530\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 966us/step - loss: 0.0529 - MAE: 0.0529\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0512 - MAE: 0.0512\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0521 - MAE: 0.0521\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0499 - MAE: 0.0499\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 977us/step - loss: 0.0499 - MAE: 0.0499\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0502 - MAE: 0.0502\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0488 - MAE: 0.0488\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0478 - MAE: 0.0478\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0482 - MAE: 0.0482\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0472 - MAE: 0.0472\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.0471 - MAE: 0.0471\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 990us/step - loss: 0.0456 - MAE: 0.0456\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0453 - MAE: 0.0453\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0447 - MAE: 0.0447\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0431 - MAE: 0.0431\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0425 - MAE: 0.0425\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0435 - MAE: 0.0435\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0429 - MAE: 0.0429\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0418 - MAE: 0.0418\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 986us/step - loss: 0.0418 - MAE: 0.0418\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0410 - MAE: 0.0410\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0406 - MAE: 0.0406\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0399 - MAE: 0.0399\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0396 - MAE: 0.0396\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0391 - MAE: 0.0391\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 992us/step - loss: 0.0396 - MAE: 0.0396\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0384 - MAE: 0.0384\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0378 - MAE: 0.0378\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0378 - MAE: 0.0378\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 980us/step - loss: 0.0375 - MAE: 0.0375\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 948us/step - loss: 0.0380 - MAE: 0.0380\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0365 - MAE: 0.0365\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0371 - MAE: 0.0371\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0352 - MAE: 0.0352\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 877us/step - loss: 0.0360 - MAE: 0.0360\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0362 - MAE: 0.0362\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0357 - MAE: 0.0357\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.0338 - MAE: 0.0338\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0340 - MAE: 0.0340\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0346 - MAE: 0.0346\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 952us/step - loss: 0.0328 - MAE: 0.0328\n",
      "Epoch 70/100\n",
      "2160/2160 [==============================] - 2s 928us/step - loss: 0.0335 - MAE: 0.0335\n",
      "Epoch 71/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0327 - MAE: 0.0327\n",
      "Epoch 72/100\n",
      "2160/2160 [==============================] - 2s 895us/step - loss: 0.0329 - MAE: 0.0329\n",
      "Epoch 73/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.0326 - MAE: 0.0326\n",
      "Epoch 74/100\n",
      "2160/2160 [==============================] - 2s 949us/step - loss: 0.0323 - MAE: 0.0323\n",
      "Epoch 75/100\n",
      "2160/2160 [==============================] - 2s 998us/step - loss: 0.0312 - MAE: 0.0312\n",
      "Epoch 76/100\n",
      "2160/2160 [==============================] - 2s 996us/step - loss: 0.0322 - MAE: 0.0322\n",
      "Epoch 77/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0312 - MAE: 0.0312\n",
      "Epoch 78/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0312 - MAE: 0.0312\n",
      "Epoch 79/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0306 - MAE: 0.0306\n",
      "Epoch 80/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0310 - MAE: 0.0310\n",
      "Epoch 81/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0307 - MAE: 0.0307\n",
      "Epoch 82/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0303 - MAE: 0.0303\n",
      "Epoch 83/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0298 - MAE: 0.0298\n",
      "Epoch 84/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.0300 - MAE: 0.0300\n",
      "Epoch 85/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0303 - MAE: 0.0303\n",
      "Epoch 86/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0292 - MAE: 0.0292\n",
      "Epoch 87/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0286 - MAE: 0.0286\n",
      "Epoch 88/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0284 - MAE: 0.0284\n",
      "Epoch 89/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.0277 - MAE: 0.0277\n",
      "Epoch 90/100\n",
      "2160/2160 [==============================] - 2s 973us/step - loss: 0.0288 - MAE: 0.0288\n",
      "Epoch 91/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.0278 - MAE: 0.0278\n",
      "Epoch 92/100\n",
      "2160/2160 [==============================] - 2s 853us/step - loss: 0.0276 - MAE: 0.0276\n",
      "Epoch 93/100\n",
      "2160/2160 [==============================] - 2s 878us/step - loss: 0.0269 - MAE: 0.0269\n",
      "Epoch 94/100\n",
      "2160/2160 [==============================] - 2s 878us/step - loss: 0.0277 - MAE: 0.0277\n",
      "Epoch 95/100\n",
      "2160/2160 [==============================] - 2s 840us/step - loss: 0.0272 - MAE: 0.0272\n",
      "Epoch 96/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.0272 - MAE: 0.0272\n",
      "Epoch 97/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.0271 - MAE: 0.0271\n",
      "Epoch 98/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.0262 - MAE: 0.0262\n",
      "Epoch 99/100\n",
      "2160/2160 [==============================] - 2s 877us/step - loss: 0.0261 - MAE: 0.0261\n",
      "Epoch 100/100\n",
      "2160/2160 [==============================] - 2s 876us/step - loss: 0.0255 - MAE: 0.0255\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_159 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (1, 192)                  2880      \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (1, 24)                   4632      \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (1, 9)                    225       \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (1, 1)                    10        \n",
      "=================================================================\n",
      "Total params: 7,915\n",
      "Trainable params: 7,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.0261501592826332\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdamax7 = Sequential()\n",
    "Model22DenseAdamax7.add(Dense(14))\n",
    "Model22DenseAdamax7.add(Dense(192, activation='relu'))\n",
    "Model22DenseAdamax7.add(Dense(24, activation='relu'))\n",
    "Model22DenseAdamax7.add(Dense(9, activation='relu'))\n",
    "Model22DenseAdamax7.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdamax7.compile(optimizer='Adamax', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdamax7.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdamax7.summary()\n",
    "\n",
    "DenseAdamaxPrediction7 = Model22DenseAdamax7.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamaxPrediction7, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bcbb59",
   "metadata": {},
   "source": [
    "## Dense RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fe6a9261",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 793us/step - loss: 0.2134 - MAE: 0.2134\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 792us/step - loss: 0.1105 - MAE: 0.1105\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 728us/step - loss: 0.1017 - MAE: 0.1017\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 746us/step - loss: 0.0962 - MAE: 0.0962\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 743us/step - loss: 0.0911 - MAE: 0.0911\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 725us/step - loss: 0.0892 - MAE: 0.0892\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 742us/step - loss: 0.0852 - MAE: 0.0852\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 759us/step - loss: 0.0843 - MAE: 0.0843\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 713us/step - loss: 0.0815 - MAE: 0.0815\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 714us/step - loss: 0.0795 - MAE: 0.0795\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 714us/step - loss: 0.0778 - MAE: 0.0778\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 735us/step - loss: 0.0757 - MAE: 0.0757\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 695us/step - loss: 0.0747 - MAE: 0.0747\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 711us/step - loss: 0.0720 - MAE: 0.0720\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 708us/step - loss: 0.0711 - MAE: 0.0711\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 695us/step - loss: 0.0705 - MAE: 0.0705\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 706us/step - loss: 0.0689 - MAE: 0.0689\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 1s 686us/step - loss: 0.0665 - MAE: 0.0665\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 1s 687us/step - loss: 0.0663 - MAE: 0.0663\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 698us/step - loss: 0.0651 - MAE: 0.0651\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 711us/step - loss: 0.0635 - MAE: 0.0635\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 766us/step - loss: 0.0627 - MAE: 0.0627\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 702us/step - loss: 0.0611 - MAE: 0.0611\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 1s 686us/step - loss: 0.0605 - MAE: 0.0605\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 706us/step - loss: 0.0599 - MAE: 0.0599\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 716us/step - loss: 0.0587 - MAE: 0.0587\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.0588 - MAE: 0.0588\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 709us/step - loss: 0.0560 - MAE: 0.0560\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 716us/step - loss: 0.0570 - MAE: 0.0570\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 695us/step - loss: 0.0565 - MAE: 0.0565\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 706us/step - loss: 0.0561 - MAE: 0.0561\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 716us/step - loss: 0.0556 - MAE: 0.0556\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 1s 691us/step - loss: 0.0551 - MAE: 0.0551\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 1s 680us/step - loss: 0.0538 - MAE: 0.0538\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 698us/step - loss: 0.0526 - MAE: 0.0526\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 703us/step - loss: 0.0527 - MAE: 0.0527\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 710us/step - loss: 0.0526 - MAE: 0.0526\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.0520 - MAE: 0.0520\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0528 - MAE: 0.0528\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 979us/step - loss: 0.0504 - MAE: 0.0504\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.0510 - MAE: 0.0510\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 790us/step - loss: 0.0499 - MAE: 0.0499\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.0507 - MAE: 0.0507\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 928us/step - loss: 0.0491 - MAE: 0.0491\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0495 - MAE: 0.0495\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0492 - MAE: 0.0492\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 929us/step - loss: 0.0482 - MAE: 0.0482\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0466 - MAE: 0.0466\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 954us/step - loss: 0.0489 - MAE: 0.0489\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0469 - MAE: 0.0469\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0470 - MAE: 0.0470\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0464 - MAE: 0.0464\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0478 - MAE: 0.0478\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0467 - MAE: 0.0467\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 987us/step - loss: 0.0465 - MAE: 0.0465\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 897us/step - loss: 0.0452 - MAE: 0.0452\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 965us/step - loss: 0.0458 - MAE: 0.0458\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0443 - MAE: 0.0443\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 887us/step - loss: 0.0450 - MAE: 0.0450\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 800us/step - loss: 0.0448 - MAE: 0.0448\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 0.0439 - MAE: 0.0439\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 976us/step - loss: 0.0444 - MAE: 0.0444\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 899us/step - loss: 0.0447 - MAE: 0.0447\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 847us/step - loss: 0.0444 - MAE: 0.0444\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 786us/step - loss: 0.0438 - MAE: 0.0438\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.0434 - MAE: 0.0434\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0434 - MAE: 0.0434\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 994us/step - loss: 0.0439 - MAE: 0.0439\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 896us/step - loss: 0.0441 - MAE: 0.0441\n",
      "Epoch 70/100\n",
      "2160/2160 [==============================] - 2s 869us/step - loss: 0.0415 - MAE: 0.0415\n",
      "Epoch 71/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.0435 - MAE: 0.0435\n",
      "Epoch 72/100\n",
      "2160/2160 [==============================] - 2s 974us/step - loss: 0.0433 - MAE: 0.0433\n",
      "Epoch 73/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.0429 - MAE: 0.0429\n",
      "Epoch 74/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.0431 - MAE: 0.0431\n",
      "Epoch 75/100\n",
      "2160/2160 [==============================] - 2s 879us/step - loss: 0.0431 - MAE: 0.0431\n",
      "Test score: 0.03512159421531412\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Model22DenseRMSprop1 = Sequential()\n",
    "Model22DenseRMSprop1.add(Dense(14))\n",
    "Model22DenseRMSprop1.add(Dense(70, activation='relu'))\n",
    "Model22DenseRMSprop1.add(Dense(7, activation='relu'))\n",
    "Model22DenseRMSprop1.add(Dense(1, activation='linear'))\n",
    "Model22DenseRMSprop1.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseRMSprop1.fit(x_train.values, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseRMSpropPrediction1 = Model22DenseRMSprop1.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ef27c0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.2906 - MAE: 0.2906\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 911us/step - loss: 0.1484 - MAE: 0.1484\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 855us/step - loss: 0.1255 - MAE: 0.1255\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.1149 - MAE: 0.1149\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.1095 - MAE: 0.1095\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.1050 - MAE: 0.1050\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.1056 - MAE: 0.1056\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.1003 - MAE: 0.1003\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 958us/step - loss: 0.0995 - MAE: 0.0995\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0980 - MAE: 0.0980\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 914us/step - loss: 0.0989 - MAE: 0.0989\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 882us/step - loss: 0.0956 - MAE: 0.0956\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.0948 - MAE: 0.0948\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.0948 - MAE: 0.0948\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 0.0948 - MAE: 0.0948\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 778us/step - loss: 0.0916 - MAE: 0.0916\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 766us/step - loss: 0.0931 - MAE: 0.0931\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 870us/step - loss: 0.0881 - MAE: 0.0881\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 996us/step - loss: 0.0899 - MAE: 0.0899\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 984us/step - loss: 0.0909 - MAE: 0.0909\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0864 - MAE: 0.0864\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0891 - MAE: 0.0891\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 853us/step - loss: 0.0867 - MAE: 0.0867\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0873 - MAE: 0.0873\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 880us/step - loss: 0.0833 - MAE: 0.0833\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 870us/step - loss: 0.0848 - MAE: 0.0848\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 880us/step - loss: 0.0884 - MAE: 0.0884\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0880 - MAE: 0.0880\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 883us/step - loss: 0.0844 - MAE: 0.0844\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0871 - MAE: 0.0871\n",
      "Test score: 0.07108216797519239\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Model22DenseRMSprop1_1 = Sequential()\n",
    "Model22DenseRMSprop1_1.add(Dense(14))\n",
    "Model22DenseRMSprop1_1.add(Dropout(0.1))\n",
    "Model22DenseRMSprop1_1.add(Dense(70, activation='relu'))\n",
    "Model22DenseRMSprop1_1.add(Dropout(0.1))\n",
    "Model22DenseRMSprop1_1.add(Dense(7, activation='relu'))\n",
    "Model22DenseRMSprop1_1.add(Dense(1, activation='linear'))\n",
    "Model22DenseRMSprop1_1.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseRMSprop1_1.fit(x_train.values, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseRMSpropPrediction1_1 = Model22DenseRMSprop1_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction1_1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9e0e21c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 897us/step - loss: 0.1853 - MAE: 0.1853\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 963us/step - loss: 0.1108 - MAE: 0.1108\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.0996 - MAE: 0.0996\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 773us/step - loss: 0.0925 - MAE: 0.0925\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 874us/step - loss: 0.0890 - MAE: 0.0890\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0842 - MAE: 0.0842\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0816 - MAE: 0.0816\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 896us/step - loss: 0.0804 - MAE: 0.0804\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 908us/step - loss: 0.0777 - MAE: 0.0777\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 921us/step - loss: 0.0778 - MAE: 0.0778\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 903us/step - loss: 0.0744 - MAE: 0.0744\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 998us/step - loss: 0.0745 - MAE: 0.0745\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 863us/step - loss: 0.0728 - MAE: 0.0728\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 992us/step - loss: 0.0713 - MAE: 0.0713\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.0707 - MAE: 0.0707\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 803us/step - loss: 0.0698 - MAE: 0.0698\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.0698 - MAE: 0.0698\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.0680 - MAE: 0.0680\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 992us/step - loss: 0.0669 - MAE: 0.0669\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 941us/step - loss: 0.0675 - MAE: 0.0675\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 894us/step - loss: 0.0658 - MAE: 0.0658\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 967us/step - loss: 0.0654 - MAE: 0.0654\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 897us/step - loss: 0.0657 - MAE: 0.0657\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 907us/step - loss: 0.0630 - MAE: 0.0630\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 965us/step - loss: 0.0641 - MAE: 0.0641\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 833us/step - loss: 0.0634 - MAE: 0.0634\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 769us/step - loss: 0.0634 - MAE: 0.0634\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 773us/step - loss: 0.0634 - MAE: 0.0634\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 772us/step - loss: 0.0623 - MAE: 0.0623\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 765us/step - loss: 0.0629 - MAE: 0.0629\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 965us/step - loss: 0.0612 - MAE: 0.0612\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 919us/step - loss: 0.0613 - MAE: 0.0613\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.0619 - MAE: 0.0619\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0613 - MAE: 0.0613\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0612 - MAE: 0.0612\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0597 - MAE: 0.0597\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 960us/step - loss: 0.0601 - MAE: 0.0601\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 985us/step - loss: 0.0608 - MAE: 0.0608\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 995us/step - loss: 0.0601 - MAE: 0.0601\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0592 - MAE: 0.0592\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 952us/step - loss: 0.0589 - MAE: 0.0589\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0588 - MAE: 0.0588\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 916us/step - loss: 0.0587 - MAE: 0.0587\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 954us/step - loss: 0.0582 - MAE: 0.0582\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0587 - MAE: 0.0587\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0582 - MAE: 0.0582\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 851us/step - loss: 0.0576 - MAE: 0.0576\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 869us/step - loss: 0.0573 - MAE: 0.0573\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 868us/step - loss: 0.0580 - MAE: 0.0580\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 866us/step - loss: 0.0565 - MAE: 0.0565\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 867us/step - loss: 0.0569 - MAE: 0.0569\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 917us/step - loss: 0.0565 - MAE: 0.0565\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0568 - MAE: 0.0568\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 970us/step - loss: 0.0567 - MAE: 0.0567\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0558 - MAE: 0.0558\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0554 - MAE: 0.0554\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0553 - MAE: 0.0553\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0553 - MAE: 0.0553\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 833us/step - loss: 0.0547 - MAE: 0.0547\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 962us/step - loss: 0.0543 - MAE: 0.0543\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.0551 - MAE: 0.0551\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 810us/step - loss: 0.0546 - MAE: 0.0546\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 881us/step - loss: 0.0551 - MAE: 0.0551\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 914us/step - loss: 0.0545 - MAE: 0.0545\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 980us/step - loss: 0.0546 - MAE: 0.0546\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_172 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.051302785713137\n"
     ]
    }
   ],
   "source": [
    "Model22DenseRMSprop2 = Sequential()\n",
    "Model22DenseRMSprop2.add(Dense(14))\n",
    "Model22DenseRMSprop2.add(Dense(70, activation='relu'))\n",
    "Model22DenseRMSprop2.add(Dense(7, activation='elu'))\n",
    "Model22DenseRMSprop2.add(Dense(1, activation='linear'))\n",
    "Model22DenseRMSprop2.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseRMSprop2.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseRMSprop2.summary()\n",
    "\n",
    "DenseRMSpropPrediction2 = Model22DenseRMSprop2.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction2, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1fd28022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.3014 - MAE: 0.3014\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 978us/step - loss: 0.1770 - MAE: 0.1770\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 974us/step - loss: 0.1462 - MAE: 0.1462\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 989us/step - loss: 0.1387 - MAE: 0.1387\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.1263 - MAE: 0.1263\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.1226 - MAE: 0.1226\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 990us/step - loss: 0.1177 - MAE: 0.1177\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1150 - MAE: 0.1150\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 997us/step - loss: 0.1114 - MAE: 0.1114\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 979us/step - loss: 0.1105 - MAE: 0.1105\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 944us/step - loss: 0.1073 - MAE: 0.1073\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.1051 - MAE: 0.1051\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 900us/step - loss: 0.1051 - MAE: 0.1051\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 856us/step - loss: 0.0997 - MAE: 0.0997\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 873us/step - loss: 0.0980 - MAE: 0.0980\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 987us/step - loss: 0.1021 - MAE: 0.1021\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 979us/step - loss: 0.0968 - MAE: 0.0968\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.0943 - MAE: 0.0943\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 993us/step - loss: 0.0957 - MAE: 0.0957\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 913us/step - loss: 0.0955 - MAE: 0.0955\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 965us/step - loss: 0.0936 - MAE: 0.0936\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0947 - MAE: 0.0947\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 899us/step - loss: 0.0952 - MAE: 0.0952\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0896 - MAE: 0.0896\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 995us/step - loss: 0.0924 - MAE: 0.0924\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 932us/step - loss: 0.0915 - MAE: 0.0915\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 983us/step - loss: 0.0902 - MAE: 0.0902\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.0903 - MAE: 0.0903\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 969us/step - loss: 0.0919 - MAE: 0.0919\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_176 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (1, 14)                   0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (1, 70)                   0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.07218295842037578\n"
     ]
    }
   ],
   "source": [
    "Model22DenseRMSprop2_1 = Sequential()\n",
    "Model22DenseRMSprop2_1.add(Dense(14))\n",
    "Model22DenseRMSprop2_1.add(Dropout(0.1))\n",
    "Model22DenseRMSprop2_1.add(Dense(70, activation='relu'))\n",
    "Model22DenseRMSprop2_1.add(Dropout(0.1))\n",
    "Model22DenseRMSprop2_1.add(Dense(7, activation='elu'))\n",
    "Model22DenseRMSprop2_1.add(Dense(1, activation='linear'))\n",
    "Model22DenseRMSprop2_1.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseRMSprop2_1.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseRMSprop2_1.summary()\n",
    "\n",
    "DenseRMSpropPrediction2_1 = Model22DenseRMSprop2_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction2_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "71fb681a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 3s 975us/step - loss: 0.2026 - MAE: 0.2026\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 887us/step - loss: 0.1276 - MAE: 0.1276\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.1137 - MAE: 0.1137\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 975us/step - loss: 0.1051 - MAE: 0.1051\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.0998 - MAE: 0.0998\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 962us/step - loss: 0.0960 - MAE: 0.0960\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 963us/step - loss: 0.0907 - MAE: 0.0907\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.0890 - MAE: 0.0890\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 882us/step - loss: 0.0855 - MAE: 0.0855\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 876us/step - loss: 0.0829 - MAE: 0.0829\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0805 - MAE: 0.0805\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 975us/step - loss: 0.0787 - MAE: 0.0787\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 994us/step - loss: 0.0774 - MAE: 0.0774\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 881us/step - loss: 0.0768 - MAE: 0.0768\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 961us/step - loss: 0.0757 - MAE: 0.0757\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 798us/step - loss: 0.0757 - MAE: 0.0757\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0736 - MAE: 0.0736\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.0730 - MAE: 0.0730\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.0722 - MAE: 0.0722\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 786us/step - loss: 0.0711 - MAE: 0.0711\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 779us/step - loss: 0.0703 - MAE: 0.0703\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 791us/step - loss: 0.0692 - MAE: 0.0692\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 746us/step - loss: 0.0689 - MAE: 0.0689\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 746us/step - loss: 0.0686 - MAE: 0.0686\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.0687 - MAE: 0.0687\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.0682 - MAE: 0.0682\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.0675 - MAE: 0.0675\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.0675 - MAE: 0.0675\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 887us/step - loss: 0.0674 - MAE: 0.0674\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.0657 - MAE: 0.0657\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.0656 - MAE: 0.0656\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 709us/step - loss: 0.0642 - MAE: 0.0642\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 790us/step - loss: 0.0647 - MAE: 0.0647\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 985us/step - loss: 0.0651 - MAE: 0.0651\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0635 - MAE: 0.0635\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 851us/step - loss: 0.0639 - MAE: 0.0639\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 929us/step - loss: 0.0631 - MAE: 0.0631\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0631 - MAE: 0.0631\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 880us/step - loss: 0.0624 - MAE: 0.0624\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 895us/step - loss: 0.0616 - MAE: 0.0616\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 800us/step - loss: 0.0619 - MAE: 0.0619\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.0620 - MAE: 0.0620\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 897us/step - loss: 0.0620 - MAE: 0.0620\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 928us/step - loss: 0.0615 - MAE: 0.0615\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 972us/step - loss: 0.0612 - MAE: 0.0612\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 958us/step - loss: 0.0608 - MAE: 0.0608\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 971us/step - loss: 0.0611 - MAE: 0.0611\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 958us/step - loss: 0.0606 - MAE: 0.0606\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 986us/step - loss: 0.0600 - MAE: 0.0600\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 876us/step - loss: 0.0601 - MAE: 0.0601\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 960us/step - loss: 0.0594 - MAE: 0.0594\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0582 - MAE: 0.0582\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.0590 - MAE: 0.0590\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 941us/step - loss: 0.0601 - MAE: 0.0601\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 997us/step - loss: 0.0576 - MAE: 0.0576\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 964us/step - loss: 0.0569 - MAE: 0.0569\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.0591 - MAE: 0.0591\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 839us/step - loss: 0.0584 - MAE: 0.0584\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 832us/step - loss: 0.0561 - MAE: 0.0561\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0572 - MAE: 0.0572\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 964us/step - loss: 0.0573 - MAE: 0.0573\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 865us/step - loss: 0.0561 - MAE: 0.0561\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 998us/step - loss: 0.0576 - MAE: 0.0576\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0563 - MAE: 0.0563\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_180 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.05663287427821477\n"
     ]
    }
   ],
   "source": [
    "Model22DenseRMSprop3 = Sequential()\n",
    "Model22DenseRMSprop3.add(Dense(14))\n",
    "Model22DenseRMSprop3.add(Dense(70, activation='relu'))\n",
    "Model22DenseRMSprop3.add(Dense(7, activation='selu'))\n",
    "Model22DenseRMSprop3.add(Dense(1, activation='linear'))\n",
    "Model22DenseRMSprop3.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseRMSprop3.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseRMSprop3.summary()\n",
    "\n",
    "DenseRMSpropPrediction3 = Model22DenseRMSprop3.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction3, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "775d5c62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1872 - MAE: 0.1872\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1103 - MAE: 0.1103\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1000 - MAE: 0.1000\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0949 - MAE: 0.0949\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0915 - MAE: 0.0915\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 735us/step - loss: 0.0878 - MAE: 0.0878\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 706us/step - loss: 0.0843 - MAE: 0.0843\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 715us/step - loss: 0.0832 - MAE: 0.0832\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 776us/step - loss: 0.0810 - MAE: 0.0810\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 871us/step - loss: 0.0797 - MAE: 0.0797\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 877us/step - loss: 0.0778 - MAE: 0.0778\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 896us/step - loss: 0.0761 - MAE: 0.0761\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.0747 - MAE: 0.0747\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0746 - MAE: 0.0746\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0732 - MAE: 0.0732\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 970us/step - loss: 0.0718 - MAE: 0.0718\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0704 - MAE: 0.0704\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0705 - MAE: 0.0705\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0700 - MAE: 0.0700\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0693 - MAE: 0.0693\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0687 - MAE: 0.0687\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0677 - MAE: 0.0677\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0672 - MAE: 0.0672\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0657 - MAE: 0.0657\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0660 - MAE: 0.0660\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0651 - MAE: 0.0651\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 966us/step - loss: 0.0662 - MAE: 0.0662\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.0654 - MAE: 0.0654\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 945us/step - loss: 0.0642 - MAE: 0.0642\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.0629 - MAE: 0.0629\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 882us/step - loss: 0.0636 - MAE: 0.0636\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 912us/step - loss: 0.0632 - MAE: 0.0632\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.0630 - MAE: 0.0630\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 726us/step - loss: 0.0627 - MAE: 0.0627\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 709us/step - loss: 0.0619 - MAE: 0.0619\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 703us/step - loss: 0.0622 - MAE: 0.0622\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 702us/step - loss: 0.0612 - MAE: 0.0612\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 1s 690us/step - loss: 0.0610 - MAE: 0.0610\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 708us/step - loss: 0.0611 - MAE: 0.0611\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 874us/step - loss: 0.0606 - MAE: 0.0606\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 870us/step - loss: 0.0620 - MAE: 0.0620\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.0603 - MAE: 0.0603\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 900us/step - loss: 0.0598 - MAE: 0.0598\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.0600 - MAE: 0.0600\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 916us/step - loss: 0.0587 - MAE: 0.0587\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 883us/step - loss: 0.0589 - MAE: 0.0589\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.0590 - MAE: 0.0590\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 891us/step - loss: 0.0591 - MAE: 0.0591\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 847us/step - loss: 0.0589 - MAE: 0.0589\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 723us/step - loss: 0.0587 - MAE: 0.0587\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 868us/step - loss: 0.0582 - MAE: 0.0582\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 884us/step - loss: 0.0577 - MAE: 0.0577\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 858us/step - loss: 0.0581 - MAE: 0.0581\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.0570 - MAE: 0.0570\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 774us/step - loss: 0.0579 - MAE: 0.0579 0s - loss: 0.0582 - MAE: 0.0\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 719us/step - loss: 0.0576 - MAE: 0.0576\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 715us/step - loss: 0.0565 - MAE: 0.0565\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.0566 - MAE: 0.0566\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 881us/step - loss: 0.0572 - MAE: 0.0572\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.0562 - MAE: 0.0562\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 886us/step - loss: 0.0568 - MAE: 0.0568\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 889us/step - loss: 0.0549 - MAE: 0.0549\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 881us/step - loss: 0.0569 - MAE: 0.0569\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 890us/step - loss: 0.0561 - MAE: 0.0561\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 926us/step - loss: 0.0556 - MAE: 0.0556\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 902us/step - loss: 0.0559 - MAE: 0.0559\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.0557 - MAE: 0.0557\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_184 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.056656353716939556\n"
     ]
    }
   ],
   "source": [
    "Model22DenseRMSprop4 = Sequential()\n",
    "Model22DenseRMSprop4.add(Dense(14))\n",
    "Model22DenseRMSprop4.add(Dense(70, activation='relu'))\n",
    "Model22DenseRMSprop4.add(Dense(7, activation='elu'))\n",
    "Model22DenseRMSprop4.add(Dense(1, activation='linear'))\n",
    "Model22DenseRMSprop4.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseRMSprop4.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseRMSprop4.summary()\n",
    "\n",
    "DenseRMSpropPrediction4 = Model22DenseRMSprop4.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction4, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e5110a69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 914us/step - loss: 0.1919 - MAE: 0.1919\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 886us/step - loss: 0.1165 - MAE: 0.1165\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.1050 - MAE: 0.1050\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 856us/step - loss: 0.0985 - MAE: 0.0985\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 880us/step - loss: 0.0930 - MAE: 0.0930\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 882us/step - loss: 0.0895 - MAE: 0.0895\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 927us/step - loss: 0.0864 - MAE: 0.0864\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 884us/step - loss: 0.0830 - MAE: 0.0830\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 882us/step - loss: 0.0823 - MAE: 0.0823\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 876us/step - loss: 0.0803 - MAE: 0.0803\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 870us/step - loss: 0.0792 - MAE: 0.0792\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 890us/step - loss: 0.0775 - MAE: 0.0775\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.0761 - MAE: 0.0761\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 848us/step - loss: 0.0758 - MAE: 0.0758\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.0739 - MAE: 0.0739\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.0737 - MAE: 0.0737\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 726us/step - loss: 0.0724 - MAE: 0.0724\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 714us/step - loss: 0.0707 - MAE: 0.0707\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 708us/step - loss: 0.0711 - MAE: 0.0711\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 731us/step - loss: 0.0701 - MAE: 0.0701\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 1s 692us/step - loss: 0.0680 - MAE: 0.0680\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 707us/step - loss: 0.0683 - MAE: 0.0683\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 696us/step - loss: 0.0676 - MAE: 0.0676\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 711us/step - loss: 0.0653 - MAE: 0.0653\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 730us/step - loss: 0.0649 - MAE: 0.0649\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 738us/step - loss: 0.0655 - MAE: 0.0655\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 702us/step - loss: 0.0631 - MAE: 0.0631\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 708us/step - loss: 0.0632 - MAE: 0.0632\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 705us/step - loss: 0.0623 - MAE: 0.0623\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 722us/step - loss: 0.0622 - MAE: 0.0622\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 704us/step - loss: 0.0616 - MAE: 0.0616\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 716us/step - loss: 0.0613 - MAE: 0.0613 0s - loss: 0.0621 - MAE: 0.\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 740us/step - loss: 0.0612 - MAE: 0.0612\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 787us/step - loss: 0.0600 - MAE: 0.0600\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 695us/step - loss: 0.0605 - MAE: 0.0605\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 721us/step - loss: 0.0601 - MAE: 0.0601\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 701us/step - loss: 0.0577 - MAE: 0.0577\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 694us/step - loss: 0.0589 - MAE: 0.0589\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 700us/step - loss: 0.0580 - MAE: 0.0580\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 1s 692us/step - loss: 0.0591 - MAE: 0.0591\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 728us/step - loss: 0.0586 - MAE: 0.0586\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.0576 - MAE: 0.0576\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 881us/step - loss: 0.0577 - MAE: 0.0577\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 867us/step - loss: 0.0564 - MAE: 0.0564\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 824us/step - loss: 0.0568 - MAE: 0.0568\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 779us/step - loss: 0.0555 - MAE: 0.0555\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 696us/step - loss: 0.0556 - MAE: 0.0556\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 734us/step - loss: 0.0561 - MAE: 0.0561 0s - loss: 0.0\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 696us/step - loss: 0.0550 - MAE: 0.0550\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 727us/step - loss: 0.0555 - MAE: 0.0555\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 698us/step - loss: 0.0541 - MAE: 0.0541\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 728us/step - loss: 0.0549 - MAE: 0.0549\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 697us/step - loss: 0.0546 - MAE: 0.0546\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 1s 681us/step - loss: 0.0544 - MAE: 0.0544\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 699us/step - loss: 0.0537 - MAE: 0.0537\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 1s 684us/step - loss: 0.0550 - MAE: 0.0550\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 711us/step - loss: 0.0536 - MAE: 0.0536\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 1s 681us/step - loss: 0.0535 - MAE: 0.0535\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 708us/step - loss: 0.0530 - MAE: 0.0530\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 717us/step - loss: 0.0537 - MAE: 0.0537\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 695us/step - loss: 0.0528 - MAE: 0.0528\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 1s 690us/step - loss: 0.0531 - MAE: 0.0531\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 758us/step - loss: 0.0536 - MAE: 0.0536\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 762us/step - loss: 0.0509 - MAE: 0.0509\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 748us/step - loss: 0.0526 - MAE: 0.0526\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 730us/step - loss: 0.0511 - MAE: 0.0511\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 702us/step - loss: 0.0520 - MAE: 0.0520\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 705us/step - loss: 0.0521 - MAE: 0.0521\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 721us/step - loss: 0.0522 - MAE: 0.0522\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_188 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.04599401392697639\n"
     ]
    }
   ],
   "source": [
    "Model22DenseRMSprop5 = Sequential()\n",
    "Model22DenseRMSprop5.add(Dense(14))\n",
    "Model22DenseRMSprop5.add(Dense(70, activation='relu'))\n",
    "Model22DenseRMSprop5.add(Dense(7, activation='elu'))\n",
    "Model22DenseRMSprop5.add(Dense(1, activation='linear'))\n",
    "Model22DenseRMSprop5.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseRMSprop5.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseRMSprop5.summary()\n",
    "\n",
    "DenseRMSpropPrediction5 = Model22DenseRMSprop5.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction5, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3c898657",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 3s 846us/step - loss: 0.1801 - MAE: 0.1801\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 854us/step - loss: 0.1235 - MAE: 0.1235\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.1127 - MAE: 0.1127\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 758us/step - loss: 0.1046 - MAE: 0.1046\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 723us/step - loss: 0.1004 - MAE: 0.1004\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 706us/step - loss: 0.0978 - MAE: 0.0978\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 713us/step - loss: 0.0953 - MAE: 0.0953\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 696us/step - loss: 0.0932 - MAE: 0.0932\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 717us/step - loss: 0.0919 - MAE: 0.0919\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 701us/step - loss: 0.0898 - MAE: 0.0898\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 715us/step - loss: 0.0884 - MAE: 0.0884\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 787us/step - loss: 0.0878 - MAE: 0.0878\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 729us/step - loss: 0.0874 - MAE: 0.0874\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 725us/step - loss: 0.0860 - MAE: 0.0860\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 734us/step - loss: 0.0851 - MAE: 0.0851\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 735us/step - loss: 0.0854 - MAE: 0.0854\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 709us/step - loss: 0.0842 - MAE: 0.0842\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 720us/step - loss: 0.0823 - MAE: 0.0823\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 733us/step - loss: 0.0825 - MAE: 0.0825\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 720us/step - loss: 0.0827 - MAE: 0.0827\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 714us/step - loss: 0.0824 - MAE: 0.0824\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 718us/step - loss: 0.0819 - MAE: 0.0819\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 708us/step - loss: 0.0805 - MAE: 0.0805\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 700us/step - loss: 0.0805 - MAE: 0.0805\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 726us/step - loss: 0.0802 - MAE: 0.0802\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 725us/step - loss: 0.0807 - MAE: 0.0807\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 713us/step - loss: 0.0803 - MAE: 0.0803\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 723us/step - loss: 0.0799 - MAE: 0.0799\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 739us/step - loss: 0.0796 - MAE: 0.0796\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 728us/step - loss: 0.0792 - MAE: 0.0792\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 723us/step - loss: 0.0798 - MAE: 0.0798\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 744us/step - loss: 0.0791 - MAE: 0.0791\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 720us/step - loss: 0.0785 - MAE: 0.0785\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 726us/step - loss: 0.0792 - MAE: 0.0792\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 726us/step - loss: 0.0787 - MAE: 0.0787\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 1s 694us/step - loss: 0.0774 - MAE: 0.0774\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 740us/step - loss: 0.0785 - MAE: 0.0785\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 733us/step - loss: 0.0779 - MAE: 0.0779\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 754us/step - loss: 0.0771 - MAE: 0.0771\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 747us/step - loss: 0.0783 - MAE: 0.0783\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 725us/step - loss: 0.0785 - MAE: 0.0785\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 1s 692us/step - loss: 0.0776 - MAE: 0.0776\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 716us/step - loss: 0.0775 - MAE: 0.0775\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 738us/step - loss: 0.0773 - MAE: 0.0773\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_192 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.06715962203427209\n"
     ]
    }
   ],
   "source": [
    "Model22DenseRMSprop6 = Sequential()\n",
    "Model22DenseRMSprop6.add(Dense(14))\n",
    "Model22DenseRMSprop6.add(Dense(70))\n",
    "Model22DenseRMSprop6.add(Dense(7, activation='relu'))\n",
    "Model22DenseRMSprop6.add(Dense(1, activation='linear'))\n",
    "Model22DenseRMSprop6.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseRMSprop6.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseRMSprop6.summary()\n",
    "\n",
    "DenseRMSpropPrediction6 = Model22DenseRMSprop6.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction6, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "58557089",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 789us/step - loss: 0.2965 - MAE: 0.2965\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 787us/step - loss: 0.1719 - MAE: 0.1719\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 774us/step - loss: 0.1423 - MAE: 0.1423\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 785us/step - loss: 0.1291 - MAE: 0.1291\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 769us/step - loss: 0.1235 - MAE: 0.1235\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 743us/step - loss: 0.1151 - MAE: 0.1151\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 770us/step - loss: 0.1142 - MAE: 0.1142\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 751us/step - loss: 0.1078 - MAE: 0.1078\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 768us/step - loss: 0.1077 - MAE: 0.1077\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 727us/step - loss: 0.1064 - MAE: 0.1064\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 706us/step - loss: 0.1058 - MAE: 0.1058\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 734us/step - loss: 0.1045 - MAE: 0.1045\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 725us/step - loss: 0.1021 - MAE: 0.1021\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 737us/step - loss: 0.1034 - MAE: 0.1034\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 753us/step - loss: 0.1034 - MAE: 0.1034\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 736us/step - loss: 0.1035 - MAE: 0.1035\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 726us/step - loss: 0.0997 - MAE: 0.0997\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 741us/step - loss: 0.1009 - MAE: 0.1009\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 726us/step - loss: 0.1020 - MAE: 0.1020\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 725us/step - loss: 0.1024 - MAE: 0.1024\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 757us/step - loss: 0.0993 - MAE: 0.0993\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 727us/step - loss: 0.0996 - MAE: 0.0996\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 751us/step - loss: 0.1007 - MAE: 0.1007\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 740us/step - loss: 0.1011 - MAE: 0.1011\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 708us/step - loss: 0.0993 - MAE: 0.0993\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 715us/step - loss: 0.0972 - MAE: 0.0972\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 740us/step - loss: 0.1000 - MAE: 0.1000\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 720us/step - loss: 0.0980 - MAE: 0.0980\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.0978 - MAE: 0.0978 1s - loss\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 754us/step - loss: 0.0988 - MAE: 0.0988 0s - loss: 0.1006 - \n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 806us/step - loss: 0.0990 - MAE: 0.0990\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_196 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (1, 14)                   0         \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (1, 70)                   0         \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.07856506080123266\n"
     ]
    }
   ],
   "source": [
    "Model22DenseRMSprop6_1 = Sequential()\n",
    "Model22DenseRMSprop6_1.add(Dense(14))\n",
    "Model22DenseRMSprop6_1.add(Dropout(0.1))\n",
    "Model22DenseRMSprop6_1.add(Dense(70))\n",
    "Model22DenseRMSprop6_1.add(Dropout(0.1))\n",
    "Model22DenseRMSprop6_1.add(Dense(7, activation='relu'))\n",
    "Model22DenseRMSprop6_1.add(Dense(1, activation='linear'))\n",
    "Model22DenseRMSprop6_1.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseRMSprop6_1.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseRMSprop6_1.summary()\n",
    "\n",
    "DenseRMSpropPrediction6_1 = Model22DenseRMSprop6_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction6_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a9eeec3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 3s 966us/step - loss: 0.1945 - MAE: 0.1945\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.1037 - MAE: 0.1037\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 865us/step - loss: 0.0969 - MAE: 0.0969\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.0918 - MAE: 0.0918\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 934us/step - loss: 0.0888 - MAE: 0.0888\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0856 - MAE: 0.0856\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 938us/step - loss: 0.0826 - MAE: 0.0826\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0805 - MAE: 0.0805\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.0776 - MAE: 0.0776\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.0758 - MAE: 0.0758\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 955us/step - loss: 0.0748 - MAE: 0.0748\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.0726 - MAE: 0.0726\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.0733 - MAE: 0.0733\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 0.0711 - MAE: 0.0711\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 800us/step - loss: 0.0701 - MAE: 0.0701\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 774us/step - loss: 0.0670 - MAE: 0.0670\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 770us/step - loss: 0.0686 - MAE: 0.0686\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.0658 - MAE: 0.0658\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 780us/step - loss: 0.0647 - MAE: 0.0647\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 762us/step - loss: 0.0654 - MAE: 0.0654\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 809us/step - loss: 0.0629 - MAE: 0.0629\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.0626 - MAE: 0.0626\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 801us/step - loss: 0.0612 - MAE: 0.0612\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.0603 - MAE: 0.0603\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.0603 - MAE: 0.0603 0s - loss: 0.0607 - MAE: 0\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 0.0594 - MAE: 0.0594 0s - loss: 0.0\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0589 - MAE: 0.0589\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.0571 - MAE: 0.0571\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 874us/step - loss: 0.0563 - MAE: 0.0563\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 870us/step - loss: 0.0557 - MAE: 0.0557\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 895us/step - loss: 0.0546 - MAE: 0.0546\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.0546 - MAE: 0.0546\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0524 - MAE: 0.0524\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 901us/step - loss: 0.0535 - MAE: 0.0535\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 895us/step - loss: 0.0519 - MAE: 0.0519\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.0526 - MAE: 0.0526\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 878us/step - loss: 0.0505 - MAE: 0.0505\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.0507 - MAE: 0.0507\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.0492 - MAE: 0.0492\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 929us/step - loss: 0.0501 - MAE: 0.0501\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 831us/step - loss: 0.0494 - MAE: 0.0494\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 899us/step - loss: 0.0483 - MAE: 0.0483\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.0478 - MAE: 0.0478\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 896us/step - loss: 0.0479 - MAE: 0.0479\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 896us/step - loss: 0.0481 - MAE: 0.0481\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 901us/step - loss: 0.0469 - MAE: 0.0469\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.0459 - MAE: 0.0459\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 899us/step - loss: 0.0454 - MAE: 0.0454\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 903us/step - loss: 0.0439 - MAE: 0.0439\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 902us/step - loss: 0.0452 - MAE: 0.0452\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 907us/step - loss: 0.0454 - MAE: 0.0454\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 901us/step - loss: 0.0449 - MAE: 0.0449\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 902us/step - loss: 0.0452 - MAE: 0.0452\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 899us/step - loss: 0.0442 - MAE: 0.0442\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_200 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (1, 192)                  2880      \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (1, 24)                   4632      \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (1, 9)                    225       \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (1, 1)                    10        \n",
      "=================================================================\n",
      "Total params: 7,915\n",
      "Trainable params: 7,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.036692643120285674\n"
     ]
    }
   ],
   "source": [
    "Model22DenseRMSprop7 = Sequential()\n",
    "Model22DenseRMSprop7.add(Dense(14))\n",
    "Model22DenseRMSprop7.add(Dense(192, activation='relu'))\n",
    "Model22DenseRMSprop7.add(Dense(24, activation='relu'))\n",
    "Model22DenseRMSprop7.add(Dense(9, activation='relu'))\n",
    "Model22DenseRMSprop7.add(Dense(1, activation='linear'))\n",
    "Model22DenseRMSprop7.compile(optimizer='RMSprop', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseRMSprop7.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseRMSprop7.summary()\n",
    "\n",
    "DenseRMSpropPrediction7 = Model22DenseRMSprop7.predict(x_test)\n",
    "score = mean_absolute_error(DenseRMSpropPrediction7, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b8065",
   "metadata": {},
   "source": [
    "## Dense Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "40804976",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.2559 - MAE: 0.2559\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 837us/step - loss: 0.1002 - MAE: 0.1002\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 796us/step - loss: 0.0899 - MAE: 0.0899\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.0841 - MAE: 0.0841\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.0825 - MAE: 0.0825\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 819us/step - loss: 0.0817 - MAE: 0.0817\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 821us/step - loss: 0.0802 - MAE: 0.0802\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.0779 - MAE: 0.0779\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 822us/step - loss: 0.0759 - MAE: 0.0759\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.0742 - MAE: 0.0742\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 835us/step - loss: 0.0735 - MAE: 0.0735\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 868us/step - loss: 0.0692 - MAE: 0.0692\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 866us/step - loss: 0.0711 - MAE: 0.0711\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 872us/step - loss: 0.0729 - MAE: 0.0729\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.0694 - MAE: 0.0694\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 778us/step - loss: 0.0675 - MAE: 0.0675\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 780us/step - loss: 0.0687 - MAE: 0.0687\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.0677 - MAE: 0.0677\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 783us/step - loss: 0.0663 - MAE: 0.0663\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 784us/step - loss: 0.0643 - MAE: 0.0643\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 758us/step - loss: 0.0628 - MAE: 0.0628\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 773us/step - loss: 0.0628 - MAE: 0.0628\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.0603 - MAE: 0.0603\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 771us/step - loss: 0.0614 - MAE: 0.0614\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 797us/step - loss: 0.0604 - MAE: 0.0604\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 775us/step - loss: 0.0591 - MAE: 0.0591\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 827us/step - loss: 0.0583 - MAE: 0.0583\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 817us/step - loss: 0.0579 - MAE: 0.0579\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 774us/step - loss: 0.0575 - MAE: 0.0575\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 778us/step - loss: 0.0558 - MAE: 0.0558\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 785us/step - loss: 0.0560 - MAE: 0.0560\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 783us/step - loss: 0.0557 - MAE: 0.0557\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 777us/step - loss: 0.0553 - MAE: 0.0553\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 771us/step - loss: 0.0559 - MAE: 0.0559\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 785us/step - loss: 0.0529 - MAE: 0.0529\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 790us/step - loss: 0.0546 - MAE: 0.0546\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 840us/step - loss: 0.0510 - MAE: 0.0510\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 881us/step - loss: 0.0526 - MAE: 0.0526\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 842us/step - loss: 0.0525 - MAE: 0.0525\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.0510 - MAE: 0.0510\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.0501 - MAE: 0.0501\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 780us/step - loss: 0.0502 - MAE: 0.0502\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 780us/step - loss: 0.0492 - MAE: 0.0492\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.0487 - MAE: 0.0487\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 803us/step - loss: 0.0491 - MAE: 0.0491\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.0476 - MAE: 0.0476\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 835us/step - loss: 0.0474 - MAE: 0.0474\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.0498 - MAE: 0.0498\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 809us/step - loss: 0.0482 - MAE: 0.0482\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 795us/step - loss: 0.0480 - MAE: 0.0480\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.0469 - MAE: 0.0469\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 778us/step - loss: 0.0471 - MAE: 0.0471\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 753us/step - loss: 0.0453 - MAE: 0.0453\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 776us/step - loss: 0.0464 - MAE: 0.0464\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 790us/step - loss: 0.0455 - MAE: 0.0455 1s\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 778us/step - loss: 0.0442 - MAE: 0.0442\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 811us/step - loss: 0.0443 - MAE: 0.0443\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 771us/step - loss: 0.0450 - MAE: 0.0450\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 783us/step - loss: 0.0443 - MAE: 0.0443\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0438 - MAE: 0.0438\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 886us/step - loss: 0.0444 - MAE: 0.0444\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 842us/step - loss: 0.0444 - MAE: 0.0444\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 976us/step - loss: 0.0450 - MAE: 0.0450\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0425 - MAE: 0.0425\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 955us/step - loss: 0.0437 - MAE: 0.0437\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0409 - MAE: 0.0409\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0429 - MAE: 0.0429\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 897us/step - loss: 0.0425 - MAE: 0.0425\n",
      "Epoch 69/100\n",
      "2160/2160 [==============================] - 2s 968us/step - loss: 0.0420 - MAE: 0.0420\n",
      "Epoch 70/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0418 - MAE: 0.0418\n",
      "Epoch 71/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0413 - MAE: 0.0413\n",
      "Test score: 0.04493942445726938\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Model22DenseAdam1 = Sequential()\n",
    "Model22DenseAdam1.add(Dense(14))\n",
    "Model22DenseAdam1.add(Dense(70, activation='relu'))\n",
    "Model22DenseAdam1.add(Dense(7, activation='relu'))\n",
    "Model22DenseAdam1.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdam1.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdam1.fit(x_train.values, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseAdamPrediction1 = Model22DenseAdam1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9e0b8328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.2472 - MAE: 0.2472\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 802us/step - loss: 0.1384 - MAE: 0.1384\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 815us/step - loss: 0.1269 - MAE: 0.1269\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 875us/step - loss: 0.1176 - MAE: 0.1176\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.1104 - MAE: 0.1104\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.1086 - MAE: 0.1086\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 853us/step - loss: 0.1038 - MAE: 0.1038\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.0989 - MAE: 0.0989\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 799us/step - loss: 0.0999 - MAE: 0.0999\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 812us/step - loss: 0.0985 - MAE: 0.0985\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0945 - MAE: 0.0945\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 864us/step - loss: 0.0959 - MAE: 0.0959\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 823us/step - loss: 0.0962 - MAE: 0.0962\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0935 - MAE: 0.0935\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 999us/step - loss: 0.0929 - MAE: 0.0929\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0924 - MAE: 0.0924\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 988us/step - loss: 0.0902 - MAE: 0.0902\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0889 - MAE: 0.0889\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 987us/step - loss: 0.0917 - MAE: 0.0917\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0890 - MAE: 0.0890\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 961us/step - loss: 0.0905 - MAE: 0.0905\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0892 - MAE: 0.0892\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 826us/step - loss: 0.0847 - MAE: 0.0847\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.0883 - MAE: 0.0883\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.0881 - MAE: 0.0881\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0857 - MAE: 0.0857\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 877us/step - loss: 0.0848 - MAE: 0.0848\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0847 - MAE: 0.0847\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0840 - MAE: 0.0840\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0831 - MAE: 0.0831\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0843 - MAE: 0.0843\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0849 - MAE: 0.0849\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0854 - MAE: 0.0854\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 960us/step - loss: 0.0846 - MAE: 0.0846\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.0839 - MAE: 0.0839\n",
      "Test score: 0.0637433020691469\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Model22DenseAdam1_1 = Sequential()\n",
    "Model22DenseAdam1_1.add(Dense(14))\n",
    "Model22DenseAdam1_1.add(Dropout(0.1))\n",
    "Model22DenseAdam1_1.add(Dense(70, activation='relu'))\n",
    "Model22DenseAdam1_1.add(Dropout(0.1))\n",
    "Model22DenseAdam1_1.add(Dense(7, activation='relu'))\n",
    "Model22DenseAdam1_1.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdam1_1.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdam1_1.fit(x_train.values, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "DenseAdamPrediction1_1 = Model22DenseAdam1_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction1_1, y_test)\n",
    "print('Test score:', score)\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "df3594fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.2156 - MAE: 0.2156\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 970us/step - loss: 0.1043 - MAE: 0.1043\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0965 - MAE: 0.0965\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0915 - MAE: 0.0915\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 881us/step - loss: 0.0871 - MAE: 0.0871\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 842us/step - loss: 0.0828 - MAE: 0.0828\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 847us/step - loss: 0.0825 - MAE: 0.0825\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 911us/step - loss: 0.0820 - MAE: 0.0820\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 865us/step - loss: 0.0796 - MAE: 0.0796\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 989us/step - loss: 0.0781 - MAE: 0.0781\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 943us/step - loss: 0.0771 - MAE: 0.0771\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0744 - MAE: 0.0744\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.0732 - MAE: 0.0732 1s - los\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 908us/step - loss: 0.0727 - MAE: 0.0727\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 901us/step - loss: 0.0707 - MAE: 0.0707\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 899us/step - loss: 0.0723 - MAE: 0.0723\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0708 - MAE: 0.0708\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 885us/step - loss: 0.0700 - MAE: 0.0700\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0691 - MAE: 0.0691\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 862us/step - loss: 0.0695 - MAE: 0.0695\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 859us/step - loss: 0.0674 - MAE: 0.0674\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0660 - MAE: 0.0660\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 997us/step - loss: 0.0675 - MAE: 0.0675\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0646 - MAE: 0.0646\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0679 - MAE: 0.0679\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0651 - MAE: 0.0651\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 914us/step - loss: 0.0639 - MAE: 0.0639\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 973us/step - loss: 0.0629 - MAE: 0.0629\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.0631 - MAE: 0.0631\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0629 - MAE: 0.0629\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0621 - MAE: 0.0621\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0608 - MAE: 0.0608\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0618 - MAE: 0.0618\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0614 - MAE: 0.0614\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 954us/step - loss: 0.0604 - MAE: 0.0604\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 967us/step - loss: 0.0598 - MAE: 0.0598\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0586 - MAE: 0.0586\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 879us/step - loss: 0.0589 - MAE: 0.0589\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0581 - MAE: 0.0581\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.0575 - MAE: 0.0575\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0562 - MAE: 0.0562\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0563 - MAE: 0.0563\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 998us/step - loss: 0.0580 - MAE: 0.0580\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 938us/step - loss: 0.0568 - MAE: 0.0568\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 965us/step - loss: 0.0549 - MAE: 0.0549\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 908us/step - loss: 0.0559 - MAE: 0.0559\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 867us/step - loss: 0.0550 - MAE: 0.0550\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 870us/step - loss: 0.0543 - MAE: 0.0543\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0545 - MAE: 0.0545\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 927us/step - loss: 0.0534 - MAE: 0.0534\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0533 - MAE: 0.0533\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 873us/step - loss: 0.0545 - MAE: 0.0545\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0529 - MAE: 0.0529\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0517 - MAE: 0.0517\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0534 - MAE: 0.0534\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0515 - MAE: 0.0515\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0521 - MAE: 0.0521\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 944us/step - loss: 0.0519 - MAE: 0.0519\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0516 - MAE: 0.0516\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0489 - MAE: 0.0489\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.0523 - MAE: 0.0523\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 828us/step - loss: 0.0495 - MAE: 0.0495\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 995us/step - loss: 0.0492 - MAE: 0.0492\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 872us/step - loss: 0.0502 - MAE: 0.0502\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0494 - MAE: 0.0494\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_213 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.04723295995814457\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdam2 = Sequential()\n",
    "Model22DenseAdam2.add(Dense(14))\n",
    "Model22DenseAdam2.add(Dense(70, activation='relu'))\n",
    "Model22DenseAdam2.add(Dense(7, activation='elu'))\n",
    "Model22DenseAdam2.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdam2.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdam2.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdam2.summary()\n",
    "\n",
    "DenseAdamPrediction2 = Model22DenseAdam2.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction2, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2db0eec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 980us/step - loss: 0.2630 - MAE: 0.2630\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1574 - MAE: 0.1574\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 954us/step - loss: 0.1390 - MAE: 0.1390\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.1227 - MAE: 0.1227\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 957us/step - loss: 0.1148 - MAE: 0.1148\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1081 - MAE: 0.1081\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1024 - MAE: 0.1024\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1003 - MAE: 0.1003\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0991 - MAE: 0.0991\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 948us/step - loss: 0.1009 - MAE: 0.1009\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.0982 - MAE: 0.0982\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0980 - MAE: 0.0980\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 883us/step - loss: 0.0940 - MAE: 0.0940\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.0935 - MAE: 0.0935\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0917 - MAE: 0.0917\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0920 - MAE: 0.0920\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 936us/step - loss: 0.0870 - MAE: 0.0870\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 841us/step - loss: 0.0893 - MAE: 0.0893\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 896us/step - loss: 0.0892 - MAE: 0.0892\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 841us/step - loss: 0.0896 - MAE: 0.0896\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 938us/step - loss: 0.0857 - MAE: 0.0857\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0857 - MAE: 0.0857\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0867 - MAE: 0.0867\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0866 - MAE: 0.0866\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0830 - MAE: 0.0830\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 987us/step - loss: 0.0865 - MAE: 0.0865\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0831 - MAE: 0.0831\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.0846 - MAE: 0.0846\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 872us/step - loss: 0.0812 - MAE: 0.0812\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 926us/step - loss: 0.0833 - MAE: 0.0833\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0803 - MAE: 0.0803\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0809 - MAE: 0.0809\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 912us/step - loss: 0.0799 - MAE: 0.0799\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 903us/step - loss: 0.0813 - MAE: 0.0813\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0795 - MAE: 0.0795\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 863us/step - loss: 0.0834 - MAE: 0.0834\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 847us/step - loss: 0.0772 - MAE: 0.0772\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0809 - MAE: 0.0809\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 804us/step - loss: 0.0803 - MAE: 0.0803\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 868us/step - loss: 0.0821 - MAE: 0.0821\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 942us/step - loss: 0.0779 - MAE: 0.0779\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0777 - MAE: 0.0777\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_217 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (1, 14)                   0         \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (1, 70)                   0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.07224405098841402\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdam2_1 = Sequential()\n",
    "Model22DenseAdam2_1.add(Dense(14))\n",
    "Model22DenseAdam2_1.add(Dropout(0.1))\n",
    "Model22DenseAdam2_1.add(Dense(70, activation='relu'))\n",
    "Model22DenseAdam2_1.add(Dropout(0.1))\n",
    "Model22DenseAdam2_1.add(Dense(7, activation='elu'))\n",
    "Model22DenseAdam2_1.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdam2_1.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdam2_1.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdam2_1.summary()\n",
    "\n",
    "DenseAdamPrediction2_1 = Model22DenseAdam2_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction2_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9ed71b15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1954 - MAE: 0.1954\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 999us/step - loss: 0.1082 - MAE: 0.1082\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 992us/step - loss: 0.0982 - MAE: 0.0982\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 951us/step - loss: 0.0904 - MAE: 0.0904\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 944us/step - loss: 0.0894 - MAE: 0.0894\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 818us/step - loss: 0.0856 - MAE: 0.0856\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 794us/step - loss: 0.0828 - MAE: 0.0828\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 903us/step - loss: 0.0787 - MAE: 0.0787\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0783 - MAE: 0.0783\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 792us/step - loss: 0.0774 - MAE: 0.0774\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 788us/step - loss: 0.0768 - MAE: 0.0768\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 814us/step - loss: 0.0750 - MAE: 0.0750\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 879us/step - loss: 0.0738 - MAE: 0.0738\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 970us/step - loss: 0.0738 - MAE: 0.0738\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.0726 - MAE: 0.0726\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.0718 - MAE: 0.0718\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 808us/step - loss: 0.0721 - MAE: 0.0721\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 834us/step - loss: 0.0702 - MAE: 0.0702\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.0704 - MAE: 0.0704\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 864us/step - loss: 0.0689 - MAE: 0.0689\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 919us/step - loss: 0.0691 - MAE: 0.0691\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 939us/step - loss: 0.0680 - MAE: 0.0680\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0685 - MAE: 0.0685\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0661 - MAE: 0.0661\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 4s 2ms/step - loss: 0.0678 - MAE: 0.0678\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 4s 2ms/step - loss: 0.0663 - MAE: 0.0663\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 4s 2ms/step - loss: 0.0671 - MAE: 0.0671\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 3s 2ms/step - loss: 0.0649 - MAE: 0.0649\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 3s 2ms/step - loss: 0.0648 - MAE: 0.0648\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0654 - MAE: 0.0654\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0627 - MAE: 0.0627\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 919us/step - loss: 0.0635 - MAE: 0.0635\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 863us/step - loss: 0.0615 - MAE: 0.0615\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 880us/step - loss: 0.0616 - MAE: 0.0616\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 972us/step - loss: 0.0621 - MAE: 0.0621\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.0607 - MAE: 0.0607\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.0618 - MAE: 0.0618\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0603 - MAE: 0.0603\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0597 - MAE: 0.0597\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0585 - MAE: 0.0585\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0597 - MAE: 0.0597\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 863us/step - loss: 0.0601 - MAE: 0.0601\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 993us/step - loss: 0.0583 - MAE: 0.0583\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0584 - MAE: 0.0584\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 985us/step - loss: 0.0586 - MAE: 0.0586\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0551 - MAE: 0.0551\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0564 - MAE: 0.0564\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.0560 - MAE: 0.0560\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0565 - MAE: 0.0565\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0565 - MAE: 0.0565\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0563 - MAE: 0.0563\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_221 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.05108442051235161\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdam3 = Sequential()\n",
    "Model22DenseAdam3.add(Dense(14))\n",
    "Model22DenseAdam3.add(Dense(70, activation='relu'))\n",
    "Model22DenseAdam3.add(Dense(7, activation='selu'))\n",
    "Model22DenseAdam3.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdam3.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdam3.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdam3.summary()\n",
    "\n",
    "DenseAdamPrediction3 = Model22DenseAdam3.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction3, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2ea0a2ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1824 - MAE: 0.1824\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.1060 - MAE: 0.1060\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 825us/step - loss: 0.0957 - MAE: 0.0957\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0938 - MAE: 0.0938\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 981us/step - loss: 0.0913 - MAE: 0.0913\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 971us/step - loss: 0.0869 - MAE: 0.0869\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 948us/step - loss: 0.0865 - MAE: 0.0865\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 991us/step - loss: 0.0825 - MAE: 0.0825\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 994us/step - loss: 0.0826 - MAE: 0.0826\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0785 - MAE: 0.0785\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 976us/step - loss: 0.0784 - MAE: 0.0784\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 852us/step - loss: 0.0762 - MAE: 0.0762\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 813us/step - loss: 0.0773 - MAE: 0.0773\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0758 - MAE: 0.0758\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 820us/step - loss: 0.0733 - MAE: 0.0733\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.0729 - MAE: 0.0729\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 908us/step - loss: 0.0731 - MAE: 0.0731\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 927us/step - loss: 0.0699 - MAE: 0.0699\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 901us/step - loss: 0.0688 - MAE: 0.0688 1s -\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.0670 - MAE: 0.0670\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 956us/step - loss: 0.0675 - MAE: 0.0675\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 989us/step - loss: 0.0658 - MAE: 0.0658\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0631 - MAE: 0.0631\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0626 - MAE: 0.0626\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0616 - MAE: 0.0616\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0625 - MAE: 0.0625\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 950us/step - loss: 0.0589 - MAE: 0.0589\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 897us/step - loss: 0.0600 - MAE: 0.0600\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 899us/step - loss: 0.0600 - MAE: 0.0600\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 855us/step - loss: 0.0585 - MAE: 0.0585\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 900us/step - loss: 0.0563 - MAE: 0.0563\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0584 - MAE: 0.0584\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 921us/step - loss: 0.0543 - MAE: 0.0543\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 964us/step - loss: 0.0539 - MAE: 0.0539\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 847us/step - loss: 0.0550 - MAE: 0.0550\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 789us/step - loss: 0.0544 - MAE: 0.0544\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 836us/step - loss: 0.0520 - MAE: 0.0520\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 881us/step - loss: 0.0514 - MAE: 0.0514\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 857us/step - loss: 0.0502 - MAE: 0.0502\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0507 - MAE: 0.0507\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 866us/step - loss: 0.0503 - MAE: 0.0503\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0474 - MAE: 0.0474\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 878us/step - loss: 0.0476 - MAE: 0.0476\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.0470 - MAE: 0.0470\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 938us/step - loss: 0.0476 - MAE: 0.0476\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 968us/step - loss: 0.0471 - MAE: 0.0471\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 987us/step - loss: 0.0458 - MAE: 0.0458\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 879us/step - loss: 0.0459 - MAE: 0.0459\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.0454 - MAE: 0.0454\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 949us/step - loss: 0.0446 - MAE: 0.0446\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 838us/step - loss: 0.0435 - MAE: 0.0435\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 896us/step - loss: 0.0423 - MAE: 0.0423\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 2s 885us/step - loss: 0.0404 - MAE: 0.0404\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 871us/step - loss: 0.0416 - MAE: 0.0416\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 891us/step - loss: 0.0415 - MAE: 0.0415\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0409 - MAE: 0.0409\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 983us/step - loss: 0.0395 - MAE: 0.0395\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 2s 986us/step - loss: 0.0385 - MAE: 0.0385\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 980us/step - loss: 0.0378 - MAE: 0.0378\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 946us/step - loss: 0.0399 - MAE: 0.0399\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 940us/step - loss: 0.0381 - MAE: 0.0381\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 958us/step - loss: 0.0380 - MAE: 0.0380\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 2s 909us/step - loss: 0.0354 - MAE: 0.0354\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0372 - MAE: 0.0372\n",
      "Epoch 65/100\n",
      "2160/2160 [==============================] - 2s 961us/step - loss: 0.0360 - MAE: 0.0360\n",
      "Epoch 66/100\n",
      "2160/2160 [==============================] - 2s 956us/step - loss: 0.0358 - MAE: 0.0358\n",
      "Epoch 67/100\n",
      "2160/2160 [==============================] - 2s 912us/step - loss: 0.0358 - MAE: 0.0358\n",
      "Epoch 68/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0359 - MAE: 0.0359\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_225 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.02718000548659245\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdam4 = Sequential()\n",
    "Model22DenseAdam4.add(Dense(14))\n",
    "Model22DenseAdam4.add(Dense(70, activation='relu'))\n",
    "Model22DenseAdam4.add(Dense(7, activation='elu'))\n",
    "Model22DenseAdam4.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdam4.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdam4.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdam4.summary()\n",
    "\n",
    "DenseAdamPrediction4 = Model22DenseAdam4.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction4, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "862fb7d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.2140 - MAE: 0.2140\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.1012 - MAE: 0.1012\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 860us/step - loss: 0.0943 - MAE: 0.0943\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 915us/step - loss: 0.0885 - MAE: 0.0885\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.0863 - MAE: 0.0863\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 998us/step - loss: 0.0829 - MAE: 0.0829\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 883us/step - loss: 0.0825 - MAE: 0.0825\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 879us/step - loss: 0.0790 - MAE: 0.0790\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 991us/step - loss: 0.0794 - MAE: 0.0794\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 989us/step - loss: 0.0755 - MAE: 0.0755\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 964us/step - loss: 0.0761 - MAE: 0.0761\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0744 - MAE: 0.0744\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 944us/step - loss: 0.0728 - MAE: 0.0728\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 896us/step - loss: 0.0705 - MAE: 0.0705\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 989us/step - loss: 0.0676 - MAE: 0.0676\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0670 - MAE: 0.0670\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0667 - MAE: 0.0667\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0646 - MAE: 0.0646\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0638 - MAE: 0.0638\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 896us/step - loss: 0.0610 - MAE: 0.0610\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 899us/step - loss: 0.0626 - MAE: 0.0626\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 971us/step - loss: 0.0589 - MAE: 0.0589\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 872us/step - loss: 0.0585 - MAE: 0.0585\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.0582 - MAE: 0.0582\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.0567 - MAE: 0.0567\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0559 - MAE: 0.0559\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0543 - MAE: 0.0543\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0536 - MAE: 0.0536\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0529 - MAE: 0.0529\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0527 - MAE: 0.0527\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0517 - MAE: 0.0517\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0519 - MAE: 0.0519\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0516 - MAE: 0.0516\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0484 - MAE: 0.0484\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0482 - MAE: 0.0482\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0497 - MAE: 0.0497\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0489 - MAE: 0.0489\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 914us/step - loss: 0.0459 - MAE: 0.0459\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 775us/step - loss: 0.0469 - MAE: 0.0469\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 893us/step - loss: 0.0474 - MAE: 0.0474\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 965us/step - loss: 0.0463 - MAE: 0.0463\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 856us/step - loss: 0.0473 - MAE: 0.0473\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 897us/step - loss: 0.0463 - MAE: 0.0463\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_229 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.03783806331535299\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdam5 = Sequential()\n",
    "Model22DenseAdam5.add(Dense(14))\n",
    "Model22DenseAdam5.add(Dense(70, activation='relu'))\n",
    "Model22DenseAdam5.add(Dense(7, activation='elu'))\n",
    "Model22DenseAdam5.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdam5.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdam5.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdam5.summary()\n",
    "\n",
    "DenseAdamPrediction5 = Model22DenseAdam5.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction5, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "83edf13c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 998us/step - loss: 0.1997 - MAE: 0.1997\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1068 - MAE: 0.1068\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1032 - MAE: 0.1032\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 893us/step - loss: 0.0974 - MAE: 0.0974\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 864us/step - loss: 0.0968 - MAE: 0.0968\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0965 - MAE: 0.0965\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 991us/step - loss: 0.0940 - MAE: 0.0940\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 996us/step - loss: 0.0928 - MAE: 0.0928\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0914 - MAE: 0.0914\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0925 - MAE: 0.0925\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0868 - MAE: 0.0868\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 2s 885us/step - loss: 0.0858 - MAE: 0.0858\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 884us/step - loss: 0.0848 - MAE: 0.0848\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 850us/step - loss: 0.0851 - MAE: 0.0851\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 938us/step - loss: 0.0831 - MAE: 0.0831\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 952us/step - loss: 0.0806 - MAE: 0.0806\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 902us/step - loss: 0.0818 - MAE: 0.0818\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 953us/step - loss: 0.0827 - MAE: 0.0827\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0830 - MAE: 0.0830\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 885us/step - loss: 0.0800 - MAE: 0.0800\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.0806 - MAE: 0.0806\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0808 - MAE: 0.0808\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.0799 - MAE: 0.0799 0s - loss:\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 929us/step - loss: 0.0807 - MAE: 0.0807\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 951us/step - loss: 0.0798 - MAE: 0.0798\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0797 - MAE: 0.0797\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0801 - MAE: 0.0801\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 982us/step - loss: 0.0792 - MAE: 0.0792\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 959us/step - loss: 0.0793 - MAE: 0.0793\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0789 - MAE: 0.0789\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0784 - MAE: 0.0784\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 988us/step - loss: 0.0786 - MAE: 0.0786\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 884us/step - loss: 0.0798 - MAE: 0.0798\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 999us/step - loss: 0.0785 - MAE: 0.0785\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 975us/step - loss: 0.0780 - MAE: 0.0780\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 863us/step - loss: 0.0784 - MAE: 0.0784\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 942us/step - loss: 0.0793 - MAE: 0.0793\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 918us/step - loss: 0.0777 - MAE: 0.0777\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 856us/step - loss: 0.0779 - MAE: 0.0779\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0785 - MAE: 0.0785\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 973us/step - loss: 0.0784 - MAE: 0.0784\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 923us/step - loss: 0.0769 - MAE: 0.0769\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 917us/step - loss: 0.0779 - MAE: 0.0779\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 949us/step - loss: 0.0779 - MAE: 0.0779\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 861us/step - loss: 0.0775 - MAE: 0.0775\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 855us/step - loss: 0.0778 - MAE: 0.0778\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 920us/step - loss: 0.0778 - MAE: 0.0778\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_233 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.06728549950064475\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdam6 = Sequential()\n",
    "Model22DenseAdam6.add(Dense(14))\n",
    "Model22DenseAdam6.add(Dense(70))\n",
    "Model22DenseAdam6.add(Dense(7, activation='relu'))\n",
    "Model22DenseAdam6.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdam6.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdam6.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdam6.summary()\n",
    "\n",
    "DenseAdamPrediction6 = Model22DenseAdam6.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction6, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6b1c40de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.2772 - MAE: 0.2772\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 875us/step - loss: 0.1709 - MAE: 0.1709\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 849us/step - loss: 0.1470 - MAE: 0.1470\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 895us/step - loss: 0.1284 - MAE: 0.1284\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 995us/step - loss: 0.1226 - MAE: 0.1226\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 961us/step - loss: 0.1172 - MAE: 0.1172\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1101 - MAE: 0.1101\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 898us/step - loss: 0.1131 - MAE: 0.1131\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.1113 - MAE: 0.1113\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1068 - MAE: 0.1068\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1009 - MAE: 0.1009\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.1016 - MAE: 0.1016\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1001 - MAE: 0.1001\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.1015 - MAE: 0.1015\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 976us/step - loss: 0.0995 - MAE: 0.0995\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 925us/step - loss: 0.1003 - MAE: 0.1003\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 890us/step - loss: 0.0973 - MAE: 0.0973\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 911us/step - loss: 0.0984 - MAE: 0.0984\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 844us/step - loss: 0.0988 - MAE: 0.0988\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 867us/step - loss: 0.0943 - MAE: 0.0943\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 897us/step - loss: 0.0954 - MAE: 0.0954\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 846us/step - loss: 0.0970 - MAE: 0.0970\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 879us/step - loss: 0.0966 - MAE: 0.0966\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 882us/step - loss: 0.0969 - MAE: 0.0969\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 880us/step - loss: 0.0934 - MAE: 0.0934\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 951us/step - loss: 0.0957 - MAE: 0.0957\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 969us/step - loss: 0.0946 - MAE: 0.0946\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 853us/step - loss: 0.0942 - MAE: 0.0942\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 942us/step - loss: 0.0943 - MAE: 0.0943\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.0940 - MAE: 0.0940\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_237 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (1, 14)                   0         \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (1, 70)                   1050      \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (1, 70)                   0         \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (1, 7)                    497       \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (1, 1)                    8         \n",
      "=================================================================\n",
      "Total params: 1,723\n",
      "Trainable params: 1,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.11624981486118648\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdam6_1 = Sequential()\n",
    "Model22DenseAdam6_1.add(Dense(14))\n",
    "Model22DenseAdam6_1.add(Dropout(0.1))\n",
    "Model22DenseAdam6_1.add(Dense(70))\n",
    "Model22DenseAdam6_1.add(Dropout(0.1))\n",
    "Model22DenseAdam6_1.add(Dense(7, activation='relu'))\n",
    "Model22DenseAdam6_1.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdam6_1.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdam6_1.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdam6_1.summary()\n",
    "\n",
    "DenseAdamPrediction6_1 = Model22DenseAdam6_1.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction6_1, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5c900a02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2160/2160 [==============================] - 2s 931us/step - loss: 0.1889 - MAE: 0.1889\n",
      "Epoch 2/100\n",
      "2160/2160 [==============================] - 2s 943us/step - loss: 0.0978 - MAE: 0.0978\n",
      "Epoch 3/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0917 - MAE: 0.0917\n",
      "Epoch 4/100\n",
      "2160/2160 [==============================] - 2s 893us/step - loss: 0.0907 - MAE: 0.0907\n",
      "Epoch 5/100\n",
      "2160/2160 [==============================] - 2s 907us/step - loss: 0.0871 - MAE: 0.0871\n",
      "Epoch 6/100\n",
      "2160/2160 [==============================] - 2s 906us/step - loss: 0.0862 - MAE: 0.0862\n",
      "Epoch 7/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.0825 - MAE: 0.0825\n",
      "Epoch 8/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0804 - MAE: 0.0804\n",
      "Epoch 9/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0785 - MAE: 0.0785\n",
      "Epoch 10/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0779 - MAE: 0.0779\n",
      "Epoch 11/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0746 - MAE: 0.0746\n",
      "Epoch 12/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0705 - MAE: 0.0705\n",
      "Epoch 13/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0719 - MAE: 0.0719\n",
      "Epoch 14/100\n",
      "2160/2160 [==============================] - 2s 910us/step - loss: 0.0706 - MAE: 0.0706\n",
      "Epoch 15/100\n",
      "2160/2160 [==============================] - 2s 890us/step - loss: 0.0667 - MAE: 0.0667\n",
      "Epoch 16/100\n",
      "2160/2160 [==============================] - 2s 922us/step - loss: 0.0650 - MAE: 0.0650\n",
      "Epoch 17/100\n",
      "2160/2160 [==============================] - 2s 858us/step - loss: 0.0652 - MAE: 0.0652\n",
      "Epoch 18/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0640 - MAE: 0.0640\n",
      "Epoch 19/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0647 - MAE: 0.0647\n",
      "Epoch 20/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0623 - MAE: 0.0623\n",
      "Epoch 21/100\n",
      "2160/2160 [==============================] - 2s 948us/step - loss: 0.0615 - MAE: 0.0615\n",
      "Epoch 22/100\n",
      "2160/2160 [==============================] - 2s 933us/step - loss: 0.0614 - MAE: 0.0614\n",
      "Epoch 23/100\n",
      "2160/2160 [==============================] - 2s 952us/step - loss: 0.0603 - MAE: 0.0603\n",
      "Epoch 24/100\n",
      "2160/2160 [==============================] - 2s 902us/step - loss: 0.0582 - MAE: 0.0582\n",
      "Epoch 25/100\n",
      "2160/2160 [==============================] - 2s 904us/step - loss: 0.0587 - MAE: 0.0587\n",
      "Epoch 26/100\n",
      "2160/2160 [==============================] - 2s 951us/step - loss: 0.0560 - MAE: 0.0560\n",
      "Epoch 27/100\n",
      "2160/2160 [==============================] - 2s 943us/step - loss: 0.0554 - MAE: 0.0554\n",
      "Epoch 28/100\n",
      "2160/2160 [==============================] - 2s 947us/step - loss: 0.0532 - MAE: 0.0532\n",
      "Epoch 29/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0545 - MAE: 0.0545\n",
      "Epoch 30/100\n",
      "2160/2160 [==============================] - 2s 981us/step - loss: 0.0534 - MAE: 0.0534\n",
      "Epoch 31/100\n",
      "2160/2160 [==============================] - 2s 888us/step - loss: 0.0503 - MAE: 0.0503\n",
      "Epoch 32/100\n",
      "2160/2160 [==============================] - 2s 957us/step - loss: 0.0519 - MAE: 0.0519\n",
      "Epoch 33/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0499 - MAE: 0.0499\n",
      "Epoch 34/100\n",
      "2160/2160 [==============================] - 2s 913us/step - loss: 0.0496 - MAE: 0.0496\n",
      "Epoch 35/100\n",
      "2160/2160 [==============================] - 2s 924us/step - loss: 0.0483 - MAE: 0.0483\n",
      "Epoch 36/100\n",
      "2160/2160 [==============================] - 2s 905us/step - loss: 0.0510 - MAE: 0.0510\n",
      "Epoch 37/100\n",
      "2160/2160 [==============================] - 2s 895us/step - loss: 0.0505 - MAE: 0.0505\n",
      "Epoch 38/100\n",
      "2160/2160 [==============================] - 2s 912us/step - loss: 0.0460 - MAE: 0.0460 0s - loss: 0.04\n",
      "Epoch 39/100\n",
      "2160/2160 [==============================] - 2s 877us/step - loss: 0.0462 - MAE: 0.0462\n",
      "Epoch 40/100\n",
      "2160/2160 [==============================] - 2s 903us/step - loss: 0.0453 - MAE: 0.0453\n",
      "Epoch 41/100\n",
      "2160/2160 [==============================] - 2s 937us/step - loss: 0.0459 - MAE: 0.0459\n",
      "Epoch 42/100\n",
      "2160/2160 [==============================] - 2s 873us/step - loss: 0.0447 - MAE: 0.0447\n",
      "Epoch 43/100\n",
      "2160/2160 [==============================] - 2s 859us/step - loss: 0.0461 - MAE: 0.0461\n",
      "Epoch 44/100\n",
      "2160/2160 [==============================] - 2s 897us/step - loss: 0.0463 - MAE: 0.0463\n",
      "Epoch 45/100\n",
      "2160/2160 [==============================] - 2s 892us/step - loss: 0.0431 - MAE: 0.0431\n",
      "Epoch 46/100\n",
      "2160/2160 [==============================] - 2s 877us/step - loss: 0.0426 - MAE: 0.0426\n",
      "Epoch 47/100\n",
      "2160/2160 [==============================] - 2s 997us/step - loss: 0.0431 - MAE: 0.0431\n",
      "Epoch 48/100\n",
      "2160/2160 [==============================] - 2s 941us/step - loss: 0.0396 - MAE: 0.0396\n",
      "Epoch 49/100\n",
      "2160/2160 [==============================] - 2s 930us/step - loss: 0.0423 - MAE: 0.0423\n",
      "Epoch 50/100\n",
      "2160/2160 [==============================] - 2s 891us/step - loss: 0.0407 - MAE: 0.0407\n",
      "Epoch 51/100\n",
      "2160/2160 [==============================] - 2s 864us/step - loss: 0.0391 - MAE: 0.0391\n",
      "Epoch 52/100\n",
      "2160/2160 [==============================] - 2s 995us/step - loss: 0.0401 - MAE: 0.0401\n",
      "Epoch 53/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0407 - MAE: 0.0407\n",
      "Epoch 54/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0403 - MAE: 0.0403\n",
      "Epoch 55/100\n",
      "2160/2160 [==============================] - 2s 980us/step - loss: 0.0384 - MAE: 0.0384\n",
      "Epoch 56/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0416 - MAE: 0.0416\n",
      "Epoch 57/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0391 - MAE: 0.0391\n",
      "Epoch 58/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0407 - MAE: 0.0407\n",
      "Epoch 59/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0378 - MAE: 0.0378\n",
      "Epoch 60/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0402 - MAE: 0.0402\n",
      "Epoch 61/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0381 - MAE: 0.0381\n",
      "Epoch 62/100\n",
      "2160/2160 [==============================] - 2s 1ms/step - loss: 0.0379 - MAE: 0.0379\n",
      "Epoch 63/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0386 - MAE: 0.0386\n",
      "Epoch 64/100\n",
      "2160/2160 [==============================] - 3s 1ms/step - loss: 0.0379 - MAE: 0.0379\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_241 (Dense)            (1, 14)                   168       \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (1, 192)                  2880      \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (1, 24)                   4632      \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (1, 9)                    225       \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (1, 1)                    10        \n",
      "=================================================================\n",
      "Total params: 7,915\n",
      "Trainable params: 7,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.0370131646728501\n"
     ]
    }
   ],
   "source": [
    "Model22DenseAdam7 = Sequential()\n",
    "Model22DenseAdam7.add(Dense(14))\n",
    "Model22DenseAdam7.add(Dense(192, activation='relu'))\n",
    "Model22DenseAdam7.add(Dense(24, activation='relu'))\n",
    "Model22DenseAdam7.add(Dense(9, activation='relu'))\n",
    "Model22DenseAdam7.add(Dense(1, activation='linear'))\n",
    "Model22DenseAdam7.compile(optimizer='Adam', loss='MAE', metrics = ['MAE'])\n",
    "\n",
    "\n",
    "Model22DenseAdam7.fit(x_train, y_train.values, epochs=100, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "Model22DenseAdam7.summary()\n",
    "\n",
    "DenseAdamPrediction7 = Model22DenseAdam7.predict(x_test)\n",
    "score = mean_absolute_error(DenseAdamPrediction7, y_test)\n",
    "print('Test score:', score)\n",
    "\n",
    "scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3b11bf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04618874454538769,\n",
       " 0.061669735938649516,\n",
       " 0.0448484305063653,\n",
       " 0.06512580697267797,\n",
       " 0.05398609063981162,\n",
       " 0.04970185433414035,\n",
       " 0.0485444111573671,\n",
       " 0.06650154902422574,\n",
       " 0.07336105339859007,\n",
       " 0.0261501592826332,\n",
       " 0.03512159421531412,\n",
       " 0.07108216797519239,\n",
       " 0.051302785713137,\n",
       " 0.07218295842037578,\n",
       " 0.05663287427821477,\n",
       " 0.056656353716939556,\n",
       " 0.04599401392697639,\n",
       " 0.06715962203427209,\n",
       " 0.07856506080123266,\n",
       " 0.036692643120285674,\n",
       " 0.04493942445726938,\n",
       " 0.0637433020691469,\n",
       " 0.04723295995814457,\n",
       " 0.07224405098841402,\n",
       " 0.05108442051235161,\n",
       " 0.02718000548659245,\n",
       " 0.03783806331535299,\n",
       " 0.06728549950064475,\n",
       " 0.11624981486118648,\n",
       " 0.0370131646728501]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5127bdc0",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d3e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIXEDF0.loc[x_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3fa55e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "REP['Limit'] = MIXEDF0.loc[x_test.index, 'Limit']\n",
    "\n",
    "REP['Z'] = MIXEDF0.loc[x_test.index, 'Z']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aec97bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a631ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model22DenseAdamax7 = load_model('Model7Nov.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "098e227e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=Signal<br>r (cm)=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "Signal",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "Signal",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -241.5,
          -240.35,
          -239.2,
          -238.05,
          -236.9,
          -235.75,
          -234.6,
          -233.45,
          -232.3,
          -231.15,
          -230,
          -228.85,
          -227.7,
          -226.55,
          -225.4,
          -224.25,
          -223.1,
          -221.95,
          -220.8,
          -219.65,
          -218.5,
          -215.05,
          -211.6,
          -208.15,
          -204.7,
          -201.25,
          -197.8,
          -194.35,
          -190.9,
          -187.45,
          -184,
          -180.55,
          -177.1,
          -173.65,
          -170.2,
          -166.75,
          -163.3,
          -159.85,
          -156.4,
          -152.95,
          -149.5,
          -146.05,
          -142.6,
          -139.15,
          -135.7,
          -132.25,
          -128.8,
          -125.35,
          -121.9,
          -118.45,
          -115,
          -111.55,
          -108.1,
          -104.65,
          -101.2,
          -97.75,
          -94.3,
          -90.85,
          -87.4,
          -83.95,
          -80.5,
          -77.05,
          -73.6,
          -70.15,
          -66.7,
          -63.25,
          -59.8,
          -56.35,
          -52.9,
          -49.45,
          -46,
          -42.55,
          -39.1,
          -35.65,
          -32.2,
          -28.75,
          -25.3,
          -21.85,
          -18.4,
          -14.95,
          -11.5,
          -8.05,
          -4.6,
          -1.15,
          0,
          1.15,
          4.6,
          8.05,
          11.5,
          14.95,
          18.4,
          21.85,
          25.3,
          28.75,
          32.2,
          35.65,
          39.1,
          42.55,
          46,
          49.45,
          52.9,
          56.35,
          59.8,
          63.25,
          66.7,
          70.15,
          73.6,
          77.05,
          80.5,
          83.95,
          87.4,
          90.85,
          94.3,
          97.75,
          101.2,
          104.65,
          108.1,
          111.55,
          115,
          118.45,
          121.9,
          125.35,
          128.8,
          132.25,
          135.7,
          139.15,
          142.6,
          146.05,
          149.5,
          152.95,
          156.4,
          159.85,
          163.3,
          166.75,
          170.2,
          173.65,
          177.1,
          180.55,
          184,
          187.45,
          190.9,
          194.35,
          197.8,
          201.25,
          204.7,
          208.15,
          211.6,
          215.05,
          218.5,
          219.65,
          220.8,
          221.95,
          223.1,
          224.25,
          225.4,
          226.55,
          227.7,
          228.85,
          230,
          231.15,
          232.3,
          233.45,
          234.6,
          235.75,
          236.9,
          238.05,
          239.2,
          240.35
         ],
         "xaxis": "x",
         "y": [
          0.032744,
          0.033541,
          0.034443,
          0.035512,
          0.037821,
          0.043901,
          0.061672,
          0.10007,
          0.15858,
          0.22966,
          0.30485,
          0.3835,
          0.45839,
          0.52697,
          0.57772,
          0.60576,
          0.61709,
          0.62101,
          0.62264,
          0.624,
          0.62389,
          0.62496,
          0.62519,
          0.62576,
          0.62621,
          0.62611,
          0.62621,
          0.62621,
          0.62634,
          0.62654,
          0.62576,
          0.62589,
          0.62587,
          0.62587,
          0.62563,
          0.62507,
          0.6248,
          0.62437,
          0.62424,
          0.62379,
          0.62322,
          0.62309,
          0.62242,
          0.62231,
          0.62218,
          0.62149,
          0.62138,
          0.62138,
          0.6208,
          0.62045,
          0.6201,
          0.61976,
          0.61941,
          0.61963,
          0.61915,
          0.61859,
          0.61882,
          0.61859,
          0.61789,
          0.61765,
          0.61741,
          0.61707,
          0.61672,
          0.6164,
          0.61581,
          0.61509,
          0.61477,
          0.6141,
          0.61269,
          0.6113,
          0.60957,
          0.60818,
          0.60735,
          0.60634,
          0.6061,
          0.6061,
          0.60541,
          0.60493,
          0.60458,
          0.60343,
          0.6017,
          0.60125,
          0.60021,
          0.60028,
          0.60028,
          0.59997,
          0.60076,
          0.6017,
          0.6025,
          0.60319,
          0.60434,
          0.60482,
          0.60597,
          0.60569,
          0.60618,
          0.60655,
          0.60701,
          0.60829,
          0.61002,
          0.61165,
          0.61317,
          0.6136,
          0.61474,
          0.61533,
          0.61581,
          0.61581,
          0.61637,
          0.61717,
          0.61707,
          0.61797,
          0.61832,
          0.61843,
          0.61856,
          0.61888,
          0.61915,
          0.61925,
          0.6196,
          0.6204,
          0.62051,
          0.62029,
          0.62142,
          0.62099,
          0.62097,
          0.62144,
          0.6219,
          0.62211,
          0.62214,
          0.62248,
          0.62281,
          0.62329,
          0.62342,
          0.62422,
          0.62457,
          0.62457,
          0.62502,
          0.62513,
          0.62524,
          0.62502,
          0.62537,
          0.62561,
          0.62604,
          0.62615,
          0.62537,
          0.62513,
          0.62491,
          0.62489,
          0.62478,
          0.6242,
          0.62227,
          0.6219,
          0.62153,
          0.61982,
          0.61416,
          0.5983,
          0.56161,
          0.50512,
          0.43388,
          0.35849,
          0.28103,
          0.20444,
          0.13625,
          0.084382,
          0.054754,
          0.041915,
          0.037398,
          0.0356,
          0.034611,
          0.033796
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=Analytical Function<br>r (cm)=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "Analytical Function",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "Analytical Function",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -241.5,
          -240.35,
          -239.2,
          -238.05,
          -236.9,
          -235.75,
          -234.6,
          -233.45,
          -232.3,
          -231.15,
          -230,
          -228.85,
          -227.7,
          -226.55,
          -225.4,
          -224.25,
          -223.1,
          -221.95,
          -220.8,
          -219.65,
          -218.5,
          -215.05,
          -211.6,
          -208.15,
          -204.7,
          -201.25,
          -197.8,
          -194.35,
          -190.9,
          -187.45,
          -184,
          -180.55,
          -177.1,
          -173.65,
          -170.2,
          -166.75,
          -163.3,
          -159.85,
          -156.4,
          -152.95,
          -149.5,
          -146.05,
          -142.6,
          -139.15,
          -135.7,
          -132.25,
          -128.8,
          -125.35,
          -121.9,
          -118.45,
          -115,
          -111.55,
          -108.1,
          -104.65,
          -101.2,
          -97.75,
          -94.3,
          -90.85,
          -87.4,
          -83.95,
          -80.5,
          -77.05,
          -73.6,
          -70.15,
          -66.7,
          -63.25,
          -59.8,
          -56.35,
          -52.9,
          -49.45,
          -46,
          -42.55,
          -39.1,
          -35.65,
          -32.2,
          -28.75,
          -25.3,
          -21.85,
          -18.4,
          -14.95,
          -11.5,
          -8.05,
          -4.6,
          -1.15,
          0,
          1.15,
          4.6,
          8.05,
          11.5,
          14.95,
          18.4,
          21.85,
          25.3,
          28.75,
          32.2,
          35.65,
          39.1,
          42.55,
          46,
          49.45,
          52.9,
          56.35,
          59.8,
          63.25,
          66.7,
          70.15,
          73.6,
          77.05,
          80.5,
          83.95,
          87.4,
          90.85,
          94.3,
          97.75,
          101.2,
          104.65,
          108.1,
          111.55,
          115,
          118.45,
          121.9,
          125.35,
          128.8,
          132.25,
          135.7,
          139.15,
          142.6,
          146.05,
          149.5,
          152.95,
          156.4,
          159.85,
          163.3,
          166.75,
          170.2,
          173.65,
          177.1,
          180.55,
          184,
          187.45,
          190.9,
          194.35,
          197.8,
          201.25,
          204.7,
          208.15,
          211.6,
          215.05,
          218.5,
          219.65,
          220.8,
          221.95,
          223.1,
          224.25,
          225.4,
          226.55,
          227.7,
          228.85,
          230,
          231.15,
          232.3,
          233.45,
          234.6,
          235.75,
          236.9,
          238.05,
          239.2,
          240.35
         ],
         "xaxis": "x",
         "y": [
          0.007790464238126501,
          0.009526421185787485,
          0.011903824579118892,
          0.015272927910292621,
          0.020249600931243786,
          0.02798265479550154,
          0.04075884227596976,
          0.06341351763710991,
          0.10632616381760485,
          0.18799019398326802,
          0.3163294615019953,
          0.44438657681608695,
          0.5254123798092089,
          0.5675893782438622,
          0.5895048353858686,
          0.6015578505926176,
          0.6085850891321593,
          0.6128712971876688,
          0.6155631936681231,
          0.6172750073970483,
          0.6183557819865777,
          0.6195408895344021,
          0.6192643697025934,
          0.6183858265923612,
          0.6172335384965515,
          0.6159538693960291,
          0.6146196295195538,
          0.6132700628107477,
          0.6119276191526779,
          0.6106057115529127,
          0.609312598916098,
          0.6080534539435927,
          0.6068315245525341,
          0.605648817334689,
          0.6045065116284574,
          0.6034052230784424,
          0.6023451733949187,
          0.6013263032542402,
          0.6003483504913651,
          0.5994109013156056,
          0.5985134304551705,
          0.5976553266737239,
          0.5968359136596691,
          0.5960544638760997,
          0.5953102098913826,
          0.5946023529569361,
          0.5939300686973854,
          0.5932925127675598,
          0.592688824060695,
          0.592118128009008,
          0.5915795391794152,
          0.5910721627381053,
          0.5905950962297449,
          0.5901474309904466,
          0.5897282527360483,
          0.5893366428603468,
          0.5889716787278477,
          0.588632434420063,
          0.5883179813240168,
          0.5880273882614265,
          0.5877597219494354,
          0.5875140474383105,
          0.5872894280338543,
          0.587084925698492,
          0.586899601207898,
          0.586732514264008,
          0.5865827235929166,
          0.5864492871174418,
          0.5863312620048807,
          0.5862277047645076,
          0.5861376712903917,
          0.5860602169614125,
          0.5859943966669122,
          0.5859392648503268,
          0.5858938755606399,
          0.5858572824778326,
          0.585828538939406,
          0.5858066979727254,
          0.5857908123084825,
          0.58577993440313,
          0.585773116451482,
          0.5857694103990373,
          0.5857678679514856,
          0.5857675405815461,
          0.5857675374995921,
          0.5857675405815461,
          0.5857678679514856,
          0.5857694103990373,
          0.585773116451482,
          0.58577993440313,
          0.5857908123084825,
          0.5858066979727254,
          0.585828538939406,
          0.5858572824778326,
          0.5858938755606399,
          0.5859392648503268,
          0.5859943966669122,
          0.5860602169614125,
          0.5861376712903917,
          0.5862277047645076,
          0.5863312620048807,
          0.5864492871174418,
          0.5865827235929166,
          0.586732514264008,
          0.586899601207898,
          0.587084925698492,
          0.5872894280338543,
          0.5875140474383105,
          0.5877597219494354,
          0.5880273882614265,
          0.5883179813240168,
          0.588632434420063,
          0.5889716787278477,
          0.5893366428603468,
          0.5897282527360483,
          0.5901474309904466,
          0.5905950962297449,
          0.5910721627381053,
          0.5915795391794152,
          0.592118128009008,
          0.592688824060695,
          0.5932925127675598,
          0.5939300686973854,
          0.5946023529569361,
          0.5953102098913826,
          0.5960544638760997,
          0.5968359136596691,
          0.5976553266737239,
          0.5985134304551705,
          0.5994109013156056,
          0.6003483504913651,
          0.6013263032542402,
          0.6023451733949187,
          0.6034052230784424,
          0.6045065116284574,
          0.605648817334689,
          0.6068315245525341,
          0.6080534539435927,
          0.609312598916098,
          0.6106057115529127,
          0.6119276191526779,
          0.6132700628107477,
          0.6146196295195538,
          0.6159538693960291,
          0.6172335384965515,
          0.6183858265923612,
          0.6192643697025934,
          0.6195408895344021,
          0.6183557819865777,
          0.6172750073970483,
          0.6155631936681231,
          0.6128712971876688,
          0.6085850891321593,
          0.6015578505926176,
          0.5895048353858686,
          0.5675893782438622,
          0.5254123798092089,
          0.44438657681608695,
          0.3163294615019953,
          0.18799019398326802,
          0.10632616381760485,
          0.06341351763710991,
          0.04075884227596976,
          0.02798265479550154,
          0.020249600931243786,
          0.015272927910292621,
          0.011903824579118892,
          0.009526421185787485
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=Neural Network<br>r (cm)=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "Neural Network",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "Neural Network",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -241.5,
          -240.35,
          -239.2,
          -238.05,
          -236.9,
          -235.75,
          -234.6,
          -233.45,
          -232.3,
          -231.15,
          -230,
          -228.85,
          -227.7,
          -226.55,
          -225.4,
          -224.25,
          -223.1,
          -221.95,
          -220.8,
          -219.65,
          -218.5,
          -215.05,
          -211.6,
          -208.15,
          -204.7,
          -201.25,
          -197.8,
          -194.35,
          -190.9,
          -187.45,
          -184,
          -180.55,
          -177.1,
          -173.65,
          -170.2,
          -166.75,
          -163.3,
          -159.85,
          -156.4,
          -152.95,
          -149.5,
          -146.05,
          -142.6,
          -139.15,
          -135.7,
          -132.25,
          -128.8,
          -125.35,
          -121.9,
          -118.45,
          -115,
          -111.55,
          -108.1,
          -104.65,
          -101.2,
          -97.75,
          -94.3,
          -90.85,
          -87.4,
          -83.95,
          -80.5,
          -77.05,
          -73.6,
          -70.15,
          -66.7,
          -63.25,
          -59.8,
          -56.35,
          -52.9,
          -49.45,
          -46,
          -42.55,
          -39.1,
          -35.65,
          -32.2,
          -28.75,
          -25.3,
          -21.85,
          -18.4,
          -14.95,
          -11.5,
          -8.05,
          -4.6,
          -1.15,
          0,
          1.15,
          4.6,
          8.05,
          11.5,
          14.95,
          18.4,
          21.85,
          25.3,
          28.75,
          32.2,
          35.65,
          39.1,
          42.55,
          46,
          49.45,
          52.9,
          56.35,
          59.8,
          63.25,
          66.7,
          70.15,
          73.6,
          77.05,
          80.5,
          83.95,
          87.4,
          90.85,
          94.3,
          97.75,
          101.2,
          104.65,
          108.1,
          111.55,
          115,
          118.45,
          121.9,
          125.35,
          128.8,
          132.25,
          135.7,
          139.15,
          142.6,
          146.05,
          149.5,
          152.95,
          156.4,
          159.85,
          163.3,
          166.75,
          170.2,
          173.65,
          177.1,
          180.55,
          184,
          187.45,
          190.9,
          194.35,
          197.8,
          201.25,
          204.7,
          208.15,
          211.6,
          215.05,
          218.5,
          219.65,
          220.8,
          221.95,
          223.1,
          224.25,
          225.4,
          226.55,
          227.7,
          228.85,
          230,
          231.15,
          232.3,
          233.45,
          234.6,
          235.75,
          236.9,
          238.05,
          239.2,
          240.35
         ],
         "xaxis": "x",
         "y": [
          0.03703826665878296,
          0.037627220153808594,
          0.03827139735221863,
          0.045950114727020264,
          0.05767148733139038,
          0.07194992899894714,
          0.08984285593032837,
          0.11552858352661133,
          0.1613588035106659,
          0.2205224633216858,
          0.30510789155960083,
          0.4182876944541931,
          0.5612829923629761,
          0.6095410585403442,
          0.6162553429603577,
          0.6194468140602112,
          0.6208667755126953,
          0.6220102310180664,
          0.6230171918869019,
          0.6239190101623535,
          0.6243908405303955,
          0.6254301071166992,
          0.6256080865859985,
          0.625755250453949,
          0.6258883476257324,
          0.6260149478912354,
          0.6260091066360474,
          0.6259408593177795,
          0.6258729100227356,
          0.6258059740066528,
          0.6257403492927551,
          0.6256855726242065,
          0.6256476640701294,
          0.6256116628646851,
          0.625577449798584,
          0.6255313158035278,
          0.6252201795578003,
          0.624884307384491,
          0.6245503425598145,
          0.6242182850837708,
          0.6238880157470703,
          0.6235596537590027,
          0.6232330203056335,
          0.6229082345962524,
          0.6225851774215698,
          0.6223716735839844,
          0.6222379207611084,
          0.6221061944961548,
          0.6219764947891235,
          0.6218488216400146,
          0.6217232346534729,
          0.6215994358062744,
          0.621477484703064,
          0.6213574409484863,
          0.6211979389190674,
          0.6208791732788086,
          0.6205620765686035,
          0.6202465295791626,
          0.6199326515197754,
          0.6196203231811523,
          0.6193094253540039,
          0.6189998984336853,
          0.6186916828155518,
          0.6183848977088928,
          0.6180792450904846,
          0.6177270412445068,
          0.6173492074012756,
          0.6169723868370056,
          0.6163050532341003,
          0.6153813004493713,
          0.6144582033157349,
          0.6135357618331909,
          0.6126139163970947,
          0.6116738319396973,
          0.6107168197631836,
          0.6097803711891174,
          0.6088443994522095,
          0.6079087853431702,
          0.6069735288619995,
          0.6058826446533203,
          0.6046727895736694,
          0.6033917665481567,
          0.6021198034286499,
          0.6008478999137878,
          0.6004239320755005,
          0.600683331489563,
          0.60146164894104,
          0.6023573875427246,
          0.603280782699585,
          0.6042178273200989,
          0.605161726474762,
          0.6061058044433594,
          0.6070500612258911,
          0.6079946160316467,
          0.608939528465271,
          0.6098847985267639,
          0.610780656337738,
          0.6116436719894409,
          0.612507164478302,
          0.6133713126182556,
          0.6142361164093018,
          0.6151083707809448,
          0.6159882545471191,
          0.6168666481971741,
          0.6177446246147156,
          0.6184805631637573,
          0.6188308596611023,
          0.6191351413726807,
          0.6194018125534058,
          0.619669497013092,
          0.6199383735656738,
          0.6201995015144348,
          0.6203616857528687,
          0.6205109357833862,
          0.6206614971160889,
          0.6208136081695557,
          0.6209670305252075,
          0.621124267578125,
          0.6215704679489136,
          0.62201988697052,
          0.6223483085632324,
          0.6226682662963867,
          0.6229895353317261,
          0.6232545375823975,
          0.623515248298645,
          0.6237634420394897,
          0.6239583492279053,
          0.6241550445556641,
          0.6243535280227661,
          0.6245537996292114,
          0.6249085664749146,
          0.6252713799476624,
          0.6256353855133057,
          0.6260007619857788,
          0.6263673305511475,
          0.626735270023346,
          0.6271045207977295,
          0.6274716854095459,
          0.627838134765625,
          0.6282079815864563,
          0.6285788416862488,
          0.629206657409668,
          0.6299632787704468,
          0.6299411058425903,
          0.6296976804733276,
          0.6294593214988708,
          0.6287882328033447,
          0.6265192031860352,
          0.6240008473396301,
          0.623032808303833,
          0.6219666004180908,
          0.6204586625099182,
          0.6188745498657227,
          0.6169553399085999,
          0.6120811700820923,
          0.6047568917274475,
          0.5547285676002502,
          0.4278489947319031,
          0.29033923149108887,
          0.21438279747962952,
          0.14552846550941467,
          0.10574916005134583,
          0.0739278793334961,
          0.04942438006401062,
          0.03302493691444397,
          0.031867027282714844,
          0.03086864948272705,
          0.029969096183776855
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "r (cm)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"09e20f65-87fd-4539-adf7-5940e8b35932\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"09e20f65-87fd-4539-adf7-5940e8b35932\")) {                    Plotly.newPlot(                        \"09e20f65-87fd-4539-adf7-5940e8b35932\",                        [{\"hovertemplate\": \"variable=Signal<br>r (cm)=%{x}<br>value=%{y}<extra></extra>\", \"legendgroup\": \"Signal\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"Signal\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [-241.5, -240.35, -239.2, -238.05, -236.9, -235.75, -234.6, -233.45, -232.3, -231.15, -230.0, -228.85, -227.7, -226.55, -225.4, -224.25, -223.1, -221.95, -220.8, -219.65, -218.5, -215.05, -211.6, -208.15, -204.7, -201.25, -197.8, -194.35, -190.9, -187.45, -184.0, -180.55, -177.1, -173.65, -170.2, -166.75, -163.3, -159.85, -156.4, -152.95, -149.5, -146.05, -142.6, -139.15, -135.7, -132.25, -128.8, -125.35, -121.9, -118.45, -115.0, -111.55, -108.1, -104.65, -101.2, -97.75, -94.3, -90.85, -87.4, -83.95, -80.5, -77.05, -73.6, -70.15, -66.7, -63.25, -59.8, -56.35, -52.9, -49.45, -46.0, -42.55, -39.1, -35.65, -32.2, -28.75, -25.3, -21.85, -18.4, -14.95, -11.5, -8.05, -4.6, -1.15, 0.0, 1.15, 4.6, 8.05, 11.5, 14.95, 18.4, 21.85, 25.3, 28.75, 32.2, 35.65, 39.1, 42.55, 46.0, 49.45, 52.9, 56.35, 59.8, 63.25, 66.7, 70.15, 73.6, 77.05, 80.5, 83.95, 87.4, 90.85, 94.3, 97.75, 101.2, 104.65, 108.1, 111.55, 115.0, 118.45, 121.9, 125.35, 128.8, 132.25, 135.7, 139.15, 142.6, 146.05, 149.5, 152.95, 156.4, 159.85, 163.3, 166.75, 170.2, 173.65, 177.1, 180.55, 184.0, 187.45, 190.9, 194.35, 197.8, 201.25, 204.7, 208.15, 211.6, 215.05, 218.5, 219.65, 220.8, 221.95, 223.1, 224.25, 225.4, 226.55, 227.7, 228.85, 230.0, 231.15, 232.3, 233.45, 234.6, 235.75, 236.9, 238.05, 239.2, 240.35], \"xaxis\": \"x\", \"y\": [0.032744, 0.033541, 0.034443, 0.035512, 0.037821, 0.043901, 0.061672, 0.10007, 0.15858, 0.22966, 0.30485, 0.3835, 0.45839, 0.52697, 0.57772, 0.60576, 0.61709, 0.62101, 0.62264, 0.624, 0.62389, 0.62496, 0.62519, 0.62576, 0.62621, 0.62611, 0.62621, 0.62621, 0.62634, 0.62654, 0.62576, 0.62589, 0.62587, 0.62587, 0.62563, 0.62507, 0.6248, 0.62437, 0.62424, 0.62379, 0.62322, 0.62309, 0.62242, 0.62231, 0.62218, 0.62149, 0.62138, 0.62138, 0.6208, 0.62045, 0.6201, 0.61976, 0.61941, 0.61963, 0.61915, 0.61859, 0.61882, 0.61859, 0.61789, 0.61765, 0.61741, 0.61707, 0.61672, 0.6164, 0.61581, 0.61509, 0.61477, 0.6141, 0.61269, 0.6113, 0.60957, 0.60818, 0.60735, 0.60634, 0.6061, 0.6061, 0.60541, 0.60493, 0.60458, 0.60343, 0.6017, 0.60125, 0.60021, 0.60028, 0.60028, 0.59997, 0.60076, 0.6017, 0.6025, 0.60319, 0.60434, 0.60482, 0.60597, 0.60569, 0.60618, 0.60655, 0.60701, 0.60829, 0.61002, 0.61165, 0.61317, 0.6136, 0.61474, 0.61533, 0.61581, 0.61581, 0.61637, 0.61717, 0.61707, 0.61797, 0.61832, 0.61843, 0.61856, 0.61888, 0.61915, 0.61925, 0.6196, 0.6204, 0.62051, 0.62029, 0.62142, 0.62099, 0.62097, 0.62144, 0.6219, 0.62211, 0.62214, 0.62248, 0.62281, 0.62329, 0.62342, 0.62422, 0.62457, 0.62457, 0.62502, 0.62513, 0.62524, 0.62502, 0.62537, 0.62561, 0.62604, 0.62615, 0.62537, 0.62513, 0.62491, 0.62489, 0.62478, 0.6242, 0.62227, 0.6219, 0.62153, 0.61982, 0.61416, 0.5983, 0.56161, 0.50512, 0.43388, 0.35849, 0.28103, 0.20444, 0.13625, 0.084382, 0.054754, 0.041915, 0.037398, 0.0356, 0.034611, 0.033796], \"yaxis\": \"y\"}, {\"hovertemplate\": \"variable=Analytical Function<br>r (cm)=%{x}<br>value=%{y}<extra></extra>\", \"legendgroup\": \"Analytical Function\", \"line\": {\"color\": \"#EF553B\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"Analytical Function\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [-241.5, -240.35, -239.2, -238.05, -236.9, -235.75, -234.6, -233.45, -232.3, -231.15, -230.0, -228.85, -227.7, -226.55, -225.4, -224.25, -223.1, -221.95, -220.8, -219.65, -218.5, -215.05, -211.6, -208.15, -204.7, -201.25, -197.8, -194.35, -190.9, -187.45, -184.0, -180.55, -177.1, -173.65, -170.2, -166.75, -163.3, -159.85, -156.4, -152.95, -149.5, -146.05, -142.6, -139.15, -135.7, -132.25, -128.8, -125.35, -121.9, -118.45, -115.0, -111.55, -108.1, -104.65, -101.2, -97.75, -94.3, -90.85, -87.4, -83.95, -80.5, -77.05, -73.6, -70.15, -66.7, -63.25, -59.8, -56.35, -52.9, -49.45, -46.0, -42.55, -39.1, -35.65, -32.2, -28.75, -25.3, -21.85, -18.4, -14.95, -11.5, -8.05, -4.6, -1.15, 0.0, 1.15, 4.6, 8.05, 11.5, 14.95, 18.4, 21.85, 25.3, 28.75, 32.2, 35.65, 39.1, 42.55, 46.0, 49.45, 52.9, 56.35, 59.8, 63.25, 66.7, 70.15, 73.6, 77.05, 80.5, 83.95, 87.4, 90.85, 94.3, 97.75, 101.2, 104.65, 108.1, 111.55, 115.0, 118.45, 121.9, 125.35, 128.8, 132.25, 135.7, 139.15, 142.6, 146.05, 149.5, 152.95, 156.4, 159.85, 163.3, 166.75, 170.2, 173.65, 177.1, 180.55, 184.0, 187.45, 190.9, 194.35, 197.8, 201.25, 204.7, 208.15, 211.6, 215.05, 218.5, 219.65, 220.8, 221.95, 223.1, 224.25, 225.4, 226.55, 227.7, 228.85, 230.0, 231.15, 232.3, 233.45, 234.6, 235.75, 236.9, 238.05, 239.2, 240.35], \"xaxis\": \"x\", \"y\": [0.007790464238126501, 0.009526421185787485, 0.011903824579118892, 0.015272927910292621, 0.020249600931243786, 0.02798265479550154, 0.04075884227596976, 0.06341351763710991, 0.10632616381760485, 0.18799019398326802, 0.3163294615019953, 0.44438657681608695, 0.5254123798092089, 0.5675893782438622, 0.5895048353858686, 0.6015578505926176, 0.6085850891321593, 0.6128712971876688, 0.6155631936681231, 0.6172750073970483, 0.6183557819865777, 0.6195408895344021, 0.6192643697025934, 0.6183858265923612, 0.6172335384965515, 0.6159538693960291, 0.6146196295195538, 0.6132700628107477, 0.6119276191526779, 0.6106057115529127, 0.609312598916098, 0.6080534539435927, 0.6068315245525341, 0.605648817334689, 0.6045065116284574, 0.6034052230784424, 0.6023451733949187, 0.6013263032542402, 0.6003483504913651, 0.5994109013156056, 0.5985134304551705, 0.5976553266737239, 0.5968359136596691, 0.5960544638760997, 0.5953102098913826, 0.5946023529569361, 0.5939300686973854, 0.5932925127675598, 0.592688824060695, 0.592118128009008, 0.5915795391794152, 0.5910721627381053, 0.5905950962297449, 0.5901474309904466, 0.5897282527360483, 0.5893366428603468, 0.5889716787278477, 0.588632434420063, 0.5883179813240168, 0.5880273882614265, 0.5877597219494354, 0.5875140474383105, 0.5872894280338543, 0.587084925698492, 0.586899601207898, 0.586732514264008, 0.5865827235929166, 0.5864492871174418, 0.5863312620048807, 0.5862277047645076, 0.5861376712903917, 0.5860602169614125, 0.5859943966669122, 0.5859392648503268, 0.5858938755606399, 0.5858572824778326, 0.585828538939406, 0.5858066979727254, 0.5857908123084825, 0.58577993440313, 0.585773116451482, 0.5857694103990373, 0.5857678679514856, 0.5857675405815461, 0.5857675374995921, 0.5857675405815461, 0.5857678679514856, 0.5857694103990373, 0.585773116451482, 0.58577993440313, 0.5857908123084825, 0.5858066979727254, 0.585828538939406, 0.5858572824778326, 0.5858938755606399, 0.5859392648503268, 0.5859943966669122, 0.5860602169614125, 0.5861376712903917, 0.5862277047645076, 0.5863312620048807, 0.5864492871174418, 0.5865827235929166, 0.586732514264008, 0.586899601207898, 0.587084925698492, 0.5872894280338543, 0.5875140474383105, 0.5877597219494354, 0.5880273882614265, 0.5883179813240168, 0.588632434420063, 0.5889716787278477, 0.5893366428603468, 0.5897282527360483, 0.5901474309904466, 0.5905950962297449, 0.5910721627381053, 0.5915795391794152, 0.592118128009008, 0.592688824060695, 0.5932925127675598, 0.5939300686973854, 0.5946023529569361, 0.5953102098913826, 0.5960544638760997, 0.5968359136596691, 0.5976553266737239, 0.5985134304551705, 0.5994109013156056, 0.6003483504913651, 0.6013263032542402, 0.6023451733949187, 0.6034052230784424, 0.6045065116284574, 0.605648817334689, 0.6068315245525341, 0.6080534539435927, 0.609312598916098, 0.6106057115529127, 0.6119276191526779, 0.6132700628107477, 0.6146196295195538, 0.6159538693960291, 0.6172335384965515, 0.6183858265923612, 0.6192643697025934, 0.6195408895344021, 0.6183557819865777, 0.6172750073970483, 0.6155631936681231, 0.6128712971876688, 0.6085850891321593, 0.6015578505926176, 0.5895048353858686, 0.5675893782438622, 0.5254123798092089, 0.44438657681608695, 0.3163294615019953, 0.18799019398326802, 0.10632616381760485, 0.06341351763710991, 0.04075884227596976, 0.02798265479550154, 0.020249600931243786, 0.015272927910292621, 0.011903824579118892, 0.009526421185787485], \"yaxis\": \"y\"}, {\"hovertemplate\": \"variable=Neural Network<br>r (cm)=%{x}<br>value=%{y}<extra></extra>\", \"legendgroup\": \"Neural Network\", \"line\": {\"color\": \"#00cc96\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"Neural Network\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [-241.5, -240.35, -239.2, -238.05, -236.9, -235.75, -234.6, -233.45, -232.3, -231.15, -230.0, -228.85, -227.7, -226.55, -225.4, -224.25, -223.1, -221.95, -220.8, -219.65, -218.5, -215.05, -211.6, -208.15, -204.7, -201.25, -197.8, -194.35, -190.9, -187.45, -184.0, -180.55, -177.1, -173.65, -170.2, -166.75, -163.3, -159.85, -156.4, -152.95, -149.5, -146.05, -142.6, -139.15, -135.7, -132.25, -128.8, -125.35, -121.9, -118.45, -115.0, -111.55, -108.1, -104.65, -101.2, -97.75, -94.3, -90.85, -87.4, -83.95, -80.5, -77.05, -73.6, -70.15, -66.7, -63.25, -59.8, -56.35, -52.9, -49.45, -46.0, -42.55, -39.1, -35.65, -32.2, -28.75, -25.3, -21.85, -18.4, -14.95, -11.5, -8.05, -4.6, -1.15, 0.0, 1.15, 4.6, 8.05, 11.5, 14.95, 18.4, 21.85, 25.3, 28.75, 32.2, 35.65, 39.1, 42.55, 46.0, 49.45, 52.9, 56.35, 59.8, 63.25, 66.7, 70.15, 73.6, 77.05, 80.5, 83.95, 87.4, 90.85, 94.3, 97.75, 101.2, 104.65, 108.1, 111.55, 115.0, 118.45, 121.9, 125.35, 128.8, 132.25, 135.7, 139.15, 142.6, 146.05, 149.5, 152.95, 156.4, 159.85, 163.3, 166.75, 170.2, 173.65, 177.1, 180.55, 184.0, 187.45, 190.9, 194.35, 197.8, 201.25, 204.7, 208.15, 211.6, 215.05, 218.5, 219.65, 220.8, 221.95, 223.1, 224.25, 225.4, 226.55, 227.7, 228.85, 230.0, 231.15, 232.3, 233.45, 234.6, 235.75, 236.9, 238.05, 239.2, 240.35], \"xaxis\": \"x\", \"y\": [0.03703826665878296, 0.037627220153808594, 0.03827139735221863, 0.045950114727020264, 0.05767148733139038, 0.07194992899894714, 0.08984285593032837, 0.11552858352661133, 0.1613588035106659, 0.2205224633216858, 0.30510789155960083, 0.4182876944541931, 0.5612829923629761, 0.6095410585403442, 0.6162553429603577, 0.6194468140602112, 0.6208667755126953, 0.6220102310180664, 0.6230171918869019, 0.6239190101623535, 0.6243908405303955, 0.6254301071166992, 0.6256080865859985, 0.625755250453949, 0.6258883476257324, 0.6260149478912354, 0.6260091066360474, 0.6259408593177795, 0.6258729100227356, 0.6258059740066528, 0.6257403492927551, 0.6256855726242065, 0.6256476640701294, 0.6256116628646851, 0.625577449798584, 0.6255313158035278, 0.6252201795578003, 0.624884307384491, 0.6245503425598145, 0.6242182850837708, 0.6238880157470703, 0.6235596537590027, 0.6232330203056335, 0.6229082345962524, 0.6225851774215698, 0.6223716735839844, 0.6222379207611084, 0.6221061944961548, 0.6219764947891235, 0.6218488216400146, 0.6217232346534729, 0.6215994358062744, 0.621477484703064, 0.6213574409484863, 0.6211979389190674, 0.6208791732788086, 0.6205620765686035, 0.6202465295791626, 0.6199326515197754, 0.6196203231811523, 0.6193094253540039, 0.6189998984336853, 0.6186916828155518, 0.6183848977088928, 0.6180792450904846, 0.6177270412445068, 0.6173492074012756, 0.6169723868370056, 0.6163050532341003, 0.6153813004493713, 0.6144582033157349, 0.6135357618331909, 0.6126139163970947, 0.6116738319396973, 0.6107168197631836, 0.6097803711891174, 0.6088443994522095, 0.6079087853431702, 0.6069735288619995, 0.6058826446533203, 0.6046727895736694, 0.6033917665481567, 0.6021198034286499, 0.6008478999137878, 0.6004239320755005, 0.600683331489563, 0.60146164894104, 0.6023573875427246, 0.603280782699585, 0.6042178273200989, 0.605161726474762, 0.6061058044433594, 0.6070500612258911, 0.6079946160316467, 0.608939528465271, 0.6098847985267639, 0.610780656337738, 0.6116436719894409, 0.612507164478302, 0.6133713126182556, 0.6142361164093018, 0.6151083707809448, 0.6159882545471191, 0.6168666481971741, 0.6177446246147156, 0.6184805631637573, 0.6188308596611023, 0.6191351413726807, 0.6194018125534058, 0.619669497013092, 0.6199383735656738, 0.6201995015144348, 0.6203616857528687, 0.6205109357833862, 0.6206614971160889, 0.6208136081695557, 0.6209670305252075, 0.621124267578125, 0.6215704679489136, 0.62201988697052, 0.6223483085632324, 0.6226682662963867, 0.6229895353317261, 0.6232545375823975, 0.623515248298645, 0.6237634420394897, 0.6239583492279053, 0.6241550445556641, 0.6243535280227661, 0.6245537996292114, 0.6249085664749146, 0.6252713799476624, 0.6256353855133057, 0.6260007619857788, 0.6263673305511475, 0.626735270023346, 0.6271045207977295, 0.6274716854095459, 0.627838134765625, 0.6282079815864563, 0.6285788416862488, 0.629206657409668, 0.6299632787704468, 0.6299411058425903, 0.6296976804733276, 0.6294593214988708, 0.6287882328033447, 0.6265192031860352, 0.6240008473396301, 0.623032808303833, 0.6219666004180908, 0.6204586625099182, 0.6188745498657227, 0.6169553399085999, 0.6120811700820923, 0.6047568917274475, 0.5547285676002502, 0.4278489947319031, 0.29033923149108887, 0.21438279747962952, 0.14552846550941467, 0.10574916005134583, 0.0739278793334961, 0.04942438006401062, 0.03302493691444397, 0.031867027282714844, 0.03086864948272705, 0.029969096183776855], \"yaxis\": \"y\"}],                        {\"legend\": {\"title\": {\"text\": \"variable\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"r (cm)\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"value\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('09e20f65-87fd-4539-adf7-5940e8b35932');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "REP = x.copy()\n",
    "REP['Signal'] = y['señal'].values\n",
    "REP['Analytical Function'] = x['Analytic function'].values\n",
    "REP['r (cm)'] = x['r'].values\n",
    "\n",
    "REP['Neural Network'] = Model22DenseAdamax7.predict(NewX)\n",
    "REP[(REP['Limit']==400) & (REP['Z']==115) & (REP['In']==1)].set_index('r (cm)').iloc[:,[-3,-2,-1]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db00255",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9086e32e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pddopen40x5 = pd.read_csv('OPEN/txt/40x5/40x5pdd.txt', delimiter='\t\t', names=['r', 'señal open 40x5', 'error open 40x5'])\n",
    "pcropen40x5 = pd.read_csv('OPEN/txt/40x5/40x5pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal open 40x5', 'error open 40x5'])\n",
    "pinopen40x5 = pd.read_csv('OPEN/txt/40x5/40x5pro-in-100.txt', delimiter='\t\t', names=['r', 'señal open 40x5', 'error open 40x5'])\n",
    "\n",
    "pddFFF40x5 = pd.read_csv('FFF/txt/40x5/40x5pdd.txt', delimiter='\t\t', names=['r', 'señal fff 40x5', 'error fff 40x5'])\n",
    "pcrFFF40x5 = pd.read_csv('FFF/txt/40x5/40x5pro-cr-100.txt', delimiter='\t\t', names=['r', 'señal fff 40x5', 'error fff 40x5'])\n",
    "pinFFF40x5 = pd.read_csv('FFF/txt/40x5/40x5pro-in-100.txt', delimiter='\t\t', names=['r', 'señal fff 40x5', 'error fff 40x5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7dc50cfe",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pddopen40x5_85 = pd.read_csv('OPEN/txt/40x5/40x5pdd.txt', delimiter='\t\t', names=['r', 'señal open 40x5', 'error open 40x5'])\n",
    "pcropen40x5_85 = pd.read_csv('OPEN/txt/40x5/40x5pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal open 40x5', 'error open 40x5'])\n",
    "pinopen40x5_85 = pd.read_csv('OPEN/txt/40x5/40x5pro-in-85.txt', delimiter='\t\t', names=['r', 'señal open 40x5', 'error open 40x5'])\n",
    "\n",
    "pddFFF40x5_85 = pd.read_csv('FFF/txt/40x5/40x5pdd.txt', delimiter='\t\t', names=['r', 'señal fff 40x5', 'error fff 40x5'])\n",
    "pcrFFF40x5_85 = pd.read_csv('FFF/txt/40x5/40x5pro-cr-85.txt', delimiter='\t\t', names=['r', 'señal fff 40x5', 'error fff 40x5'])\n",
    "pinFFF40x5_85 = pd.read_csv('FFF/txt/40x5/40x5pro-in-85.txt', delimiter='\t\t', names=['r', 'señal fff 40x5', 'error fff 40x5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "981961e0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n",
      "/home/armando/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pddopen40x5_115 = pd.read_csv('OPEN/txt/40x5/40x5pdd.txt', delimiter='\t\t', names=['r', 'señal open 40x5', 'error open 40x5'])\n",
    "pcropen40x5_115 = pd.read_csv('OPEN/txt/40x5/40x5pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal open 40x5', 'error open 40x5'])\n",
    "pinopen40x5_115 = pd.read_csv('OPEN/txt/40x5/40x5pro-in-115.txt', delimiter='\t\t', names=['r', 'señal open 40x5', 'error open 40x5'])\n",
    "\n",
    "pddFFF40x5_115 = pd.read_csv('FFF/txt/40x5/40x5pdd.txt', delimiter='\t\t', names=['r', 'señal fff 40x5', 'error fff 40x5'])\n",
    "pcrFFF40x5_115 = pd.read_csv('FFF/txt/40x5/40x5pro-cr-115.txt', delimiter='\t\t', names=['r', 'señal fff 40x5', 'error fff 40x5'])\n",
    "pinFFF40x5_115 = pd.read_csv('FFF/txt/40x5/40x5pro-in-115.txt', delimiter='\t\t', names=['r', 'señal fff 40x5', 'error fff 40x5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f92e3de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=señal fff 40x5<br>r=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "señal fff 40x5",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "señal fff 40x5",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -241.5,
          -240.35,
          -239.2,
          -238.05,
          -236.9,
          -235.75,
          -234.6,
          -233.45,
          -232.3,
          -231.15,
          -230,
          -228.85,
          -227.7,
          -226.55,
          -225.4,
          -224.25,
          -223.1,
          -221.95,
          -220.8,
          -219.65,
          -218.5,
          -215.05,
          -211.6,
          -208.15,
          -204.7,
          -201.25,
          -197.8,
          -194.35,
          -190.9,
          -187.45,
          -184,
          -180.55,
          -177.1,
          -173.65,
          -170.2,
          -166.75,
          -163.3,
          -159.85,
          -156.4,
          -152.95,
          -149.5,
          -146.05,
          -142.6,
          -139.15,
          -135.7,
          -132.25,
          -128.8,
          -125.35,
          -121.9,
          -118.45,
          -115,
          -111.55,
          -108.1,
          -104.65,
          -101.2,
          -97.75,
          -94.3,
          -90.85,
          -87.4,
          -83.95,
          -80.5,
          -77.05,
          -73.6,
          -70.15,
          -70,
          -68,
          -66.7,
          -65,
          -63.25,
          -62,
          -59.8,
          -59,
          -56.35,
          -56,
          -53,
          -52.9,
          -50,
          -49.45,
          -47,
          -46,
          -44,
          -42.55,
          -41,
          -39.1,
          -38,
          -35.65,
          -35,
          -34,
          -33,
          -32.2,
          -32,
          -31,
          -30,
          -29,
          -28.75,
          -28,
          -27,
          -26,
          -25.3,
          -25,
          -24,
          -23,
          -22,
          -21.85,
          -21,
          -20,
          -19,
          -18.4,
          -18,
          -17,
          -16,
          -15,
          -14.95,
          -12,
          -11.5,
          -9,
          -8.05,
          -6,
          -4.6,
          -3,
          -1.15,
          0,
          1.15,
          3,
          4.6,
          6,
          8.05,
          9,
          11.5,
          12,
          14.95,
          15,
          16,
          17,
          18,
          18.4,
          19,
          20,
          21,
          21.85,
          22,
          23,
          24,
          25,
          25.3,
          26,
          27,
          28,
          28.75,
          29,
          30,
          31,
          32,
          32.2,
          33,
          34,
          35,
          35.65,
          38,
          39.1,
          41,
          42.55,
          44,
          46,
          47,
          49.45,
          50,
          52.9,
          53,
          56,
          56.35,
          59,
          59.8,
          62,
          63.25,
          65,
          66.7,
          68,
          70,
          70.15,
          73.6,
          77.05,
          80.5,
          83.95,
          87.4,
          90.85,
          94.3,
          97.75,
          101.2,
          104.65,
          108.1,
          111.55,
          115,
          118.45,
          121.9,
          125.35,
          128.8,
          132.25,
          135.7,
          139.15,
          142.6,
          146.05,
          149.5,
          152.95,
          156.4,
          159.85,
          163.3,
          166.75,
          170.2,
          173.65,
          177.1,
          180.55,
          184,
          187.45,
          190.9,
          194.35,
          197.8,
          201.25,
          204.7,
          208.15,
          211.6
         ],
         "xaxis": "x",
         "y": [
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.006763,
          0.0068164,
          0.0068164,
          0.0070746,
          0.0070746,
          0.0072906,
          0.0072906,
          0.0076073,
          0.0076073,
          0.008062,
          0.0085921,
          0.0085921,
          0.0092903,
          0.0092903,
          0.01038,
          0.01038,
          0.011555,
          0.011555,
          0.013013,
          0.013013,
          0.014692,
          0.014692,
          0.018637,
          0.026684,
          0.04902,
          0.04902,
          0.10587,
          0.20397,
          0.32105,
          0.43731,
          0.43731,
          0.56398,
          0.68923,
          0.81031,
          0.81031,
          0.9228,
          1.0098,
          1.051,
          1.0618,
          1.0618,
          1.0682,
          1.0705,
          1.0723,
          1.0723,
          1.0753,
          1.0786,
          1.0767,
          1.081,
          1.081,
          1.0858,
          1.0858,
          1.0874,
          1.0874,
          1.0886,
          1.0886,
          1.0894,
          1.0894,
          1.0879,
          1.0879,
          1.0861,
          1.0861,
          1.0797,
          1.0797,
          1.0762,
          1.0762,
          1.0693,
          1.0693,
          1.0603,
          1.0474,
          1.0165,
          0.9383,
          0.9383,
          0.8249,
          0.70503,
          0.58608,
          0.58608,
          0.454,
          0.3338,
          0.21538,
          0.10807,
          0.10807,
          0.042227,
          0.022556,
          0.017166,
          0.017166,
          0.015579,
          0.014736,
          0.014014,
          0.013447,
          0.013447,
          0.012893,
          0.012383,
          0.011859,
          0.011859,
          0.010445,
          0.010445,
          0.0093734,
          0.0093734,
          0.0085315,
          0.0085315,
          0.0080145,
          0.0080145,
          0.00752,
          0.00752,
          0.0071613,
          0.0069251,
          0.0069251,
          0.0067201,
          0.0067201,
          0.0065234,
          0.0065234,
          0.0063272,
          0.0063272,
          0.0062565,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356,
          0.0061356
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=señal open 40x5<br>r=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "señal open 40x5",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "señal open 40x5",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -241.5,
          -240.35,
          -239.2,
          -238.05,
          -236.9,
          -235.75,
          -234.6,
          -233.45,
          -232.3,
          -231.15,
          -230,
          -228.85,
          -227.7,
          -226.55,
          -225.4,
          -224.25,
          -223.1,
          -221.95,
          -220.8,
          -219.65,
          -218.5,
          -215.05,
          -211.6,
          -208.15,
          -204.7,
          -201.25,
          -197.8,
          -194.35,
          -190.9,
          -187.45,
          -184,
          -180.55,
          -177.1,
          -173.65,
          -170.2,
          -166.75,
          -163.3,
          -159.85,
          -156.4,
          -152.95,
          -149.5,
          -146.05,
          -142.6,
          -139.15,
          -135.7,
          -132.25,
          -128.8,
          -125.35,
          -121.9,
          -118.45,
          -115,
          -111.55,
          -108.1,
          -104.65,
          -101.2,
          -97.75,
          -94.3,
          -90.85,
          -87.4,
          -83.95,
          -80.5,
          -77.05,
          -73.6,
          -70.15,
          -70,
          -68,
          -66.7,
          -65,
          -63.25,
          -62,
          -59.8,
          -59,
          -56.35,
          -56,
          -53,
          -52.9,
          -50,
          -49.45,
          -47,
          -46,
          -44,
          -42.55,
          -41,
          -39.1,
          -38,
          -35.65,
          -35,
          -34,
          -33,
          -32.2,
          -32,
          -31,
          -30,
          -29,
          -28.75,
          -28,
          -27,
          -26,
          -25.3,
          -25,
          -24,
          -23,
          -22,
          -21.85,
          -21,
          -20,
          -19,
          -18.4,
          -18,
          -17,
          -16,
          -15,
          -14.95,
          -12,
          -11.5,
          -9,
          -8.05,
          -6,
          -4.6,
          -3,
          -1.15,
          0,
          1.15,
          3,
          4.6,
          6,
          8.05,
          9,
          11.5,
          12,
          14.95,
          15,
          16,
          17,
          18,
          18.4,
          19,
          20,
          21,
          21.85,
          22,
          23,
          24,
          25,
          25.3,
          26,
          27,
          28,
          28.75,
          29,
          30,
          31,
          32,
          32.2,
          33,
          34,
          35,
          35.65,
          38,
          39.1,
          41,
          42.55,
          44,
          46,
          47,
          49.45,
          50,
          52.9,
          53,
          56,
          56.35,
          59,
          59.8,
          62,
          63.25,
          65,
          66.7,
          68,
          70,
          70.15,
          73.6,
          77.05,
          80.5,
          83.95,
          87.4,
          90.85,
          94.3,
          97.75,
          101.2,
          104.65,
          108.1,
          111.55,
          115,
          118.45,
          121.9,
          125.35,
          128.8,
          132.25,
          135.7,
          139.15,
          142.6,
          146.05,
          149.5,
          152.95,
          156.4,
          159.85,
          163.3,
          166.75,
          170.2,
          173.65,
          177.1,
          180.55,
          184,
          187.45,
          190.9,
          194.35,
          197.8,
          201.25,
          204.7,
          208.15,
          211.6
         ],
         "xaxis": "x",
         "y": [
          0.039123,
          0.040513,
          0.042066,
          0.044444,
          0.04938,
          0.063606,
          0.10702,
          0.19735,
          0.33609,
          0.50541,
          0.68462,
          0.87143,
          1.0483,
          1.2107,
          1.3317,
          1.3972,
          1.4262,
          1.4337,
          1.4378,
          1.4394,
          1.4415,
          1.4431,
          1.4448,
          1.4448,
          1.4433,
          1.4454,
          1.4445,
          1.4451,
          1.4437,
          1.4447,
          1.4438,
          1.4424,
          1.4416,
          1.4414,
          1.4402,
          1.4393,
          1.4377,
          1.4366,
          1.4352,
          1.435,
          1.4339,
          1.4319,
          1.4296,
          1.4282,
          1.4272,
          1.4283,
          1.4266,
          1.4257,
          1.4255,
          1.4238,
          1.4224,
          1.4219,
          1.4203,
          1.4209,
          1.4206,
          1.4196,
          1.4184,
          1.4159,
          1.4147,
          1.4153,
          1.4133,
          1.4128,
          1.4108,
          1.4118,
          1.4118,
          1.4118,
          1.4099,
          1.4099,
          1.4081,
          1.4081,
          1.4059,
          1.4059,
          1.404,
          1.404,
          1.404,
          1.4009,
          1.4009,
          1.3974,
          1.3974,
          1.394,
          1.394,
          1.3907,
          1.3907,
          1.3868,
          1.3868,
          1.3852,
          1.3852,
          1.3852,
          1.3852,
          1.3863,
          1.3863,
          1.3863,
          1.3863,
          1.3863,
          1.3867,
          1.3867,
          1.3867,
          1.3867,
          1.3833,
          1.3833,
          1.3833,
          1.3833,
          1.3833,
          1.3842,
          1.3842,
          1.3842,
          1.3842,
          1.3814,
          1.3814,
          1.3814,
          1.3814,
          1.3814,
          1.3781,
          1.3781,
          1.375,
          1.375,
          1.3719,
          1.3719,
          1.3706,
          1.3706,
          1.3675,
          1.3689,
          1.3683,
          1.3683,
          1.37,
          1.37,
          1.3722,
          1.3722,
          1.3739,
          1.3739,
          1.3763,
          1.3763,
          1.3763,
          1.3763,
          1.3763,
          1.3774,
          1.3774,
          1.3774,
          1.3774,
          1.3796,
          1.3796,
          1.3796,
          1.3796,
          1.3796,
          1.3802,
          1.3802,
          1.3802,
          1.3802,
          1.3804,
          1.3804,
          1.3804,
          1.3804,
          1.3804,
          1.3821,
          1.3821,
          1.3821,
          1.3821,
          1.3829,
          1.3829,
          1.3854,
          1.3854,
          1.3856,
          1.3856,
          1.3926,
          1.3926,
          1.395,
          1.395,
          1.3978,
          1.3978,
          1.3978,
          1.4002,
          1.4002,
          1.4011,
          1.4011,
          1.403,
          1.403,
          1.4024,
          1.4024,
          1.4024,
          1.4037,
          1.4045,
          1.4073,
          1.4082,
          1.4096,
          1.4112,
          1.4121,
          1.4131,
          1.4131,
          1.4137,
          1.4143,
          1.4154,
          1.4142,
          1.415,
          1.4178,
          1.4183,
          1.4194,
          1.42,
          1.4208,
          1.4208,
          1.4216,
          1.4233,
          1.4227,
          1.4255,
          1.4263,
          1.4292,
          1.43,
          1.4316,
          1.4313,
          1.4321,
          1.4335,
          1.4338,
          1.4344,
          1.4352,
          1.4366,
          1.4374,
          1.436,
          1.4366,
          1.4362,
          1.4365,
          1.4382,
          1.4362
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "r"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"65cf93bb-791b-4002-87cb-a46396992efb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"65cf93bb-791b-4002-87cb-a46396992efb\")) {                    Plotly.newPlot(                        \"65cf93bb-791b-4002-87cb-a46396992efb\",                        [{\"hovertemplate\": \"variable=se\\u00f1al fff 40x5<br>r=%{x}<br>value=%{y}<extra></extra>\", \"legendgroup\": \"se\\u00f1al fff 40x5\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"se\\u00f1al fff 40x5\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [-241.5, -240.35, -239.2, -238.05, -236.9, -235.75, -234.6, -233.45, -232.3, -231.15, -230.0, -228.85, -227.7, -226.55, -225.4, -224.25, -223.1, -221.95, -220.8, -219.65, -218.5, -215.05, -211.6, -208.15, -204.7, -201.25, -197.8, -194.35, -190.9, -187.45, -184.0, -180.55, -177.1, -173.65, -170.2, -166.75, -163.3, -159.85, -156.4, -152.95, -149.5, -146.05, -142.6, -139.15, -135.7, -132.25, -128.8, -125.35, -121.9, -118.45, -115.0, -111.55, -108.1, -104.65, -101.2, -97.75, -94.3, -90.85, -87.4, -83.95, -80.5, -77.05, -73.6, -70.15, -70.0, -68.0, -66.7, -65.0, -63.25, -62.0, -59.8, -59.0, -56.35, -56.0, -53.0, -52.9, -50.0, -49.45, -47.0, -46.0, -44.0, -42.55, -41.0, -39.1, -38.0, -35.65, -35.0, -34.0, -33.0, -32.2, -32.0, -31.0, -30.0, -29.0, -28.75, -28.0, -27.0, -26.0, -25.3, -25.0, -24.0, -23.0, -22.0, -21.85, -21.0, -20.0, -19.0, -18.4, -18.0, -17.0, -16.0, -15.0, -14.95, -12.0, -11.5, -9.0, -8.05, -6.0, -4.6, -3.0, -1.15, 0.0, 1.15, 3.0, 4.6, 6.0, 8.05, 9.0, 11.5, 12.0, 14.95, 15.0, 16.0, 17.0, 18.0, 18.4, 19.0, 20.0, 21.0, 21.85, 22.0, 23.0, 24.0, 25.0, 25.3, 26.0, 27.0, 28.0, 28.75, 29.0, 30.0, 31.0, 32.0, 32.2, 33.0, 34.0, 35.0, 35.65, 38.0, 39.1, 41.0, 42.55, 44.0, 46.0, 47.0, 49.45, 50.0, 52.9, 53.0, 56.0, 56.35, 59.0, 59.8, 62.0, 63.25, 65.0, 66.7, 68.0, 70.0, 70.15, 73.6, 77.05, 80.5, 83.95, 87.4, 90.85, 94.3, 97.75, 101.2, 104.65, 108.1, 111.55, 115.0, 118.45, 121.9, 125.35, 128.8, 132.25, 135.7, 139.15, 142.6, 146.05, 149.5, 152.95, 156.4, 159.85, 163.3, 166.75, 170.2, 173.65, 177.1, 180.55, 184.0, 187.45, 190.9, 194.35, 197.8, 201.25, 204.7, 208.15, 211.6], \"xaxis\": \"x\", \"y\": [0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.006763, 0.0068164, 0.0068164, 0.0070746, 0.0070746, 0.0072906, 0.0072906, 0.0076073, 0.0076073, 0.008062, 0.0085921, 0.0085921, 0.0092903, 0.0092903, 0.01038, 0.01038, 0.011555, 0.011555, 0.013013, 0.013013, 0.014692, 0.014692, 0.018637, 0.026684, 0.04902, 0.04902, 0.10587, 0.20397, 0.32105, 0.43731, 0.43731, 0.56398, 0.68923, 0.81031, 0.81031, 0.9228, 1.0098, 1.051, 1.0618, 1.0618, 1.0682, 1.0705, 1.0723, 1.0723, 1.0753, 1.0786, 1.0767, 1.081, 1.081, 1.0858, 1.0858, 1.0874, 1.0874, 1.0886, 1.0886, 1.0894, 1.0894, 1.0879, 1.0879, 1.0861, 1.0861, 1.0797, 1.0797, 1.0762, 1.0762, 1.0693, 1.0693, 1.0603, 1.0474, 1.0165, 0.9383, 0.9383, 0.8249, 0.70503, 0.58608, 0.58608, 0.454, 0.3338, 0.21538, 0.10807, 0.10807, 0.042227, 0.022556, 0.017166, 0.017166, 0.015579, 0.014736, 0.014014, 0.013447, 0.013447, 0.012893, 0.012383, 0.011859, 0.011859, 0.010445, 0.010445, 0.0093734, 0.0093734, 0.0085315, 0.0085315, 0.0080145, 0.0080145, 0.00752, 0.00752, 0.0071613, 0.0069251, 0.0069251, 0.0067201, 0.0067201, 0.0065234, 0.0065234, 0.0063272, 0.0063272, 0.0062565, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356, 0.0061356], \"yaxis\": \"y\"}, {\"hovertemplate\": \"variable=se\\u00f1al open 40x5<br>r=%{x}<br>value=%{y}<extra></extra>\", \"legendgroup\": \"se\\u00f1al open 40x5\", \"line\": {\"color\": \"#EF553B\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"se\\u00f1al open 40x5\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [-241.5, -240.35, -239.2, -238.05, -236.9, -235.75, -234.6, -233.45, -232.3, -231.15, -230.0, -228.85, -227.7, -226.55, -225.4, -224.25, -223.1, -221.95, -220.8, -219.65, -218.5, -215.05, -211.6, -208.15, -204.7, -201.25, -197.8, -194.35, -190.9, -187.45, -184.0, -180.55, -177.1, -173.65, -170.2, -166.75, -163.3, -159.85, -156.4, -152.95, -149.5, -146.05, -142.6, -139.15, -135.7, -132.25, -128.8, -125.35, -121.9, -118.45, -115.0, -111.55, -108.1, -104.65, -101.2, -97.75, -94.3, -90.85, -87.4, -83.95, -80.5, -77.05, -73.6, -70.15, -70.0, -68.0, -66.7, -65.0, -63.25, -62.0, -59.8, -59.0, -56.35, -56.0, -53.0, -52.9, -50.0, -49.45, -47.0, -46.0, -44.0, -42.55, -41.0, -39.1, -38.0, -35.65, -35.0, -34.0, -33.0, -32.2, -32.0, -31.0, -30.0, -29.0, -28.75, -28.0, -27.0, -26.0, -25.3, -25.0, -24.0, -23.0, -22.0, -21.85, -21.0, -20.0, -19.0, -18.4, -18.0, -17.0, -16.0, -15.0, -14.95, -12.0, -11.5, -9.0, -8.05, -6.0, -4.6, -3.0, -1.15, 0.0, 1.15, 3.0, 4.6, 6.0, 8.05, 9.0, 11.5, 12.0, 14.95, 15.0, 16.0, 17.0, 18.0, 18.4, 19.0, 20.0, 21.0, 21.85, 22.0, 23.0, 24.0, 25.0, 25.3, 26.0, 27.0, 28.0, 28.75, 29.0, 30.0, 31.0, 32.0, 32.2, 33.0, 34.0, 35.0, 35.65, 38.0, 39.1, 41.0, 42.55, 44.0, 46.0, 47.0, 49.45, 50.0, 52.9, 53.0, 56.0, 56.35, 59.0, 59.8, 62.0, 63.25, 65.0, 66.7, 68.0, 70.0, 70.15, 73.6, 77.05, 80.5, 83.95, 87.4, 90.85, 94.3, 97.75, 101.2, 104.65, 108.1, 111.55, 115.0, 118.45, 121.9, 125.35, 128.8, 132.25, 135.7, 139.15, 142.6, 146.05, 149.5, 152.95, 156.4, 159.85, 163.3, 166.75, 170.2, 173.65, 177.1, 180.55, 184.0, 187.45, 190.9, 194.35, 197.8, 201.25, 204.7, 208.15, 211.6], \"xaxis\": \"x\", \"y\": [0.039123, 0.040513, 0.042066, 0.044444, 0.04938, 0.063606, 0.10702, 0.19735, 0.33609, 0.50541, 0.68462, 0.87143, 1.0483, 1.2107, 1.3317, 1.3972, 1.4262, 1.4337, 1.4378, 1.4394, 1.4415, 1.4431, 1.4448, 1.4448, 1.4433, 1.4454, 1.4445, 1.4451, 1.4437, 1.4447, 1.4438, 1.4424, 1.4416, 1.4414, 1.4402, 1.4393, 1.4377, 1.4366, 1.4352, 1.435, 1.4339, 1.4319, 1.4296, 1.4282, 1.4272, 1.4283, 1.4266, 1.4257, 1.4255, 1.4238, 1.4224, 1.4219, 1.4203, 1.4209, 1.4206, 1.4196, 1.4184, 1.4159, 1.4147, 1.4153, 1.4133, 1.4128, 1.4108, 1.4118, 1.4118, 1.4118, 1.4099, 1.4099, 1.4081, 1.4081, 1.4059, 1.4059, 1.404, 1.404, 1.404, 1.4009, 1.4009, 1.3974, 1.3974, 1.394, 1.394, 1.3907, 1.3907, 1.3868, 1.3868, 1.3852, 1.3852, 1.3852, 1.3852, 1.3863, 1.3863, 1.3863, 1.3863, 1.3863, 1.3867, 1.3867, 1.3867, 1.3867, 1.3833, 1.3833, 1.3833, 1.3833, 1.3833, 1.3842, 1.3842, 1.3842, 1.3842, 1.3814, 1.3814, 1.3814, 1.3814, 1.3814, 1.3781, 1.3781, 1.375, 1.375, 1.3719, 1.3719, 1.3706, 1.3706, 1.3675, 1.3689, 1.3683, 1.3683, 1.37, 1.37, 1.3722, 1.3722, 1.3739, 1.3739, 1.3763, 1.3763, 1.3763, 1.3763, 1.3763, 1.3774, 1.3774, 1.3774, 1.3774, 1.3796, 1.3796, 1.3796, 1.3796, 1.3796, 1.3802, 1.3802, 1.3802, 1.3802, 1.3804, 1.3804, 1.3804, 1.3804, 1.3804, 1.3821, 1.3821, 1.3821, 1.3821, 1.3829, 1.3829, 1.3854, 1.3854, 1.3856, 1.3856, 1.3926, 1.3926, 1.395, 1.395, 1.3978, 1.3978, 1.3978, 1.4002, 1.4002, 1.4011, 1.4011, 1.403, 1.403, 1.4024, 1.4024, 1.4024, 1.4037, 1.4045, 1.4073, 1.4082, 1.4096, 1.4112, 1.4121, 1.4131, 1.4131, 1.4137, 1.4143, 1.4154, 1.4142, 1.415, 1.4178, 1.4183, 1.4194, 1.42, 1.4208, 1.4208, 1.4216, 1.4233, 1.4227, 1.4255, 1.4263, 1.4292, 1.43, 1.4316, 1.4313, 1.4321, 1.4335, 1.4338, 1.4344, 1.4352, 1.4366, 1.4374, 1.436, 1.4366, 1.4362, 1.4365, 1.4382, 1.4362], \"yaxis\": \"y\"}],                        {\"legend\": {\"title\": {\"text\": \"variable\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"r\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"value\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('65cf93bb-791b-4002-87cb-a46396992efb');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pcrFFF40x5.merge(pinopen40x5_115, on='r', how='outer').set_index('r')[['señal fff 40x5', 'señal open 40x5']].sort_index().ffill().bfill().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4031244e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=señal fff 40x5<br>r=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "señal fff 40x5",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "señal fff 40x5",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0
         ],
         "xaxis": "x",
         "y": [
          1.0879
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "r"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"97f88a84-ce78-439c-8240-ccaf8142af73\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"97f88a84-ce78-439c-8240-ccaf8142af73\")) {                    Plotly.newPlot(                        \"97f88a84-ce78-439c-8240-ccaf8142af73\",                        [{\"hovertemplate\": \"variable=se\\u00f1al fff 40x5<br>r=%{x}<br>value=%{y}<extra></extra>\", \"legendgroup\": \"se\\u00f1al fff 40x5\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"se\\u00f1al fff 40x5\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [0.0], \"xaxis\": \"x\", \"y\": [1.0879], \"yaxis\": \"y\"}],                        {\"legend\": {\"title\": {\"text\": \"variable\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"r\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"value\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('97f88a84-ce78-439c-8240-ccaf8142af73');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pcrFFF40x5.merge(pinopen40x5_115, on='r').set_index('r')['señal fff 40x5'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed9050",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFF5 = pddFFF40x5.iloc[:,:2]\n",
    "FFF5['FFF'] = 1\n",
    "FFF5.columns = ['r', 'señal', 'FFF']\n",
    "FFF5['Area'] = \n",
    "FFF5['Limit'] = 25\n",
    "\n",
    "Open5 = pcropen5_115.iloc[:,:2]\n",
    "Open5['FFF'] = 0\n",
    "Open5.columns = ['r', 'señal', 'FFF']\n",
    "Open5['Area'] = 25\n",
    "Open5['Limit'] = 25\n",
    "\n",
    "FFF10 = pcrFFF10_115.iloc[:,:2]\n",
    "FFF10['FFF'] = 1\n",
    "FFF10.columns = ['r', 'señal', 'FFF']\n",
    "FFF10['Area'] = 100\n",
    "FFF10['Limit'] = 50\n",
    "\n",
    "Open10 = pcropen10_115.iloc[:,:2]\n",
    "Open10['FFF'] = 0\n",
    "Open10.columns = ['r', 'señal', 'FFF']\n",
    "Open10['Area'] = 100\n",
    "Open10['Limit'] = 50\n",
    "\n",
    "FFF20 = pcrFFF20_115.iloc[:,:2]\n",
    "FFF20['FFF'] = 1\n",
    "FFF20.columns = ['r', 'señal', 'FFF']\n",
    "FFF20['Area'] = 400\n",
    "FFF20['Limit'] = 100\n",
    "\n",
    "Open20 = pcropen20_115.iloc[:,:2]\n",
    "Open20['FFF'] = 0\n",
    "Open20.columns = ['r', 'señal', 'FFF']\n",
    "Open20['Area'] = 400\n",
    "Open20['Limit'] = 100\n",
    "\n",
    "FFF40 = pcrFFF40_115.iloc[:,:2]\n",
    "FFF40['FFF'] = 1\n",
    "FFF40.columns = ['r', 'señal', 'FFF']\n",
    "FFF40['Area'] = 1600\n",
    "FFF40['Limit'] = 200\n",
    "\n",
    "Open40 = pcropen40_115.iloc[:,:2]\n",
    "Open40['FFF'] = 0\n",
    "Open40.columns = ['r', 'señal', 'FFF']\n",
    "Open40['Area'] = 1600\n",
    "Open40['Limit'] = 200\n",
    "\n",
    "MixedCR115 = pd.concat([Open5, FFF5, Open10, FFF10, Open20, FFF20, Open40, FFF40]) \n",
    "MixedCR115['In'] = 0\n",
    "MixedCR115['Z'] = 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bebcbc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d377a796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d18e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1def5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e847932f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105c9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3b338e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152f50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb238901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1557f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
